{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import platform\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    pass\n",
    "args = Args()\n",
    "args.test_scene = 'alley_1'\n",
    "args.arch = \"densenet121\"\n",
    "args.epoches = 500\n",
    "args.epoches_unary_threshold = 0\n",
    "args.image_h = 256\n",
    "args.image_w = 256\n",
    "args.img_extentions = [\"png\"]\n",
    "args.training_thresholds = [250,200,150,50,0,300]\n",
    "args.base_lr = 1e-5\n",
    "args.snapshot_interval = 5000\n",
    "args.debug = True\n",
    "\n",
    "system_ = platform.system()\n",
    "system_dist, system_version, _ = platform.dist()\n",
    "if system_ == \"Darwin\": \n",
    "    args.train_dir = '/Volumes/Transcend/dataset/sintel2'\n",
    "    args.pretrained = False\n",
    "elif platform.dist() ==  ('debian', 'jessie/sid', ''):\n",
    "    args.train_dir = '/home/albertxavier/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "elif platform.dist() == ('debian', 'stretch/sid', ''):\n",
    "    args.train_dir = '/home/cad/lwp/workspace/dataset/sintel2'\n",
    "    args.pretrained = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "def make_dataset(dir):\n",
    "    images_paths = glob.glob(os.path.join(dir, 'clean', '*', '*.png'))\n",
    "    albedo_paths = images_paths[:]\n",
    "    shading_paths = images_paths[:]\n",
    "    pathes = []\n",
    "    for img_path in images_paths:\n",
    "        sp = img_path.split('/'); sp[-3] = 'albedo'; sp = ['/'] + sp; albedo_path = os.path.join(*sp)\n",
    "        sp = img_path.split('/'); sp[-3] = 'albedo'; sp = ['/'] + sp; shading_path = os.path.join(*sp)\n",
    "        pathes.append((img_path, albedo_path, shading_path))\n",
    "    return pathes\n",
    "\n",
    "class MyImageFolder(data_utils.Dataset):\n",
    "    def __init__(self, root, transform=None, target_transform=None,\n",
    "                loader=default_loader):\n",
    "        imgs = make_dataset(root)\n",
    "        if len(imgs) == 0:\n",
    "            raise(RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n",
    "                               \"Supported image extensions are: \" + \",\".join(args.img_extentions)))\n",
    "\n",
    "        self.root = root\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path, albedo_path, shading_path = self.imgs[index]\n",
    "        \n",
    "        img = self.loader(img_path)\n",
    "        albedo = self.loader(albedo_path)\n",
    "        shading = self.loader(shading_path)\n",
    "        \n",
    "        if self.transform is not None: img = self.transform(img)\n",
    "        if self.transform is not None: albedo = self.transform(albedo)\n",
    "        if self.transform is not None: shading = self.transform(shading)\n",
    "\n",
    "        return img, albedo, shading\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "dataset= MyImageFolder(args.train_dir, \n",
    "                       transforms.Compose(\n",
    "        [transforms.RandomCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ))\n",
    "\n",
    "train_loader = data_utils.DataLoader(dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "[Defination](https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py)\n",
    "* DenseNet-121: num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16)\n",
    "    * First Convolution: 32M -> 16M -> 8M\n",
    "    * every transition: 8M -> 4M -> 2M (downsample 1/2, except the last block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-241335ed.pth\" to /home/cad/.torch/models/densenet121-241335ed.pth\n",
      "13.6%\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[Errno 104] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-72faf724a555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdensenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/lwp/workspace/anaconda3/lib/python3.6/site-packages/torchvision/models/densenet.py\u001b[0m in \u001b[0;36mdensenet121\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m                      **kwargs)\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_zoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_urls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'densenet121'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lwp/workspace/anaconda3/lib/python3.6/site-packages/torch/utils/model_zoo.py\u001b[0m in \u001b[0;36mload_url\u001b[0;34m(url, model_dir, map_location)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading: \"{}\" to {}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mhash_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHASH_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0m_download_url_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lwp/workspace/anaconda3/lib/python3.6/site-packages/torch/utils/model_zoo.py\u001b[0m in \u001b[0;36m_download_url_to_file\u001b[0;34m(url, dst, hash_prefix)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lwp/workspace/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lwp/workspace/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lwp/workspace/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lwp/workspace/anaconda3/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1002\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lwp/workspace/anaconda3/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lwp/workspace/anaconda3/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \"\"\"\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 104] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "densenet = models.__dict__[args.arch](pretrained=args.pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet (\n",
      "  (features): Sequential (\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu0): ReLU (inplace)\n",
      "    (pool0): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "    (denseblock1): _DenseBlock (\n",
      "      (denselayer1): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition (\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock (\n",
      "      (denselayer1): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition (\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock (\n",
      "      (denselayer1): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition (\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock (\n",
      "      (denselayer1): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (classifier): Linear (1024 -> 1000)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class PreTrainedModel(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(PreTrainedModel, self).__init__()\n",
    "        common_features_net = nn.Sequential(*list(pretrained.children())[0:1])\n",
    "        self.net_16M = nn.Sequential(OrderedDict([\n",
    "            ('conv0', common_features_net[0].conv0),\n",
    "            ('norm0', common_features_net[0].norm0),\n",
    "            ('relu0', common_features_net[0].relu0)\n",
    "        ]))\n",
    "        self.net_8M = nn.Sequential(OrderedDict([\n",
    "            ('pool0', common_features_net[0].pool0)\n",
    "        ]))\n",
    "        self.net_4M = nn.Sequential(OrderedDict([\n",
    "            ('denseblock1', common_features_net[0].denseblock1),\n",
    "            ('transition1', common_features_net[0].transition1)\n",
    "        ]))\n",
    "        self.net_2M = nn.Sequential(OrderedDict([\n",
    "            ('denseblock2', common_features_net[0].denseblock2),\n",
    "            ('transition2', common_features_net[0].transition2)\n",
    "        ]))\n",
    "        self.net_1M = nn.Sequential(OrderedDict([\n",
    "            ('denseblock3', common_features_net[0].denseblock3),\n",
    "            ('transition3', common_features_net[0].transition3),\n",
    "            ('denseblock4', common_features_net[0].denseblock4)\n",
    "        ]))\n",
    "    def forward(self, ft_32M):\n",
    "        \n",
    "        pretrained_features = [0]*5\n",
    "        pretrained_features[0] = self.net_16M(ft_32M)\n",
    "        pretrained_features[1]  = self.net_8M(pretrained_features[0])\n",
    "        pretrained_features[2]  = self.net_4M(pretrained_features[1])\n",
    "        pretrained_features[3]  = self.net_2M(pretrained_features[2])\n",
    "        pretrained_features[4]  = self.net_1M(pretrained_features[3])\n",
    "        return pretrained_features\n",
    "\n",
    "if args.debug == True:\n",
    "#     pass\n",
    "    print(densenet)\n",
    "#     common_features_net = nn.Sequential(*list(densenet.children())[0:1])\n",
    "#     net_x = nn.Sequential(OrderedDict([\n",
    "#             ('conv0', common_features_net[0].conv0),\n",
    "#     ]))\n",
    "    \n",
    "#     \"\"\"\n",
    "#         debug: copy/clone\n",
    "# #     \"\"\"\n",
    "# #     print net_x\n",
    "#     t = nn.Sequential(*list(net_x.children()))\n",
    "\n",
    "#     for param in _8M.parameters():\n",
    "#         print param.data\n",
    "\n",
    "#     for param in t.parameters():\n",
    "#         param.data = (param.data*2)\n",
    "#     print \"@@@@@@\"\n",
    "\n",
    "#     for param in t.parameters():\n",
    "#         print param.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.add_module('norm.1', nn.BatchNorm2d(num_input_features)),\n",
    "        self.add_module('relu.1', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv.1', nn.Conv2d(num_input_features, bn_size *\n",
    "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
    "        self.add_module('norm.2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "        self.add_module('relu.2', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv.2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                        kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super(_DenseLayer, self).forward(x)\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "\n",
    "class _MyTransition(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(_MyTransition, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module('pool', nn.AvgPool2d(kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "class GradientNet(nn.Module):\n",
    "    def build_blocks(self, num_block, num_init_features):\n",
    "        bn_size = 4\n",
    "        growth_rate = 32\n",
    "        drop_rate = 0\n",
    "        num_features = num_init_features\n",
    "        features = nn.Sequential()\n",
    "        for i, num_layers in enumerate(num_block):\n",
    "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
    "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "            features.add_module('denseblock%d' % (i + 1), block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            \n",
    "            trans = _MyTransition(num_input_features=num_features, num_output_features=num_features // 2)\n",
    "            features.add_module('transition%d' % (i + 1), trans)\n",
    "            num_features = num_features // 2\n",
    "        return features\n",
    "    \n",
    "    def __init__(self, pretrained_model):\n",
    "        super(GradientNet, self).__init__()\n",
    "        self.block_config = [(3,3,3),(6,6,6),(12,12,12),(16,16,16),(24,24,24)]\n",
    "        self.num_input_features = [64,64,128,256,1024]\n",
    "        self.upsample_config = [2,4,8,16,32]\n",
    "        self.pretrained_model = pretrained_model\n",
    "        \n",
    "        self.denseblocks = [0] * len(self.block_config)\n",
    "        for i in range(0, len(self.block_config)):\n",
    "            self.denseblocks[i] = self.build_blocks(self.block_config[i], self.num_input_features[i])\n",
    "        \n",
    "        self.upsamples = [0] * len(self.block_config)\n",
    "        stride = 2\n",
    "        self.num_upsample_input_features = [92,176,352,480,800]\n",
    "        for i in range(0, len(self.block_config)):\n",
    "            self.upsamples[i] = nn.ConvTranspose2d(in_channels=self.num_upsample_input_features[i], \n",
    "                                                   out_channels=3, kernel_size=self.upsample_config[i], \n",
    "                                    stride=stride, padding=0, \n",
    "                                                   output_padding=0, groups=1, bias=True, dilation=1)\n",
    "            stride = stride * 2\n",
    "        \n",
    "        self.merge = nn.Sequential()\n",
    "        self.merge_in_channels =  (3*len(self.block_config), 64, 32, 16)\n",
    "        self.merge_out_channels = (                      64, 32, 16,  3)\n",
    "        for i in range(0, len(self.merge_out_channels)): \n",
    "            self.merge.add_module('merge.conv{}'.format(i), \n",
    "                                  nn.Conv2d(in_channels=self.merge_in_channels[i], \n",
    "                                            out_channels=self.merge_out_channels[i], kernel_size=1))\n",
    "            self.merge.add_module('merge.relu{}'.format(i), nn.ReLU(inplace=True))\n",
    "                                    \n",
    "    def forward(self, ft_input):\n",
    "        ft_pretrained = self.pretrained_model(ft_input)\n",
    "#         if args.debug == True: \n",
    "#             for i,v in enumerate(ft_pretrained): \n",
    "#                 print '{}th ft_pretrained shape = {}'.format(i, v.data.shape)\n",
    "        ft_predict = [b(ft_pretrained[i]) for i, b in enumerate(self.denseblocks)]\n",
    "#         if args.debug == True: \n",
    "#             for i,v in enumerate(ft_predict): \n",
    "#                 print '{}th ft_predict shape = {}'.format(i, v.data.shape)\n",
    "        ft_upsampled = [up(ft_predict[i]) for i, up in enumerate(self.upsamples)]\n",
    "        ft_concated = torch.cat(ft_upsampled, 1)\n",
    "        ft_merged = self.merge(ft_concated)\n",
    "        ft_output = ft_upsampled + [ft_merged]\n",
    "        return ft_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer & Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained = PreTrainedModel(densenet)\n",
    "net = GradientNet(pretrained)\n",
    "mse_losses = [nn.MSELoss()] * 6\n",
    "optimizer = optim.SGD(net.parameters(), lr=args.base_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      " 16M loss = 0.0 8M loss = 0.0 4M loss = 0.0 2M loss = 0.0 1M loss = 0.45284 merged loss = 0.0\n",
      " 16M loss = 0.0 8M loss = 0.0 4M loss = 0.0 2M loss = 0.0 1M loss = 0.23155 merged loss = 0.0\n",
      " 16M loss = 0.0 8M loss = 0.0 4M loss = 0.0 2M loss = 0.0 1M loss = 0.141306 merged loss = 0.0\n",
      " 16M loss = 0.0 8M loss = 0.0 4M loss = 0.0 2M loss = 0.0 1M loss = 0.342299 merged loss = 0.0\n",
      " 16M loss = 0.0 8M loss = 0.0 4M loss = 0.0 2M loss = 0.0 1M loss = 0.221165 merged loss = 0.0\n",
      " 16M loss = 0.0 8M loss = 0.0 4M loss = 0.0 2M loss = 0.0 1M loss = 0.218716 merged loss = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/albertxavier/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/albertxavier/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/albertxavier/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/albertxavier/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/albertxavier/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/albertxavier/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/albertxavier/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-79693c24a80a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mrun_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mrun_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mloss_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epoches):\n",
    "    print('epoch: {}'.format(epoch))\n",
    "    run_losses = [0] * len(args.training_thresholds)\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        input_img, gt_albedo, gt_shading = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if platform.system() == 'Linux':\n",
    "            input_img = input_img.cuda()\n",
    "            gt_albedo = gt_albedo.cuda()\n",
    "            gt_shading = gt_shading.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        ft_predict = net(input_img)\n",
    "        run_losses = [Variable(torch.Tensor([0]))] * len(mse_losses)\n",
    "        for (i,threshold) in enumerate(args.training_thresholds):\n",
    "            if epoch >= threshold:\n",
    "                if i == 5: s = 1.\n",
    "                else: s = (2**(i+1))\n",
    "                gt = gt_albedo.data.numpy()\n",
    "                n,c,h,w = gt.shape\n",
    "                gt = gt[0,:,:,:]\n",
    "                gt = gt.transpose((1,2,0))\n",
    "                _, _, h2, w2 = ft_predict[i].data.numpy().shape\n",
    "                gt = cv2.resize(gt, (h2,w2))\n",
    "                gt = cv2.resize(gt, (h,w))\n",
    "                gt = gt.transpose((2,0,1))\n",
    "                gt = gt[np.newaxis, :]\n",
    "                gt = Variable(torch.from_numpy(gt))\n",
    "                run_losses[i] = mse_losses[i](ft_predict[i], gt)\n",
    "                run_losses[i].backward()\n",
    "        loss_output = ''\n",
    "        for i,v in enumerate(run_losses):\n",
    "            if i == len(run_losses)-1: \n",
    "                loss_output += ' merged loss = '+ str(run_losses[-1].data.numpy()[0])\n",
    "                continue\n",
    "            loss_output += ' %dM loss = '% (2**(4-i)) + str(run_losses[i].data.numpy()[0])\n",
    "        print(loss_output)\n",
    "        optimizer.step()\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'args' : args,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, 'snapshot.pth.tar'.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named graphviz",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7784240a69a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgraphviz\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDigraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named graphviz"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.creator)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
