{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as opti\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COnfigurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    pass\n",
    "args = Args()\n",
    "args.arch = \"densenet121\"\n",
    "args.train_dir = '/home/albertxavier/dataset/sintel/images/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Args' object has no attribute 'image_h'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5aa44a95a5b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m dataset= MyImageFolder(args.train_dir, \n\u001b[0;32m     46\u001b[0m                        transforms.Compose(\n\u001b[1;32m---> 47\u001b[1;33m         [transforms.RandomCrop((args.image_h, args.image_w)),\n\u001b[0m\u001b[0;32m     48\u001b[0m          transforms.ToTensor()]\n\u001b[0;32m     49\u001b[0m     ))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Args' object has no attribute 'image_h'"
     ]
    }
   ],
   "source": [
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "def make_dataset(dir):\n",
    "    images_paths = glob.glob(os.path.join(dir, 'clean', '*', '*.png'))\n",
    "    albedo_paths = images_paths[:]\n",
    "    shading_paths = images_paths[:]\n",
    "    pathes = []\n",
    "    for img_path in images_paths:\n",
    "        sp = img_path.split('/'); sp[-3] = 'albedo'; sp = ['/'] + sp; albedo_path = os.path.join(*sp)\n",
    "        sp = img_path.split('/'); sp[-3] = 'albedo'; sp = ['/'] + sp; shading_path = os.path.join(*sp)\n",
    "        pathes.append((img_path, albedo_path, shading_path))\n",
    "    return pathes\n",
    "\n",
    "class MyImageFolder(data_utils.Dataset):\n",
    "    def __init__(self, root, transform=None, target_transform=None,\n",
    "                loader=default_loader):\n",
    "        imgs = make_dataset(root)\n",
    "        if len(imgs) == 0:\n",
    "            raise(RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n",
    "                               \"Supported image extensions are: \" + \",\".join(args.img_extentions)))\n",
    "\n",
    "        self.root = root\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path, albedo_path, shading_path = self.imgs[index]\n",
    "        \n",
    "        img = self.loader(img_path)\n",
    "        albedo = self.loader(albedo_path)\n",
    "        shading = self.loader(shading_path)\n",
    "        \n",
    "        if self.transform is not None: img = self.transform(img)\n",
    "        if self.transform is not None: albedo = self.transform(albedo)\n",
    "        if self.transform is not None: shading = self.transform(shading)\n",
    "\n",
    "        return img, albedo, shading\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "dataset= MyImageFolder(args.train_dir, \n",
    "                       transforms.Compose(\n",
    "        [transforms.RandomCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ))\n",
    "\n",
    "train_loader =data_utils.DataLoader(dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'densenet161'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ce76c4ab0c9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# densenet = models.__dict__[args.arch](pretrained=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdensenet161\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# densenet = models.__dict__[\"resnet18\"](pretrained=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'densenet161'"
     ]
    }
   ],
   "source": [
    "# densenet = models.__dict__[args.arch](pretrained=True)\n",
    "print models.densenet161(pretrained=True)\n",
    "# densenet = models.__dict__[\"resnet18\"](pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My nn Modules\n",
    "class PretainedModel(nn.Module):\n",
    "    def __init__(self, original_model, arch):\n",
    "        if arch == \"densenet121\":\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named graphviz",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7784240a69a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgraphviz\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDigraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named graphviz"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.creator)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
