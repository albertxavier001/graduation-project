{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, platform, datetime, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import functional as F\n",
    "# import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc\n",
    "\n",
    "from myimagefoldereccv import MyImageFolder\n",
    "from mymodel import GradientNet\n",
    "from myargs import Args\n",
    "from myutils import MyUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myutils = MyUtils()\n",
    "\n",
    "args = Args()\n",
    "args.arch = \"densenet121\"\n",
    "args.epoches = 500\n",
    "args.epoches_unary_threshold = 0\n",
    "args.image_h = 256\n",
    "args.image_w = 256\n",
    "args.img_extentions = [\"png\"]\n",
    "args.training_thresholds = [250,200,150,50,0,300]\n",
    "args.base_lr = 1\n",
    "args.lr = args.base_lr\n",
    "args.snapshot_interval = 5000\n",
    "args.debug = True\n",
    "\n",
    "\n",
    "# growth_rate = (4*(2**(args.gpu_num)))\n",
    "transition_scale=2\n",
    "pretrained_scale=4\n",
    "growth_rate = 32\n",
    "\n",
    "#######\n",
    "args.test_scene = ['alley_1', 'bamboo_1', 'bandage_1', 'cave_2', 'market_2', 'market_6', 'shaman_2', 'sleeping_1', 'temple_2']\n",
    "gradient=False\n",
    "args.gpu_num = 0\n",
    "#######\n",
    "\n",
    "writer_comment = 'eccv_albedo'\n",
    "\n",
    "\n",
    "offset = 0.\n",
    "if gradient == True: offset = 0.5\n",
    "\n",
    "args.display_interval = 50\n",
    "args.display_curindex = 0\n",
    "\n",
    "system_ = platform.system()\n",
    "system_dist, system_version, _ = platform.dist()\n",
    "if system_ == \"Darwin\": \n",
    "    args.train_dir = '/Volumes/Transcend/dataset/sintel2'\n",
    "    args.pretrained = False\n",
    "elif platform.dist() ==  ('debian', 'jessie/sid', ''):\n",
    "    args.train_dir = '/home/albertxavier/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "elif platform.dist() == ('debian', 'stretch/sid', ''):\n",
    "    args.train_dir = '/home/cad/lwp/workspace/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "\n",
    "if platform.system() == 'Linux': use_gpu = True\n",
    "else: use_gpu = False\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.gpu_num)\n",
    "    \n",
    "\n",
    "print(platform.dist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = MyImageFolder(args.train_dir, 'train',\n",
    "                       transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ), random_crop=True, \n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "test_dataset = MyImageFolder(args.train_dir, 'test', \n",
    "                       transforms.Compose(\n",
    "        [transforms.CenterCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ), random_crop=False,\n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset,1,True,num_workers=1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "[Defination](https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py)\n",
    "* DenseNet-121: num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16)\n",
    "    * First Convolution: 32M -> 16M -> 8M\n",
    "    * every transition: 8M -> 4M -> 2M (downsample 1/2, except the last block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenet = models.__dict__[args.arch](pretrained=args.pretrained)\n",
    "\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if use_gpu: densenet.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "args.display_curindex = 0\n",
    "args.base_lr = 0.01\n",
    "args.display_interval = 20\n",
    "args.momentum = 0.9\n",
    "args.epoches = 240\n",
    "args.training_thresholds = 240//4\n",
    "args.power = 0.5\n",
    "\n",
    "\n",
    "\n",
    "net = GradientNet(densenet=densenet, growth_rate=growth_rate, \n",
    "                  transition_scale=transition_scale, pretrained_scale=pretrained_scale,\n",
    "                 gradient=gradient)\n",
    "if use_gpu:\n",
    "    net.cuda()\n",
    "\n",
    "mse_losses = nn.MSELoss()\n",
    "mse_losses_dx = nn.MSELoss()\n",
    "mse_losses_dy = nn.MSELoss()\n",
    "if use_gpu:\n",
    "    mse_losses = nn.MSELoss().cuda()\n",
    "    mse_losses_dx = nn.MSELoss().cuda()\n",
    "    mse_losses_dy = nn.MSELoss().cuda()\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "optimizer = optim.SGD(parameters, lr=args.base_lr, momentum=args.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_eval_model_per_epoch(epoch, net, args, train_loader, test_loader, phase='train'):\n",
    "    if phase == 'train':\n",
    "        volatile = False\n",
    "        net.train()\n",
    "    else:\n",
    "        volatile = True\n",
    "#         net.eval()\n",
    "        net.train()\n",
    "    \n",
    "    print('epoch: {} [{}]'.format(epoch, datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "    \"\"\"adjust learning rate\"\"\"\n",
    "    if epoch < args.training_thresholds: \n",
    "        myutils.adjust_learning_rate(optimizer, args, epoch, beg=0, end=args.training_thresholds-1)\n",
    "    else:\n",
    "        myutils.adjust_learning_rate(optimizer, args, epoch, beg=args.training_thresholds, end=args.epoches)\n",
    "    writer.add_scalar('learning rate', optimizer.param_groups[0]['lr'], global_step=epoch)\n",
    "\n",
    "    \"\"\"init statics\"\"\"\n",
    "    run_losses_unary = 0.\n",
    "    run_losses_dx = 0.\n",
    "    run_losses_dy = 0.\n",
    "    run_cnts   = 0.00001\n",
    "\n",
    "    \"\"\"for all training/test data\"\"\"\n",
    "    loader = train_loader if phase == 'train' else test_loader\n",
    "    \n",
    "    for ind, data in enumerate(loader, 0):\n",
    "        \"\"\"prepare data\"\"\"\n",
    "        input_img, gt_albedo, gt_shading, cur_scene, img_path = data\n",
    "        cur_frame = img_path[0].split('/')[-1]\n",
    "        input_img = Variable(input_img, volatile=volatile)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu: \n",
    "            input_img, gt_albedo, gt_shading = input_img.cuda(), gt_albedo.cuda(), gt_shading.cuda()\n",
    "        \n",
    "        if phase == 'train':\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        res = net(input_img)\n",
    "        \n",
    "        \"\"\"prepare gradient\"\"\"\n",
    "        gt_dx = myutils.makeGradientTorch(gt_albedo, direction='x')\n",
    "        gt_dy = myutils.makeGradientTorch(gt_albedo, direction='y')\n",
    "        res_dx = myutils.makeGradientTorch(res, direction='x')\n",
    "        res_dy = myutils.makeGradientTorch(res, direction='y')\n",
    "        \n",
    "        \"\"\"compute loss\"\"\"\n",
    "        if phase == 'train':\n",
    "            \"\"\"unary loss\"\"\"\n",
    "            loss_unary = mse_losses(res, gt_albedo)\n",
    "            loss_dx = mse_losses(2*res_dx, 2*gt_dx)\n",
    "            loss_dy = mse_losses(2*res_dy, 2*gt_dy)\n",
    "            \n",
    "            run_losses_unary += loss_unary.data.cpu().numpy()[0]\n",
    "            run_losses_dx += loss_dx.data.cpu().numpy()[0]\n",
    "            run_losses_dy += loss_dy.data.cpu().numpy()[0]\n",
    "            \n",
    "            run_cnts += 1\n",
    "\n",
    "        \"\"\"backward\"\"\"\n",
    "        if phase == 'train':\n",
    "            loss_unary.backward(retain_graph=True)\n",
    "            loss_dx.backward(retain_graph=True)\n",
    "            loss_dy.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "        \n",
    "        \"\"\"generate display img\"\"\"\n",
    "        display_im = myutils.tensor2Numpy(input_img)[:,:,::-1]*255\n",
    "        display_gt = myutils.tensor2Numpy(gt_albedo)[:,:,::-1]*255\n",
    "        display_res = myutils.tensor2Numpy(res)[:,:,::-1]*255\n",
    "\n",
    "        \"\"\"display\"\"\"\n",
    "        if (phase == 'train' and args.display_curindex % args.display_interval == 0) or \\\n",
    "        (phase == 'test' and cur_scene == 'alley_1' and cur_frame == 'frame_0001.png'):\n",
    "            # print('display ', phase, img_path, display_im.shape)\n",
    "            cv2.imwrite('snapshot{}/input.png'.format(args.gpu_num), display_im)\n",
    "            cv2.imwrite('snapshot{}/{}-gt-{}.png'.format(args.gpu_num, phase, epoch), display_gt) \n",
    "            cv2.imwrite('snapshot{}/{}-rs-{}.png'.format(args.gpu_num, phase, epoch), display_res)\n",
    "        \n",
    "        args.display_curindex += 1\n",
    "    \n",
    "    \"\"\"output loss\"\"\"\n",
    "    loss_output = ''\n",
    "    loss_output += '{} loss: '.format(phase)\n",
    "    loss_output += 'unary: %6f ' % (run_losses_unary/run_cnts)\n",
    "    loss_output += 'pairwise: %6f ' % ((run_losses_dx+run_losses_dy)/run_cnts)\n",
    "    loss_output += 'crf: %6f' % ((run_losses_unary+run_losses_dx+run_losses_dy)/run_cnts)\n",
    "    print(loss_output)\n",
    "    \n",
    "    \"\"\"write to tensorboard\"\"\"\n",
    "    writer.add_scalars('loss', {phase: np.array([(run_losses_unary+run_losses_dx+run_losses_dy)/run_cnts])}, global_step=epoch)\n",
    "    \n",
    "    \"\"\"save snapshot\"\"\"\n",
    "    if phase == 'train':\n",
    "        myutils.save_snapshot(epoch, args, net, optimizer)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"training loop\"\"\"\n",
    "writer = SummaryWriter(comment='-{}'.format(writer_comment))\n",
    "\n",
    "for epoch in range(args.epoches):\n",
    "    phase = 'test' if (epoch+1) % 5 == 0 else 'train'\n",
    "    train_eval_model_per_epoch(epoch, net, args, train_loader, test_loader, phase=phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = Variable(torch.zeros(1,3,256,256))\n",
    "# y = net(x.cuda())\n",
    "# g = make_dot(y[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g.render('net-transition_scale_{}'.format(transition_scale)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
