{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, platform, datetime, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import functional as F\n",
    "# import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc\n",
    "\n",
    "from myimagefoldereccv import MyImageFolder\n",
    "from mymodel import GradientNet\n",
    "from myargs import Args\n",
    "from myutils import MyUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myutils = MyUtils()\n",
    "\n",
    "args = Args()\n",
    "args.arch = \"densenet121\"\n",
    "args.epoches = 500\n",
    "args.epoches_unary_threshold = 0\n",
    "args.image_h = 256\n",
    "args.image_w = 256\n",
    "args.img_extentions = [\"png\"]\n",
    "args.training_thresholds = [250,200,150,50,0,300]\n",
    "args.base_lr = 1\n",
    "args.lr = args.base_lr\n",
    "args.snapshot_interval = 5000\n",
    "args.debug = True\n",
    "\n",
    "\n",
    "# growth_rate = (4*(2**(args.gpu_num)))\n",
    "transition_scale=2\n",
    "pretrained_scale=4\n",
    "growth_rate = 32\n",
    "\n",
    "#######\n",
    "args.test_scene = ['alley_1', 'bamboo_1', 'bandage_1', 'cave_2', 'market_2', 'market_6', 'shaman_2', 'sleeping_1', 'temple_2']\n",
    "gradient=False\n",
    "args.gpu_num = 0\n",
    "#######\n",
    "\n",
    "writer_comment = '{}_rgb_shading'.format(args.test_scene)\n",
    "if gradient == True:\n",
    "    writer_comment = '{}_gd_shading'.format(args.test_scene)\n",
    "\n",
    "offset = 0.\n",
    "if gradient == True: offset = 0.5\n",
    "\n",
    "args.display_interval = 50\n",
    "args.display_curindex = 0\n",
    "\n",
    "system_ = platform.system()\n",
    "system_dist, system_version, _ = platform.dist()\n",
    "if system_ == \"Darwin\": \n",
    "    args.train_dir = '/Volumes/Transcend/dataset/sintel2'\n",
    "    args.pretrained = False\n",
    "elif platform.dist() ==  ('debian', 'jessie/sid', ''):\n",
    "    args.train_dir = '/home/lwp/workspace/sintel2'\n",
    "    args.pretrained = True\n",
    "elif platform.dist() == ('debian', 'stretch/sid', ''):\n",
    "    args.train_dir = '/home/cad/lwp/workspace/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "\n",
    "if platform.system() == 'Linux': use_gpu = True\n",
    "else: use_gpu = False\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.gpu_num)\n",
    "    \n",
    "\n",
    "print(platform.dist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = MyImageFolder(args.train_dir, 'train',\n",
    "                       transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ), random_crop=True, \n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "test_dataset = MyImageFolder(args.train_dir, 'test', \n",
    "                       transforms.Compose(\n",
    "        [transforms.CenterCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ), random_crop=False,\n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset,1,True,num_workers=1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "[Defination](https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py)\n",
    "* DenseNet-121: num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16)\n",
    "    * First Convolution: 32M -> 16M -> 8M\n",
    "    * every transition: 8M -> 4M -> 2M (downsample 1/2, except the last block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenet = models.__dict__[args.arch](pretrained=args.pretrained)\n",
    "\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if use_gpu: densenet.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "args.display_curindex = 0\n",
    "args.base_lr = 0.05\n",
    "args.display_interval = 20\n",
    "args.momentum = 0.9\n",
    "args.epoches = 240\n",
    "args.training_thresholds = 240//3*2\n",
    "args.power = 0.5\n",
    "\n",
    "\n",
    "\n",
    "net = GradientNet(densenet=densenet, growth_rate=growth_rate, \n",
    "                  transition_scale=transition_scale, pretrained_scale=pretrained_scale,\n",
    "                 gradient=gradient)\n",
    "if use_gpu:\n",
    "    net.cuda()\n",
    "\n",
    "mse_losses = nn.MSELoss()\n",
    "mse_losses_dx = nn.MSELoss()\n",
    "mse_losses_dy = nn.MSELoss()\n",
    "if use_gpu:\n",
    "    mse_losses = nn.MSELoss().cuda()\n",
    "    mse_losses_dx = nn.MSELoss().cuda()\n",
    "    mse_losses_dy = nn.MSELoss().cuda()\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "optimizer = optim.SGD(parameters, lr=args.base_lr, momentum=args.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment='-{}'.format(writer_comment))\n",
    "\n",
    "def train_eval_model_per_epoch(epoch, net, args, train_loader, test_loader, phase='train'):\n",
    "    if phase == 'train':\n",
    "        volatile = False\n",
    "        net.train()\n",
    "    else:\n",
    "        volatile = True\n",
    "#         net.eval()\n",
    "        net.train()\n",
    "    \n",
    "    print('epoch: {} [{}]'.format(epoch, datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "    \"\"\"adjust learning rate\"\"\"\n",
    "    if epoch < args.training_thresholds: \n",
    "        myutils.adjust_learning_rate(optimizer, epoch, beg=0, end=args.training_thresholds-1)\n",
    "    else:\n",
    "        myutils.adjust_learning_rate(optimizer, epoch, beg=args.training_thresholds, end=args.epoches, base_lr=args.base_lr)\n",
    "    writer.add_scalar('learning rate', optimizer.param_groups[0]['lr'], global_step=epoch)\n",
    "\n",
    "    \"\"\"init statics\"\"\"\n",
    "    run_losses_unary = 0.\n",
    "    run_losses_dx = 0.\n",
    "    run_losses_dy = 0.\n",
    "    run_cnts   = 0.00001\n",
    "\n",
    "    \"\"\"for all training/test data\"\"\"\n",
    "    loader = train_loader if phase == 'train' else test_loader\n",
    "    \n",
    "    for ind, data in enumerate(loader, 0):\n",
    "        \"\"\"prepare data\"\"\"\n",
    "        input_img, gt_albedo, gt_shading, cur_scene, img_path = data\n",
    "        cur_frame = img_path.split('/')[-1]\n",
    "        input_img = Variable(input_img, volatile=volatile)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu: \n",
    "            input_img, gt_albedo, gt_shading = input_img.cuda(), gt_albedo.cuda(), gt_shading.cuda()\n",
    "        \n",
    "        if phase == 'train':\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        res = net(input_img)\n",
    "        \n",
    "        \"\"\"prepare gradient\"\"\"\n",
    "        gt_dx = myutils.makeGradientTorch(gt, direction='x')\n",
    "        gt_dy = myutils.makeGradientTorch(gt, direction='y')\n",
    "        res_dx = myutils.makeGradientTorch(res, direction='x')\n",
    "        res_dy = myutils.makeGradientTorch(res, direction='y')\n",
    "        \n",
    "        \"\"\"compute loss\"\"\"\n",
    "        if phase == 'train':\n",
    "            \"\"\"unary loss\"\"\"\n",
    "            loss_unary = mse_losses(res, gt)\n",
    "            run_losses_unary = loss_unary.data.cpu().numpy()[0]\n",
    "            \n",
    "            loss_dx = mse_losses(res_dx, gt_dx)\n",
    "            loss_dy = mse_losses(res_dy, gt_dy)\n",
    "            \n",
    "            run_losses_unary = loss_unary.data.cpu().numpy()[0]\n",
    "            run_losses_dx = loss_dx.data.cpu().numpy()[0]\n",
    "            run_losses_dy = loss_dy.data.cpu().numpy()[0]\n",
    "            \n",
    "            run_cnts += 1\n",
    "\n",
    "        \"\"\"backward\"\"\"\n",
    "        if phase == 'train':\n",
    "            loss_unary.backward(retain_graph=True)\n",
    "            loss_dx.backward(retain_graph=True)\n",
    "            loss_dy.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "        \n",
    "        args.display_curindex += 1\n",
    "    \n",
    "    \"\"\"output loss\"\"\"\n",
    "    loss_output = ''\n",
    "    loss_unary += '{} loss: '.format(phase)\n",
    "    loss_output += 'unary: %6f' % (run_losses_unary/run_cnts)\n",
    "    loss_output += 'pairwise: %6f' % ((run_losses_dx+run_losses_dy)/run_cnts)\n",
    "    loss_output += 'crf: %6f' % ((run_losses_unary+run_losses_dx+run_losses_dy)/run_cnts)\n",
    "    print(loss_output)\n",
    "    \n",
    "    \"\"\"write to tensorboard\"\"\"\n",
    "    writer.add_scalars('loss', {phase: np.array([run_losses/run_cnts])}, global_step=epoch)\n",
    "    \n",
    "    \"\"\"save snapshot\"\"\"\n",
    "    if phase == 'train':\n",
    "        myutils.save_snapshot(epoch, args, net, optimizer)\n",
    "    \n",
    "    \"\"\"generate display img\"\"\"\n",
    "    display_im = input_img.cpu().data.numpy()[:,:,::-1]*255\n",
    "    display_gt = gt_albedo.cpu().data.numpy()[:,:,::-1]*255\n",
    "    display_res = res.cpu().data.numpy()[:,:,::-1]*255\n",
    "\n",
    "    \"\"\"display\"\"\"\n",
    "    if (phase == 'train' and args.display_curindex % args.display_interval == 0) or \\\n",
    "    (phase == 'test' and cur_scene == 'alley_1' and cur_frame == 'frame_0001.png'):\n",
    "        cv2.imwrite('snapshot{}/input.png'.format(args.gpu_num), display_im)\n",
    "        cv2.imwrite('snapshot{}/{}-gt-{}-{}.png'.format(phase, args.gpu_num, epoch, i), display_gt) \n",
    "        cv2.imwrite('snapshot{}/{}-rs-{}-{}.png'.format(phase, args.gpu_num, epoch, i), display_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"training loop\"\"\"\n",
    "for epoch in range(args.epoches):\n",
    "    phase = 'test' if (epoch+1) % 5 == 0 else 'train'\n",
    "    train_eval_model_per_epoch(epoch, net, args, train_loader, test_loader, phase=phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"10240,10240\"), format='svg')\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = Variable(torch.zeros(1,3,256,256))\n",
    "# y = net(x.cuda())\n",
    "# g = make_dot(y[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g.render('net-transition_scale_{}'.format(transition_scale)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
