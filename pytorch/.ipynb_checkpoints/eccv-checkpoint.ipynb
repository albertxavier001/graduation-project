{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, platform, datetime, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "# from torch import functional as F\n",
    "import torch.nn.functional as F\n",
    "# import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc\n",
    "\n",
    "from myimagefoldereccv import MyImageFolder\n",
    "from mymodel import GradientNet\n",
    "from myargs import Args\n",
    "from myutils import MyUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myutils = MyUtils()\n",
    "\n",
    "args = Args()\n",
    "args.arch = \"densenet121\"\n",
    "args.epoches = 500\n",
    "args.epoches_unary_threshold = 0\n",
    "args.image_h = 256\n",
    "args.image_w = 256\n",
    "args.img_extentions = [\"png\"]\n",
    "args.training_thresholds = [250,200,150,50,0,300]\n",
    "args.base_lr = 1\n",
    "args.lr = args.base_lr\n",
    "args.snapshot_interval = 5000\n",
    "args.debug = True\n",
    "\n",
    "\n",
    "# growth_rate = (4*(2**(args.gpu_num)))\n",
    "transition_scale=2\n",
    "pretrained_scale=4\n",
    "growth_rate = 32\n",
    "\n",
    "#######\n",
    "args.test_scene = ['alley_1', 'bamboo_1', 'bandage_1', 'cave_2', 'market_2', 'market_6', 'shaman_2', 'sleeping_1', 'temple_2']\n",
    "gradient=False\n",
    "args.gpu_num = 0\n",
    "#######\n",
    "\n",
    "writer_comment = 'eccv_albedo'\n",
    "\n",
    "\n",
    "offset = 0.\n",
    "if gradient == True: offset = 0.5\n",
    "\n",
    "args.display_interval = 50\n",
    "args.display_curindex = 0\n",
    "\n",
    "system_ = platform.system()\n",
    "system_dist, system_version, _ = platform.dist()\n",
    "if system_ == \"Darwin\": \n",
    "    args.train_dir = '/Volumes/Transcend/dataset/sintel2'\n",
    "    args.pretrained = False\n",
    "    args.image_w, args.image_h = 32, 32\n",
    "elif platform.dist() ==  ('debian', 'jessie/sid', ''):\n",
    "    args.train_dir = '/home/albertxavier/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "elif platform.dist() == ('debian', 'stretch/sid', ''):\n",
    "    args.train_dir = '/home/cad/lwp/workspace/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "\n",
    "if platform.system() == 'Linux': use_gpu = True\n",
    "else: use_gpu = False\n",
    "\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.gpu_num)\n",
    "    \n",
    "\n",
    "print(platform.dist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = MyImageFolder(args.train_dir, 'train',\n",
    "                       transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ), random_crop=True, \n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "test_dataset = MyImageFolder(args.train_dir, 'test', \n",
    "                       transforms.Compose(\n",
    "        [transforms.CenterCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ), random_crop=False,\n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset,1,True,num_workers=1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "[Defination](https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py)\n",
    "* DenseNet-121: num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16)\n",
    "    * First Convolution: 32M -> 16M -> 8M\n",
    "    * every transition: 8M -> 4M -> 2M (downsample 1/2, except the last block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenet = models.__dict__[args.arch](pretrained=args.pretrained)\n",
    "\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if use_gpu: densenet.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "args.display_curindex = 0\n",
    "args.base_lr = 0.01\n",
    "args.display_interval = 20\n",
    "args.momentum = 0.9\n",
    "args.epoches = int(60*4)\n",
    "#args.training_thresholds = 240//4\n",
    "args.power = 0.5\n",
    "\n",
    "\n",
    "\n",
    "net = GradientNet(densenet=densenet, growth_rate=growth_rate, \n",
    "                  transition_scale=transition_scale, pretrained_scale=pretrained_scale,\n",
    "                 gradient=gradient)\n",
    "if use_gpu:\n",
    "    net.cuda()\n",
    "\n",
    "mse_loss = nn.MSELoss().cuda() if use_gpu==True else nn.MSELoss()\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "optimizer = optim.SGD(parameters, lr=args.base_lr, momentum=args.momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_y(predict_unary, predict_dx, predict_dy, gt, predict_alpha, predict_beta, max_iter=100, eps=1.e-6, use_gpu=True):\n",
    "    def generate_y_(last_y, predict_unary, predict_dx, predict_dy, gt, predict_alpha, predict_beta, use_gpu=True):\n",
    "        def prepare_fileters(direction='up'):\n",
    "            filters = torch.Tensor(torch.zeros(3,3,3,3))\n",
    "            if direction == 'up': \n",
    "                for i in range(3): filters[i,i,0,1] = 1.\n",
    "            elif direction == 'down': \n",
    "                for i in range(3): filters[i,i,2,1] = 1.\n",
    "            elif direction == 'left': \n",
    "                for i in range(3): filters[i,i,1,0] = 1.\n",
    "            else: \n",
    "                for i in range(3): filters[i,i,1,2] = 1.\n",
    "            filters = Variable(filters)\n",
    "            if use_gpu == True: filters = filters.cuda()\n",
    "            return filters\n",
    "\n",
    "        f_up = prepare_fileters(direction='up')\n",
    "        f_down = prepare_fileters(direction='down')\n",
    "        f_left = prepare_fileters(direction='left')\n",
    "        f_right = prepare_fileters(direction='right')\n",
    "\n",
    "        last_y_up = F.conv2d(last_y, f_up, padding=1)\n",
    "        last_y_down = F.conv2d(last_y, f_down, padding=1)\n",
    "        last_y_left = F.conv2d(last_y, f_left, padding=1)\n",
    "        last_y_right = F.conv2d(last_y, f_right, padding=1)\n",
    "        \n",
    "        t_up = -F.conv2d(predict_dy, f_up, padding=1)\n",
    "        t_down = predict_dy\n",
    "        t_left = -F.conv2d(predict_dx, f_left, padding=1)\n",
    "        t_right = predict_dx\n",
    "        \n",
    "        beta_up = predict_beta[:,0,:,:]\n",
    "        beta_down = predict_beta[:,1,:,:]\n",
    "        beta_left = predict_beta[:,2,:,:]\n",
    "        beta_right = predict_beta[:,3,:,:]\n",
    "        \n",
    "        y = predict_alpha * predict_unary\n",
    "\n",
    "        y = y + beta_up * (last_y_up + t_up) # up\n",
    "        y = y + beta_down * (last_y_down + t_down) # down\n",
    "        y = y + beta_left * (last_y_left + t_left) # left\n",
    "        y = y + beta_right * (last_y_right + t_right) # right\n",
    "\n",
    "        constant = torch.sum(predict_alpha)+torch.sum(predict_beta)\n",
    "        y = y / constant\n",
    "        return y\n",
    "    \n",
    "    predict_unary = predict_unary.clone()\n",
    "    predict_dx = predict_dx.clone()\n",
    "    predict_dy = predict_dy.clone()\n",
    "    \n",
    "    y = Variable(predict_unary.cpu().data.clone(), requires_grad=False)\n",
    "    if use_gpu == True: y = y.cuda()\n",
    "    iters = 0\n",
    "    while 1:\n",
    "        last_y = y.clone()\n",
    "        y = generate_y_(y, predict_unary, predict_dx, predict_dy, gt, predict_alpha, predict_beta, use_gpu=use_gpu)\n",
    "        cur_loss = myutils.mse_loss_scalar(y, last_y)\n",
    "        if cur_loss <= eps: break\n",
    "        if iters >= max_iter: break\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_eval_model_per_epoch(epoch, net, args, train_loader, test_loader, phase='train'):\n",
    "    if phase == 'train':\n",
    "        volatile = False\n",
    "        net.train()\n",
    "    else:\n",
    "        volatile = True\n",
    "#         net.eval()\n",
    "        net.train()\n",
    "    \n",
    "    print('epoch: {} [{}]'.format(epoch, datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "    \"\"\"adjust learning rate\"\"\"\n",
    "    myutils.adjust_learning_rate(optimizer, args, epoch, beg=0, end=args.epoches)\n",
    "    #if epoch < args.training_thresholds: \n",
    "    #    myutils.adjust_learning_rate(optimizer, args, epoch, beg=0, end=args.training_thresholds-1)\n",
    "    #else:\n",
    "    #    myutils.adjust_learning_rate(optimizer, args, epoch, beg=args.training_thresholds, end=args.epoches)\n",
    "    writer.add_scalar('learning rate', optimizer.param_groups[0]['lr'], global_step=epoch)\n",
    "\n",
    "    \"\"\"init statics\"\"\"\n",
    "    run_loss_unary = 0.\n",
    "    run_loss_dx = 0.\n",
    "    run_loss_dy = 0.\n",
    "    run_loss_y = 0.\n",
    "    run_cnt   = 0.00001\n",
    "\n",
    "    \"\"\"for all training/test data\"\"\"\n",
    "    loader = train_loader if phase == 'train' else test_loader\n",
    "    \n",
    "    for ind, data in enumerate(loader, 0):\n",
    "        \"\"\"prepare data\"\"\"\n",
    "        input_img, gt_albedo, gt_shading, cur_scene, img_path = data\n",
    "        (cur_scene,) = cur_scene\n",
    "        (img_path,) = img_path\n",
    "        cur_frame = img_path.split('/')[-1]\n",
    "        input_img = Variable(input_img, volatile=volatile)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu: \n",
    "            input_img, gt_albedo, gt_shading = input_img.cuda(), gt_albedo.cuda(), gt_shading.cuda()\n",
    "        \n",
    "        \"\"\"prepare gradient\"\"\"\n",
    "        gt_dx = myutils.makeGradientTorch(gt_albedo, direction='x', use_gpu=use_gpu)\n",
    "        gt_dy = myutils.makeGradientTorch(gt_albedo, direction='y', use_gpu=use_gpu)\n",
    "        \n",
    "        if phase == 'train':\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        predict_all = net(input_img)\n",
    "        predict_unary = predict_all[:,0:3,:,:]\n",
    "        predict_dx = predict_all[:,3:6,:,:]\n",
    "        predict_dy = predict_all[:,6:9,:,:]\n",
    "        predict_alpha = predict_all[:,9,:,:] + 100.\n",
    "        predict_beta = predict_all[:,9:13,:,:] + 100.\n",
    "        \n",
    "        \"\"\"prepare crf y\"\"\"\n",
    "        y = generate_y(predict_unary, predict_dx, predict_dy, gt_albedo, predict_alpha, predict_beta, use_gpu=use_gpu)\n",
    "        \n",
    "        \"\"\"prepare final gt\"\"\"\n",
    "        predict_final = torch.cat([predict_all[:,0:3+6,:,:], y], 1)\n",
    "        gt_final = torch.cat([gt_albedo, gt_dx, gt_dy, gt_albedo], 1)\n",
    "        \n",
    "        \"\"\"compute loss\"\"\"\n",
    "        loss = mse_loss(predict_final, gt_final)\n",
    "        \n",
    "        run_loss_unary += myutils.mse_loss_scalar(predict_unary, gt_albedo)\n",
    "        run_loss_dx += myutils.mse_loss_scalar(predict_dx, gt_dx)\n",
    "        run_loss_dy += myutils.mse_loss_scalar(predict_dy, gt_dy)\n",
    "        run_loss_y += myutils.mse_loss_scalar(y, gt_albedo)\n",
    "        run_cnt += 1\n",
    "\n",
    "        \"\"\"backward\"\"\"\n",
    "        if phase == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        \"\"\"generate display img\"\"\"\n",
    "        display_im = myutils.tensor2Numpy(input_img)[:,:,::-1]*255\n",
    "        display_gt_albedo = myutils.tensor2Numpy(gt_albedo)[:,:,::-1]*255\n",
    "        display_gt_dx = (myutils.tensor2Numpy(gt_dx)[:,:,::-1]+0.5)*255\n",
    "        display_gt_dy = (myutils.tensor2Numpy(gt_dy)[:,:,::-1]+0.5)*255\n",
    "        display_unary = myutils.tensor2Numpy(predict_unary)[:,:,::-1]*255\n",
    "        display_dx = (myutils.tensor2Numpy(predict_dx)[:,:,::-1]+0.5)*255\n",
    "        display_dy = (myutils.tensor2Numpy(predict_dy)[:,:,::-1]+0.5)*255\n",
    "\n",
    "        \"\"\"display\"\"\"\n",
    "        if (phase == 'train' and args.display_curindex % args.display_interval == 0) or \\\n",
    "        (phase == 'test' and cur_scene == 'alley_1' and cur_frame == 'frame_0001.png'):\n",
    "            # print('display ', phase, img_path, display_im.shape)\n",
    "            cv2.imwrite('snapshot{}/input.png'.format(args.gpu_num), display_im)\n",
    "            cv2.imwrite('snapshot{}/{}-gt-{}-unary.png'.format(args.gpu_num, phase, epoch), display_gt_albedo) \n",
    "            cv2.imwrite('snapshot{}/{}-gt-{}-dx.png'.format(args.gpu_num, phase, epoch), display_gt_dx) \n",
    "            cv2.imwrite('snapshot{}/{}-gt-{}-dy.png'.format(args.gpu_num, phase, epoch), display_gt_dy) \n",
    "            cv2.imwrite('snapshot{}/{}-rs-{}-unary.png'.format(args.gpu_num, phase, epoch), display_unary)\n",
    "            cv2.imwrite('snapshot{}/{}-rs-{}-dx.png'.format(args.gpu_num, phase, epoch), display_dx)\n",
    "            cv2.imwrite('snapshot{}/{}-rs-{}-dy.png'.format(args.gpu_num, phase, epoch), display_dy)\n",
    "        \n",
    "        args.display_curindex += 1\n",
    "    \n",
    "    \"\"\"output loss\"\"\"\n",
    "    loss_output = ''\n",
    "    loss_output += '{} loss: '.format(phase)\n",
    "    loss_output += 'unary: %6f ' % (run_loss_unary/run_cnt)\n",
    "    loss_output += 'pairwise: %6f ' % ((run_loss_dx+run_loss_dy)/run_cnt)\n",
    "    loss_output += 'crf: %6f ' % ((run_loss_unary+run_loss_dx+run_loss_dy)/run_cnt)\n",
    "    loss_output += 'y: %6f ' % (run_loss_y/run_cnt)\n",
    "    \n",
    "    print(loss_output)\n",
    "    \n",
    "    \"\"\"write to tensorboard\"\"\"\n",
    "    writer.add_scalars('loss', {\n",
    "        '%s unary loss'% (phase): np.array([run_loss_unary/run_cnt]),\n",
    "        '%s dx loss'% (phase): np.array([run_loss_dx/run_cnt]),\n",
    "        '%s dy loss'% (phase): np.array([run_loss_dy/run_cnt]),\n",
    "        '%s pairwise loss'% (phase): np.array([(run_loss_dx+run_loss_dy)/run_cnt]),\n",
    "        '%s y loss'% (phase): np.array([run_loss_y/run_cnt]),\n",
    "    }, global_step=epoch)\n",
    "    \n",
    "    \"\"\"save snapshot\"\"\"\n",
    "    if phase == 'train':\n",
    "        myutils.save_snapshot(epoch, args, net, optimizer)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"training loop\"\"\"\n",
    "writer = SummaryWriter(comment='-{}'.format(writer_comment))\n",
    "\n",
    "for epoch in range(args.epoches):\n",
    "    phase = 'test' if epoch == 0 or (epoch+1) % 5 == 0 else 'train'\n",
    "    train_eval_model_per_epoch(epoch, net, args, train_loader, test_loader, phase=phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = Variable(torch.zeros(1,3,256,256))\n",
    "# y = net(x.cuda())\n",
    "# g = make_dot(y[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g.render('net-transition_scale_{}'.format(transition_scale)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
