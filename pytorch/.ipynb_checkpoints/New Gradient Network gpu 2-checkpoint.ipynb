{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, platform, datetime, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import functional as F\n",
    "# import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc\n",
    "\n",
    "from myimagefolder import MyImageFolder\n",
    "from mymodel_gpu2 import PreTrainedModel, GradientNet\n",
    "from myargs import Args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('debian', 'jessie/sid', '')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = Args()\n",
    "args.test_scene = 'alley_1'\n",
    "args.arch = \"densenet121\"\n",
    "args.epoches = 500\n",
    "args.epoches_unary_threshold = 0\n",
    "args.image_h = 256\n",
    "args.image_w = 256\n",
    "args.img_extentions = [\"png\"]\n",
    "args.training_thresholds = [250,200,150,50,0,300]\n",
    "args.base_lr = 1\n",
    "args.lr = args.base_lr\n",
    "args.snapshot_interval = 5000\n",
    "args.debug = True\n",
    "args.gpu_num = 2\n",
    "args.display_interval = 50\n",
    "args.display_curindex = 0\n",
    "\n",
    "system_ = platform.system()\n",
    "system_dist, system_version, _ = platform.dist()\n",
    "if system_ == \"Darwin\": \n",
    "    args.train_dir = '/Volumes/Transcend/dataset/sintel2'\n",
    "    args.pretrained = False\n",
    "elif platform.dist() ==  ('debian', 'jessie/sid', ''):\n",
    "    args.train_dir = '/home/lwp/workspace/sintel2'\n",
    "    args.pretrained = True\n",
    "elif platform.dist() == ('debian', 'stretch/sid', ''):\n",
    "    args.train_dir = '/home/cad/lwp/workspace/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "\n",
    "if platform.system() == 'Linux': use_gpu = True\n",
    "else: use_gpu = False\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.gpu_num)\n",
    "    \n",
    "\n",
    "print(platform.dist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = MyImageFolder(args.train_dir, 'train',\n",
    "                       transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ), random_crop=True, \n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "test_dataset = MyImageFolder(args.train_dir, 'test', \n",
    "                       transforms.Compose(\n",
    "        [transforms.CenterCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ), random_crop=False,\n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset,1,True,num_workers=1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "[Defination](https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py)\n",
    "* DenseNet-121: num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16)\n",
    "    * First Convolution: 32M -> 16M -> 8M\n",
    "    * every transition: 8M -> 4M -> 2M (downsample 1/2, except the last block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenet = models.__dict__[args.arch](pretrained=args.pretrained)\n",
    "\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if use_gpu: densenet.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss = 6\n",
    "\n",
    "args.display_curindex = 0\n",
    "args.base_lr = 0.05\n",
    "args.display_interval = 20\n",
    "args.momentum = 0.9\n",
    "args.epoches = 120\n",
    "args.training_thresholds = [ss*4,ss*3,ss*2,ss*1,ss*0,ss*5]\n",
    "args.power = 0.5\n",
    "\n",
    "\n",
    "\n",
    "pretrained = PreTrainedModel(densenet)\n",
    "if use_gpu: \n",
    "    pretrained.cuda()\n",
    "    \n",
    "net = GradientNet(pretrained)\n",
    "if use_gpu: \n",
    "    net.cuda()\n",
    "\n",
    "if use_gpu: \n",
    "    mse_losses = [nn.MSELoss().cuda()] * 6\n",
    "    test_losses = [nn.MSELoss().cuda()] * 6\n",
    "else:\n",
    "    mse_losses = [nn.MSELoss()] * 6\n",
    "    test_losses = [nn.MSELoss()] * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [2017-11-19 14:02:25]\n",
      "lr 0.05\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.053698 merged: 0.000000\n",
      "epoch: 1 [2017-11-19 14:03:48]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.049098 merged: 0.000000\n",
      "epoch: 2 [2017-11-19 14:05:10]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.047099 merged: 0.000000\n",
      "epoch: 3 [2017-11-19 14:06:31]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.045852 merged: 0.000000\n",
      "epoch: 4 [2017-11-19 14:07:53]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.043947 merged: 0.000000\n",
      "epoch: 5 [2017-11-19 14:09:15]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.040625 merged: 0.000000\n",
      "epoch: 6 [2017-11-19 14:10:36]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.048388  1M: 0.045034 merged: 0.000000\n",
      "epoch: 7 [2017-11-19 14:12:07]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.044077  1M: 0.043985 merged: 0.000000\n",
      "epoch: 8 [2017-11-19 14:13:39]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.040370  1M: 0.039522 merged: 0.000000\n",
      "epoch: 9 [2017-11-19 14:15:13]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.034961  1M: 0.035874 merged: 0.000000\n",
      "epoch: 10 [2017-11-19 14:16:45]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.027672  1M: 0.030514 merged: 0.000000\n",
      "epoch: 11 [2017-11-19 14:18:18]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.024153  1M: 0.028282 merged: 0.000000\n",
      "epoch: 12 [2017-11-19 14:19:50]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.048549  2M: 0.030359  1M: 0.033572 merged: 0.000000\n",
      "epoch: 13 [2017-11-19 14:21:33]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.040085  2M: 0.026624  1M: 0.032146 merged: 0.000000\n",
      "epoch: 14 [2017-11-19 14:23:16]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.028554  2M: 0.023017  1M: 0.028174 merged: 0.000000\n",
      "epoch: 15 [2017-11-19 14:24:59]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.022348  2M: 0.020591  1M: 0.027038 merged: 0.000000\n",
      "epoch: 16 [2017-11-19 14:26:38]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.019428  2M: 0.018925  1M: 0.025718 merged: 0.000000\n",
      "epoch: 17 [2017-11-19 14:28:21]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.018818  2M: 0.019551  1M: 0.024946 merged: 0.000000\n",
      "epoch: 18 [2017-11-19 14:30:03]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.044768  4M: 0.022065  2M: 0.020874  1M: 0.027948 merged: 0.000000\n",
      "epoch: 19 [2017-11-19 14:31:51]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.000000  8M: 0.034654  4M: 0.019827  2M: 0.020563  1M: 0.026426 merged: 0.000000\n",
      "epoch: 20 [2017-11-19 14:33:42]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.000000  8M: 0.026419  4M: 0.018928  2M: 0.019381  1M: 0.026495 merged: 0.000000\n",
      "epoch: 21 [2017-11-19 14:35:36]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.000000  8M: 0.021048  4M: 0.016542  2M: 0.017964  1M: 0.024340 merged: 0.000000\n",
      "epoch: 22 [2017-11-19 14:37:28]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.000000  8M: 0.017708  4M: 0.015085  2M: 0.017072  1M: 0.023438 merged: 0.000000\n",
      "epoch: 23 [2017-11-19 14:39:22]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.018498  4M: 0.015039  2M: 0.016562  1M: 0.022912 merged: 0.000000\n",
      "epoch: 24 [2017-11-19 14:41:14]\n",
      "lr 1e-08\n",
      " 16M: 0.043711  8M: 0.019333  4M: 0.016371  2M: 0.018143  1M: 0.024678 merged: 0.000000\n",
      "epoch: 25 [2017-11-19 14:43:23]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.032719  8M: 0.018697  4M: 0.015621  2M: 0.017714  1M: 0.024652 merged: 0.000000\n",
      "epoch: 26 [2017-11-19 14:45:35]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.023544  8M: 0.015938  4M: 0.014629  2M: 0.016777  1M: 0.023396 merged: 0.000000\n",
      "epoch: 27 [2017-11-19 14:47:45]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.019812  8M: 0.014990  4M: 0.013943  2M: 0.016474  1M: 0.023183 merged: 0.000000\n",
      "epoch: 28 [2017-11-19 14:49:56]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.017507  8M: 0.013819  4M: 0.013274  2M: 0.015694  1M: 0.021792 merged: 0.000000\n",
      "epoch: 29 [2017-11-19 14:52:09]\n",
      "lr 1e-08\n",
      " 16M: 0.016289  8M: 0.013107  4M: 0.013536  2M: 0.016221  1M: 0.022879 merged: 0.000000\n",
      "epoch: 30 [2017-11-19 14:54:17]\n",
      "lr 0.05\n",
      " 16M: 0.022719  8M: 0.016274  4M: 0.014745  2M: 0.017533  1M: 0.023519 merged: 0.036252\n",
      "epoch: 31 [2017-11-19 14:57:42]\n",
      "lr 0.04971830761761256\n",
      " 16M: 0.021270  8M: 0.018308  4M: 0.016725  2M: 0.017940  1M: 0.023363 merged: 0.025193\n",
      "epoch: 32 [2017-11-19 15:01:01]\n",
      "lr 0.04943501011144937\n",
      " 16M: 0.019715  8M: 0.017205  4M: 0.015934  2M: 0.018395  1M: 0.022814 merged: 0.020712\n",
      "epoch: 33 [2017-11-19 15:04:23]\n",
      "lr 0.04915007972606608\n",
      " 16M: 0.018539  8M: 0.017524  4M: 0.014964  2M: 0.018506  1M: 0.023932 merged: 0.019226\n",
      "epoch: 34 [2017-11-19 15:07:48]\n",
      "lr 0.04886348789677424\n",
      " 16M: 0.017740  8M: 0.016407  4M: 0.014609  2M: 0.018155  1M: 0.023205 merged: 0.017715\n",
      "epoch: 35 [2017-11-19 15:11:08]\n",
      "lr 0.04857520521621862\n",
      " 16M: 0.015536  8M: 0.015027  4M: 0.014143  2M: 0.017352  1M: 0.022689 merged: 0.015889\n",
      "epoch: 36 [2017-11-19 15:14:22]\n",
      "lr 0.04828520139915856\n",
      " 16M: 0.014843  8M: 0.013759  4M: 0.013520  2M: 0.016368  1M: 0.022217 merged: 0.015148\n",
      "epoch: 37 [2017-11-19 15:17:47]\n",
      "lr 0.047993445245333805\n",
      " 16M: 0.014486  8M: 0.013551  4M: 0.013405  2M: 0.016112  1M: 0.022671 merged: 0.014400\n",
      "epoch: 38 [2017-11-19 15:21:09]\n",
      "lr 0.0476999046002862\n",
      " 16M: 0.014854  8M: 0.014854  4M: 0.013813  2M: 0.016176  1M: 0.021649 merged: 0.014732\n",
      "epoch: 39 [2017-11-19 15:24:35]\n",
      "lr 0.04740454631399772\n",
      " 16M: 0.013269  8M: 0.013321  4M: 0.013184  2M: 0.016212  1M: 0.021504 merged: 0.013580\n",
      "epoch: 40 [2017-11-19 15:28:11]\n",
      "lr 0.04710733619719444\n",
      " 16M: 0.012947  8M: 0.012827  4M: 0.012850  2M: 0.015847  1M: 0.022193 merged: 0.012965\n",
      "epoch: 41 [2017-11-19 15:31:35]\n",
      "lr 0.04680823897515326\n",
      " 16M: 0.012462  8M: 0.012205  4M: 0.012345  2M: 0.015217  1M: 0.020995 merged: 0.012532\n",
      "epoch: 42 [2017-11-19 15:35:09]\n",
      "lr 0.04650721823883479\n",
      " 16M: 0.012697  8M: 0.012210  4M: 0.012299  2M: 0.015247  1M: 0.021297 merged: 0.012465\n",
      "epoch: 43 [2017-11-19 15:38:37]\n",
      "lr 0.046204236393150765\n",
      " 16M: 0.011966  8M: 0.011831  4M: 0.011867  2M: 0.014899  1M: 0.020445 merged: 0.011556\n",
      "epoch: 44 [2017-11-19 15:42:01]\n",
      "lr 0.045899254602157845\n",
      " 16M: 0.011948  8M: 0.012290  4M: 0.012508  2M: 0.014647  1M: 0.020463 merged: 0.012135\n",
      "epoch: 45 [2017-11-19 15:45:28]\n",
      "lr 0.04559223273095164\n",
      " 16M: 0.011076  8M: 0.011239  4M: 0.011536  2M: 0.014089  1M: 0.020718 merged: 0.011034\n",
      "epoch: 46 [2017-11-19 15:49:02]\n",
      "lr 0.045283129284014914\n",
      " 16M: 0.011146  8M: 0.011562  4M: 0.011826  2M: 0.014383  1M: 0.020694 merged: 0.011201\n",
      "epoch: 47 [2017-11-19 15:52:29]\n",
      "lr 0.04497190133975169\n",
      " 16M: 0.010871  8M: 0.011062  4M: 0.011495  2M: 0.013977  1M: 0.019510 merged: 0.010787\n",
      "epoch: 48 [2017-11-19 15:55:53]\n",
      "lr 0.04465850448091506\n",
      " 16M: 0.010564  8M: 0.011199  4M: 0.011474  2M: 0.013800  1M: 0.019565 merged: 0.010816\n",
      "epoch: 49 [2017-11-19 15:59:19]\n",
      "lr 0.044342892720609255\n",
      " 16M: 0.010017  8M: 0.010419  4M: 0.011153  2M: 0.013595  1M: 0.019576 merged: 0.010157\n",
      "epoch: 50 [2017-11-19 16:02:36]\n",
      "lr 0.044025018423517\n",
      " 16M: 0.010545  8M: 0.010669  4M: 0.011050  2M: 0.013873  1M: 0.019319 merged: 0.010411\n",
      "epoch: 51 [2017-11-19 16:06:01]\n",
      "lr 0.04370483222197017\n",
      " 16M: 0.009676  8M: 0.010225  4M: 0.010763  2M: 0.013342  1M: 0.019092 merged: 0.009784\n",
      "epoch: 52 [2017-11-19 16:09:25]\n",
      "lr 0.043382282926444894\n",
      " 16M: 0.009651  8M: 0.010280  4M: 0.010657  2M: 0.013450  1M: 0.019637 merged: 0.009799\n",
      "epoch: 53 [2017-11-19 16:12:46]\n",
      "lr 0.04305731743002185\n",
      " 16M: 0.009928  8M: 0.010322  4M: 0.010931  2M: 0.013374  1M: 0.019327 merged: 0.009906\n",
      "epoch: 54 [2017-11-19 16:16:17]\n",
      "lr 0.04272988060630656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-163:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-af2f6ef86bb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m#                 run_cnts[i] += 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mrun_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0mrun_cnts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m#                 print('i = ', i, '; weig\\n', net.upsample01.weight[0,0,0:4,0:4].data.cpu().numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "writer = SummaryWriter()\n",
    "writer.add_text('training', 'reduce training time')\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "optimizer = optim.SGD(parameters, lr=args.base_lr, momentum=args.momentum)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, beg, end, reset_lr=None):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if reset_lr != None:\n",
    "            param_group['lr'] = reset_lr\n",
    "            continue\n",
    "        if epoch != 0: \n",
    "            # linear\n",
    "#             param_group['lr'] *= (end-epoch) / (end-beg)\n",
    "#             poly base_lr (1 - iter/max_iter) ^ (power)\n",
    "            param_group['lr'] = args.base_lr * (float(end-epoch)/(end-beg)) ** (args.power)\n",
    "            if param_group['lr'] < 1.0e-8: param_group['lr'] = 1.0e-8\n",
    "        print('lr', param_group['lr'])\n",
    "        \n",
    "# def findLargerInd(target, arr):\n",
    "#     res = list(filter(lambda x: x>target, arr))\n",
    "#     print('res',res)\n",
    "#     if len(res) == 0: return -1\n",
    "#     return res[0]\n",
    "\n",
    "for epoch in range(args.epoches):\n",
    "    net.train()\n",
    "    print('epoch: {} [{}]'.format(epoch, datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "    \n",
    "    if epoch < args.training_thresholds[-1]: adjust_learning_rate(optimizer, epoch%ss, beg=0, end=ss-1)\n",
    "    else: adjust_learning_rate(optimizer, epoch, beg=args.training_thresholds[-1], end=args.epoches-1)\n",
    "    \n",
    "    run_losses = [0] * len(args.training_thresholds)\n",
    "    run_cnts   = [0.00001] * len(args.training_thresholds)\n",
    "    if (epoch in args.training_thresholds) == True: \n",
    "        adjust_learning_rate(optimizer, epoch, reset_lr=args.base_lr, beg=-1, end=-1)\n",
    "    writer.add_scalar('learning rate', optimizer.param_groups[0]['lr'], global_step=epoch)\n",
    "    for ind, data in enumerate(train_loader, 0):\n",
    "#         if  ind == 1 : break\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        im = input_img[0,:,:,:].numpy(); im = im.transpose(1,2,0); im = im[:,:,::-1]*255\n",
    "        \n",
    "        if test_scene[0] == 'alley_1':\n",
    "            print('alley_1 yes')\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda()\n",
    "            gt_albedo = gt_albedo.cuda()\n",
    "            gt_shading = gt_shading.cuda()\n",
    "#         run_losses = [0] * len(mse_losses)\n",
    "#         run_cnts = [0.00001] * len(mse_losses)\n",
    "        if args.display_curindex % args.display_interval == 0:\n",
    "            cv2.imwrite('snapshot2/input.png', im)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        ft_predict = net(input_img)\n",
    "        for i, threshold in enumerate(args.training_thresholds):\n",
    "#             threshold = args.training_thresholds[i]\n",
    "            if epoch >= threshold:\n",
    "#             if epoch >= 0:\n",
    "                if i == 5: s = 1\n",
    "                else: s = (2**(i+1))\n",
    "                gt = gt_albedo.cpu().data.numpy()\n",
    "                n,c,h,w = gt.shape\n",
    "                gt = gt[0,:,:,:]\n",
    "                gt = gt.transpose((1,2,0))\n",
    "                gt = cv2.resize(gt, (h//s, w//s))\n",
    "#                 gt = cv2.resize(gt, (h,w))\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    cv2.imwrite('snapshot2/gt-{}-{}.png'.format(epoch, i), gt[:,:,::-1]*255)\n",
    "                gt = gt.transpose((2,0,1))\n",
    "                gt = gt[np.newaxis, :]\n",
    "                gt = Variable(torch.from_numpy(gt))\n",
    "                if use_gpu: gt = gt.cuda()\n",
    "                loss = mse_losses[i](ft_predict[i], gt)\n",
    "                loss_data = loss.data.cpu().numpy()\n",
    "                writer.add_scalar('{}th train iters loss'.format(i), loss_data, global_step=args.display_curindex)\n",
    "                ma_ = ft_predict[i].max().cpu().data.numpy()\n",
    "                mi_ = ft_predict[i].min().cpu().data.numpy()\n",
    "                #print('mi', mi_, 'ma', ma_)\n",
    "#                 writer.add_scalars('{}th train predict'.format(i), {'max': ma_, 'min': mi_}, global_step=args.display_curindex)\n",
    "#                 run_cnts[i] += 1\n",
    "                run_losses[i] += loss.data.cpu().numpy()[0]\n",
    "                loss.backward(retain_graph=True)\n",
    "                run_cnts[i] += 1\n",
    "#                 print('i = ', i, '; weig\\n', net.upsample01.weight[0,0,0:4,0:4].data.cpu().numpy())\n",
    "#                 print('i = ', i, '; grad\\n', net.upsample01.weight.grad[0,0,0:4,0:4].data.cpu().numpy())\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    im = ft_predict[i].cpu().data.numpy()[0].transpose((1,2,0)) * 255\n",
    "                    cv2.imwrite('snapshot2/train-{}-{}.png'.format(epoch, i), im[:,:,::-1])\n",
    "        optimizer.step()\n",
    "        args.display_curindex += 1\n",
    "\n",
    "    \"\"\" every epoch \"\"\"\n",
    "#     loss_output = 'ind: ' + str(args.display_curindex)\n",
    "    loss_output = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i,v in enumerate(run_losses):\n",
    "        if i == len(run_losses)-1: \n",
    "            loss_output += ' merged: %6f' % (run_losses[i] / run_cnts[i])\n",
    "            continue\n",
    "        loss_output += ' %2dM: %6f' % ((2**(4-i)), (run_losses[i] / run_cnts[i]))\n",
    "    print(loss_output)\n",
    "    # save at every epoch\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'args' : args,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, 'snapshot2/snapshot-{}.pth.tar'.format(epoch))\n",
    "    \n",
    "    # test \n",
    "    test_losses_trainphase = [0] * len(args.training_thresholds)\n",
    "    test_cnts_trainphase   = [0.00001] * len(args.training_thresholds)   \n",
    "    for ind, data in enumerate(test_loader, 0):\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "        ft_test = net(input_img)\n",
    "            \n",
    "        for i,v in enumerate(ft_test):\n",
    "            if epoch < args.training_thresholds[i]: continue\n",
    "            if i == 5: s = 1\n",
    "            else: s = (2**(i+1))\n",
    "            gt = gt_albedo.data.numpy()\n",
    "            n,c,h,w = gt.shape\n",
    "            gt = gt[0,:,:,:]\n",
    "            gt = gt.transpose((1,2,0))\n",
    "            gt = cv2.resize(gt, (h//s, w//s))\n",
    "#             gt = cv2.resize(gt, (h,w))\n",
    "            \n",
    "            gt = gt.transpose((2,0,1))\n",
    "            gt = gt[np.newaxis, :]\n",
    "            gt = Variable(torch.from_numpy(gt))\n",
    "            if use_gpu: gt = gt.cuda()\n",
    "\n",
    "            loss = mse_losses[i](ft_test[i], gt)\n",
    "            \n",
    "            test_losses_trainphase[i] += loss.data.cpu().numpy()[0]\n",
    "            test_cnts_trainphase[i] += 1\n",
    "            v = v[0].cpu().data.numpy()\n",
    "            v = v.transpose(1,2,0)\n",
    "            if ind == 0: cv2.imwrite('snapshot2/test-phase_train-{}-{}.png'.format(epoch, i), v[:,:,::-1]*255)\n",
    "\n",
    "    \n",
    "    net.eval()\n",
    "    test_losses = [0] * len(args.training_thresholds)\n",
    "    test_cnts   = [0.00001] * len(args.training_thresholds)   \n",
    "    for ind, data in enumerate(test_loader, 0):\n",
    "#         if ind == 1: break\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "        ft_test = net(input_img)\n",
    "            \n",
    "        for i,v in enumerate(ft_test):\n",
    "            if epoch < args.training_thresholds[i]: continue\n",
    "            if i == 5: s = 1\n",
    "            else: s = (2**(i+1))\n",
    "            gt = gt_albedo.data.numpy()\n",
    "            n,c,h,w = gt.shape\n",
    "            gt = gt[0,:,:,:]\n",
    "            gt = gt.transpose((1,2,0))\n",
    "            gt = cv2.resize(gt, (h//s, w//s))\n",
    "#             gt = cv2.resize(gt, (h,w))\n",
    "            \n",
    "            gt = gt.transpose((2,0,1))\n",
    "            gt = gt[np.newaxis, :]\n",
    "            gt = Variable(torch.from_numpy(gt))\n",
    "            if use_gpu: gt = gt.cuda()\n",
    "\n",
    "            loss = mse_losses[i](ft_test[i], gt)\n",
    "            \n",
    "            test_losses[i] += loss.data.cpu().numpy()[0]\n",
    "            test_cnts[i] += 1\n",
    "            v = v[0].cpu().data.numpy()\n",
    "            v = v.transpose(1,2,0)\n",
    "            if ind == 0: cv2.imwrite('snapshot2/test-phase_test-{}-{}.png'.format(epoch, i), v[:,:,::-1]*255)\n",
    "    \n",
    "    writer.add_scalars('16M loss', {\n",
    "        'train 16M ': np.array([run_losses[0]/ run_cnts[0]]),\n",
    "        'test_trainphase 16M ': np.array([test_losses_trainphase[0]/ test_cnts_trainphase[0]]),\n",
    "        'test 16M ': np.array([test_losses[0]/ test_cnts[0]])\n",
    "    }, global_step=epoch)  \n",
    "    writer.add_scalars('8M loss', {\n",
    "        'train 8M ': np.array([run_losses[1]/ run_cnts[1]]),\n",
    "        'test_trainphase 8M ': np.array([test_losses_trainphase[1]/ test_cnts_trainphase[1]]),\n",
    "        'test 8M ': np.array([test_losses[1]/ test_cnts[1]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('4M loss', {\n",
    "        'train 4M ': np.array([run_losses[2]/ run_cnts[2]]),\n",
    "        'test_trainphase 4M ': np.array([test_losses_trainphase[2]/ test_cnts_trainphase[2]]),\n",
    "        'test 4M ': np.array([test_losses[2]/ test_cnts[2]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('2M loss', {\n",
    "        'train 2M ': np.array([run_losses[3]/ run_cnts[3]]),\n",
    "        'test_trainphase 2M ': np.array([test_losses_trainphase[3]/ test_cnts_trainphase[3]]),\n",
    "        'test 2M ': np.array([test_losses[3]/ test_cnts[3]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('1M loss', {\n",
    "        'train 1M ': np.array([run_losses[4]/ run_cnts[4]]),\n",
    "        'test_trainphase 1M ': np.array([test_losses_trainphase[4]/ test_cnts_trainphase[4]]),\n",
    "        'test 1M ': np.array([test_losses[4]/ test_cnts[4]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('merged loss', {\n",
    "        'train merged ': np.array([run_losses[5]/ run_cnts[5]]),\n",
    "        'test_trainphase merged ': np.array([test_losses_trainphase[5]/ test_cnts_trainphase[5]]),\n",
    "        'test merged ': np.array([test_losses[5]/ test_cnts[5]])\n",
    "    }, global_step=epoch) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"10240,10240\"), format='svg')\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.zeros(1,3,256,256))\n",
    "y = net(x.cuda())\n",
    "g = make_dot(y[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'net.svg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.render('net') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
