{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, platform, datetime, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import functional as F\n",
    "# import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc\n",
    "\n",
    "from myimagefolder import MyImageFolder\n",
    "from mymodel import PreTrainedModel, GradientNet16, GradientNet08, GradientNet04, GradientNet02, GradientNet01, GradientNetMerge \n",
    "from myargs import Args\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('debian', 'jessie/sid', '')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = Args()\n",
    "args.test_scene = 'alley_1'\n",
    "args.arch = \"densenet121\"\n",
    "args.epoches = 500\n",
    "args.epoches_unary_threshold = 0\n",
    "args.image_h = 256\n",
    "args.image_w = 256\n",
    "args.img_extentions = [\"png\"]\n",
    "args.training_thresholds = [250,200,150,50,0,300]\n",
    "args.base_lr = 1\n",
    "args.lr = args.base_lr\n",
    "args.snapshot_interval = 5000\n",
    "args.debug = True\n",
    "args.gpu_num = 1\n",
    "args.display_interval = 50\n",
    "args.display_curindex = 0\n",
    "\n",
    "system_ = platform.system()\n",
    "system_dist, system_version, _ = platform.dist()\n",
    "if system_ == \"Darwin\": \n",
    "    args.train_dir = '/Volumes/Transcend/dataset/sintel2'\n",
    "    args.pretrained = False\n",
    "elif platform.dist() ==  ('debian', 'jessie/sid', ''):\n",
    "    args.train_dir = '/home/lwp/workspace/sintel2'\n",
    "    args.pretrained = True\n",
    "elif platform.dist() == ('debian', 'stretch/sid', ''):\n",
    "    args.train_dir = '/home/cad/lwp/workspace/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "\n",
    "if platform.system() == 'Linux': use_gpu = True\n",
    "else: use_gpu = False\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.gpu_num)\n",
    "    \n",
    "\n",
    "print(platform.dist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = MyImageFolder(args.train_dir, 'train',\n",
    "                       transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ), random_crop=True, \n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "test_dataset = MyImageFolder(args.train_dir, 'test', \n",
    "                       transforms.Compose(\n",
    "        [transforms.CenterCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ), random_crop=False,\n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset,1,True,num_workers=1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "[Defination](https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py)\n",
    "* DenseNet-121: num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16)\n",
    "    * First Convolution: 32M -> 16M -> 8M\n",
    "    * every transition: 8M -> 4M -> 2M (downsample 1/2, except the last block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenet = models.__dict__[args.arch](pretrained=args.pretrained)\n",
    "\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if use_gpu: densenet.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 6\n",
    "\n",
    "args.display_curindex = 0\n",
    "args.base_lr = 0.05\n",
    "args.display_interval = 20\n",
    "args.momentum = 0.9\n",
    "args.epoches = 120\n",
    "args.training_thresholds = [ss*4,ss*3,ss*2,ss*1,ss*0,ss*5]\n",
    "args.power = 0.5\n",
    "\n",
    "\n",
    "\n",
    "pretrained = PreTrainedModel(densenet)\n",
    "if use_gpu: \n",
    "    pretrained.cuda()\n",
    "    \n",
    "net16 = GradientNet16()\n",
    "net08 = GradientNet08()\n",
    "net04 = GradientNet04()\n",
    "net02 = GradientNet02()\n",
    "net01 = GradientNet01()\n",
    "netmg = GradientNetMerge()\n",
    "\n",
    "if use_gpu: \n",
    "    net16.cuda()\n",
    "    net08.cuda()\n",
    "    net04.cuda()\n",
    "    net02.cuda()\n",
    "    net01.cuda()\n",
    "    netmg.cuda()\n",
    "nets = [net16, net08, net04, net02, net01, netmg]\n",
    "\n",
    "if use_gpu: \n",
    "    mse_losses = [nn.MSELoss().cuda()] * 6\n",
    "    test_losses = [nn.MSELoss().cuda()] * 6\n",
    "else:\n",
    "    mse_losses = [nn.MSELoss()] * 6\n",
    "    test_losses = [nn.MSELoss()] * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [2017-11-19 18:25:55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-212:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/lwp/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c4dbf6beeafd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m#                 run_cnts[i] += 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mrun_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m#                 if i < 5: optimizers[i].step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "writer = SummaryWriter()\n",
    "writer.add_text('training', 'different kernel size for different scale')\n",
    "\n",
    "parameters = [0]*len(nets)\n",
    "optimizers = [0]*len(nets)\n",
    "for i in range(len(nets)):\n",
    "    parameters[i] = filter(lambda p: p.requires_grad, nets[i].parameters())\n",
    "    optimizers[i] = optim.SGD(parameters[i], lr=args.base_lr, momentum=args.momentum)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, beg, end, reset_lr=None):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if reset_lr != None:\n",
    "            param_group['lr'] = reset_lr\n",
    "            continue\n",
    "        if epoch != 0: \n",
    "            param_group['lr'] = args.base_lr * (float(end-epoch)/(end-beg)) ** (args.power)\n",
    "            if param_group['lr'] < 1.0e-8: param_group['lr'] = 1.0e-8\n",
    "#         print('lr', param_group['lr'])\n",
    "\n",
    "pretrained.train()\n",
    "ft_pretrained = pretrained(input_img)\n",
    "pretrained.eval()\n",
    "ft_pretrained_test_phase = pretrained(input_img)\n",
    "\n",
    "\n",
    "for epoch in range(args.epoches):\n",
    "    net16.train(); net08.train(); net04.train(); net02.train(); net01.train(); netmg.train();\n",
    "    print('epoch: {} [{}]'.format(epoch, datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "    \n",
    "    if epoch < args.training_thresholds[-1]: \n",
    "        for optimizer in optimizers: adjust_learning_rate(optimizer, epoch%ss, beg=0, end=ss-1)\n",
    "    else: \n",
    "        for optimizer in optimizers: adjust_learning_rate(optimizer, epoch, beg=args.training_thresholds[-1], end=args.epoches-1)\n",
    "    \n",
    "    run_losses = [0] * len(args.training_thresholds)\n",
    "    run_cnts   = [0.00001] * len(args.training_thresholds)\n",
    "    if (epoch in args.training_thresholds) == True: \n",
    "        for optimizer in optimizers: adjust_learning_rate(optimizer, epoch, reset_lr=args.base_lr, beg=-1, end=-1)\n",
    "    writer.add_scalar('learning rate', optimizers[0].param_groups[0]['lr'], global_step=epoch)\n",
    "    for ind, data in enumerate(train_loader, 0):\n",
    "#         if  ind == 1 : break\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        im = input_img[0,:,:,:].numpy(); im = im.transpose(1,2,0); im = im[:,:,::-1]*255\n",
    "        \n",
    "        if test_scene[0] == 'alley_1':\n",
    "            print('alley_1 yes')\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda()\n",
    "            gt_albedo = gt_albedo.cuda()\n",
    "            gt_shading = gt_shading.cuda()\n",
    "        if args.display_curindex % args.display_interval == 0:\n",
    "            cv2.imwrite('snapshot/input.png', im)\n",
    "\n",
    "#         for optimizer in optimizers: optimizer.zero_grad()\n",
    "        \n",
    "        ft_predict = [0] * len(nets)\n",
    "        for i, threshold in enumerate(args.training_thresholds):\n",
    "#             if epoch >= threshold:\n",
    "            if epoch >= 0:\n",
    "                optimizers[i].zero_grad()\n",
    "                if i < 5: ft_predict[i] = nets[i](ft_pretrained)\n",
    "                else: \n",
    "                    for net_ind in range(len(nets)-1):\n",
    "                        ft_predict[net_ind] =nets[net_ind](ft_pretrained)\n",
    "                    ft_predict[i] = nets[i](ft_predict[0:-1])\n",
    "                if i == 5: s = 1\n",
    "                else: s = (2**(i+1))\n",
    "                gt = gt_albedo.cpu().data.numpy()\n",
    "                n,c,h,w = gt.shape\n",
    "                gt = gt[0,:,:,:]\n",
    "                gt = gt.transpose((1,2,0))\n",
    "                gt = cv2.resize(gt, (h//s, w//s))\n",
    "#                 gt = cv2.resize(gt, (h,w))\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    cv2.imwrite('snapshot/gt-{}-{}.png'.format(epoch, i), gt[:,:,::-1]*255)\n",
    "                gt = gt.transpose((2,0,1))\n",
    "                gt = gt[np.newaxis, :]\n",
    "                gt = Variable(torch.from_numpy(gt))\n",
    "                if use_gpu: gt = gt.cuda()\n",
    "                loss = mse_losses[i](ft_predict[i], gt)\n",
    "                loss_data = loss.data.cpu().numpy()\n",
    "                writer.add_scalar('{}th train iters loss'.format(i), loss_data, global_step=args.display_curindex)\n",
    "#                 ma_ = ft_predict[i].max().cpu().data.numpy()\n",
    "#                 mi_ = ft_predict[i].min().cpu().data.numpy()\n",
    "                #print('mi', mi_, 'ma', ma_)\n",
    "#                 writer.add_scalars('{}th train predict'.format(i), {'max': ma_, 'min': mi_}, global_step=args.display_curindex)\n",
    "#                 run_cnts[i] += 1\n",
    "                run_losses[i] += loss.data.cpu().numpy()[0]\n",
    "                loss.backward()\n",
    "                optimizers[i].step()\n",
    "#                 if i < 5: optimizers[i].step()\n",
    "#                 else: for opt_ind in range(len(optimizers)): optimizers[i].step()\n",
    "                run_cnts[i] += 1\n",
    "#                 print('i = ', i, '; weig\\n', net.upsample01.weight[0,0,0:4,0:4].data.cpu().numpy())\n",
    "#                 print('i = ', i, '; grad\\n', net.upsample01.weight.grad[0,0,0:4,0:4].data.cpu().numpy())\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    im = ft_predict[i].cpu().data.numpy()[0].transpose((1,2,0)) * 255\n",
    "                    cv2.imwrite('snapshot/train-{}-{}.png'.format(epoch, i), im[:,:,::-1])\n",
    "        args.display_curindex += 1\n",
    "\n",
    "    \"\"\" every epoch \"\"\"\n",
    "#     loss_output = 'ind: ' + str(args.display_curindex)\n",
    "    loss_output = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i,v in enumerate(run_losses):\n",
    "        if i == len(run_losses)-1: \n",
    "            loss_output += ' merged: %6f' % (run_losses[i] / run_cnts[i])\n",
    "            continue\n",
    "        loss_output += ' %2dM: %6f' % ((2**(4-i)), (run_losses[i] / run_cnts[i]))\n",
    "    print(loss_output)\n",
    "    # save at every epoch\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('snapshot')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'args' : args,\n",
    "            'state_dict_16M': nets[0].state_dict(),\n",
    "            'state_dict_08M': nets[1].state_dict(),\n",
    "            'state_dict_04M': nets[2].state_dict(),\n",
    "            'state_dict_02M': nets[3].state_dict(),\n",
    "            'state_dict_01M': nets[4].state_dict(),\n",
    "            'state_dict_merge': nets[5].state_dict(),\n",
    "            'optimizer_16M': optimizers[0].state_dict(),\n",
    "            'optimizer_08M': optimizers[1].state_dict(),\n",
    "            'optimizer_04M': optimizers[2].state_dict(),\n",
    "            'optimizer_02M': optimizers[3].state_dict(),\n",
    "            'optimizer_01M': optimizers[4].state_dict(),\n",
    "            'optimizer_merge': optimizers[5].state_dict()\n",
    "        }, 'snapshot/snapshot-{}.pth.tar'.format(epoch))\n",
    "    \n",
    "    # test \n",
    "    if epoch % 5 != 0 or epoch == 0: continue\n",
    "    print('eval net')\n",
    "    test_losses_trainphase = [0] * len(args.training_thresholds)\n",
    "    test_cnts_trainphase   = [0.00001] * len(args.training_thresholds)   \n",
    "    for ind, data in enumerate(test_loader, 0):\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "        \n",
    "#         ft_pretrained = pretrained(input_img)\n",
    "        ft_test = [0]*len(nets)\n",
    "        for i,v in enumerate(ft_test):\n",
    "            if epoch < args.training_thresholds[i]: continue\n",
    "            if i < 5: ft_test[i] = nets[i](ft_pretrained)\n",
    "            else: ft_test[i] = nets[i](ft_test[0:-1])\n",
    "            if i == 5: s = 1\n",
    "            else: s = (2**(i+1))\n",
    "            gt = gt_albedo.data.numpy()\n",
    "            n,c,h,w = gt.shape\n",
    "            gt = gt[0,:,:,:]\n",
    "            gt = gt.transpose((1,2,0))\n",
    "            gt = cv2.resize(gt, (h//s, w//s))\n",
    "#             gt = cv2.resize(gt, (h,w))\n",
    "            \n",
    "            gt = gt.transpose((2,0,1))\n",
    "            gt = gt[np.newaxis, :]\n",
    "            gt = Variable(torch.from_numpy(gt))\n",
    "            if use_gpu: gt = gt.cuda()\n",
    "            \n",
    "            loss = mse_losses[i](ft_test[i], gt)\n",
    "            \n",
    "            test_losses_trainphase[i] += loss.data.cpu().numpy()[0]\n",
    "            test_cnts_trainphase[i] += 1\n",
    "            v = ft_test[i]\n",
    "            v = v[0].cpu().data.numpy()\n",
    "            v = v.transpose(1,2,0)\n",
    "            if ind == 0: cv2.imwrite('snapshot/test-phase_train-{}-{}.png'.format(epoch, i), v[:,:,::-1]*255)\n",
    "\n",
    "    \n",
    "#     net.eval()\n",
    "    net16.eval(); net08.eval(); net04.eval(); net02.eval(); net01.eval(); netmg.eval();\n",
    "    test_losses = [0] * len(args.training_thresholds)\n",
    "    test_cnts   = [0.00001] * len(args.training_thresholds)   \n",
    "    for ind, data in enumerate(test_loader, 0):\n",
    "#         if ind == 1: break\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "#         ft_test = net(input_img)\n",
    "        \n",
    "#         ft_pretrained = pretrained(input_img)\n",
    "        ft_test = [0]*len(nets)\n",
    "        for i,v in enumerate(ft_test):\n",
    "            if epoch < args.training_thresholds[i]: continue\n",
    "            if i < 5: ft_test[i] = nets[i](ft_pretrained_test_phase)\n",
    "            else: ft_test[i] = nets[i](ft_test[0:-1]) \n",
    "            if i == 5: s = 1\n",
    "            else: s = (2**(i+1))\n",
    "            gt = gt_albedo.data.numpy()\n",
    "            n,c,h,w = gt.shape\n",
    "            gt = gt[0,:,:,:]\n",
    "            gt = gt.transpose((1,2,0))\n",
    "            gt = cv2.resize(gt, (h//s, w//s))\n",
    "#             gt = cv2.resize(gt, (h,w))\n",
    "            \n",
    "            gt = gt.transpose((2,0,1))\n",
    "            gt = gt[np.newaxis, :]\n",
    "            gt = Variable(torch.from_numpy(gt))\n",
    "            if use_gpu: gt = gt.cuda()\n",
    "\n",
    "            loss = mse_losses[i](ft_test[i], gt)\n",
    "            \n",
    "            test_losses[i] += loss.data.cpu().numpy()[0]\n",
    "            test_cnts[i] += 1\n",
    "            v = ft_test[i]\n",
    "            v = v[0].cpu().data.numpy()\n",
    "            v = v.transpose(1,2,0)\n",
    "            if ind == 0: cv2.imwrite('snapshot/test-phase_test-{}-{}.png'.format(epoch, i), v[:,:,::-1]*255)\n",
    "    \n",
    "    writer.add_scalars('16M loss', {\n",
    "        'train 16M ': np.array([run_losses[0]/ run_cnts[0]]),\n",
    "        'test_trainphase 16M ': np.array([test_losses_trainphase[0]/ test_cnts_trainphase[0]]),\n",
    "        'test 16M ': np.array([test_losses[0]/ test_cnts[0]])\n",
    "    }, global_step=epoch)  \n",
    "    writer.add_scalars('8M loss', {\n",
    "        'train 8M ': np.array([run_losses[1]/ run_cnts[1]]),\n",
    "        'test_trainphase 8M ': np.array([test_losses_trainphase[1]/ test_cnts_trainphase[1]]),\n",
    "        'test 8M ': np.array([test_losses[1]/ test_cnts[1]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('4M loss', {\n",
    "        'train 4M ': np.array([run_losses[2]/ run_cnts[2]]),\n",
    "        'test_trainphase 4M ': np.array([test_losses_trainphase[2]/ test_cnts_trainphase[2]]),\n",
    "        'test 4M ': np.array([test_losses[2]/ test_cnts[2]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('2M loss', {\n",
    "        'train 2M ': np.array([run_losses[3]/ run_cnts[3]]),\n",
    "        'test_trainphase 2M ': np.array([test_losses_trainphase[3]/ test_cnts_trainphase[3]]),\n",
    "        'test 2M ': np.array([test_losses[3]/ test_cnts[3]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('1M loss', {\n",
    "        'train 1M ': np.array([run_losses[4]/ run_cnts[4]]),\n",
    "        'test_trainphase 1M ': np.array([test_losses_trainphase[4]/ test_cnts_trainphase[4]]),\n",
    "        'test 1M ': np.array([test_losses[4]/ test_cnts[4]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('merged loss', {\n",
    "        'train merged ': np.array([run_losses[5]/ run_cnts[5]]),\n",
    "        'test_trainphase merged ': np.array([test_losses_trainphase[5]/ test_cnts_trainphase[5]]),\n",
    "        'test merged ': np.array([test_losses[5]/ test_cnts[5]])\n",
    "    }, global_step=epoch) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"10240,10240\"), format='svg')\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.zeros(1,3,256,256))\n",
    "y = net(x.cuda())\n",
    "g = make_dot(y[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'net.svg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.render('net') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
