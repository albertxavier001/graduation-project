{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, platform\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('debian', 'stretch/sid', '')\n"
     ]
    }
   ],
   "source": [
    "class Args(object):\n",
    "    pass\n",
    "args = Args()\n",
    "args.test_scene = 'alley_1'\n",
    "args.arch = \"densenet121\"\n",
    "args.epoches = 500\n",
    "args.epoches_unary_threshold = 0\n",
    "args.image_h = 256\n",
    "args.image_w = 256\n",
    "args.img_extentions = [\"png\"]\n",
    "args.training_thresholds = [250,200,150,50,0,300]\n",
    "args.base_lr = 1e4\n",
    "args.snapshot_interval = 5000\n",
    "args.debug = True\n",
    "args.gpu_num = 1\n",
    "args.display_interval = 50\n",
    "args.display_curindex = 0\n",
    "\n",
    "system_ = platform.system()\n",
    "system_dist, system_version, _ = platform.dist()\n",
    "if system_ == \"Darwin\": \n",
    "    args.train_dir = '/Volumes/Transcend/dataset/sintel2'\n",
    "    args.pretrained = False\n",
    "elif platform.dist() ==  ('debian', 'jessie/sid', ''):\n",
    "    args.train_dir = '/home/albertxavier/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "elif platform.dist() == ('debian', 'stretch/sid', ''):\n",
    "    args.train_dir = '/home/cad/lwp/workspace/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "print(platform.dist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Little Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class Netxxx(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Netxxx, self).__init__()\n",
    "#         self.bn = nn.BatchNorm2d(64)\n",
    "#     def forward(self,x):\n",
    "#         return self.bn(x)\n",
    "# netxxx = Netxxx()\n",
    "# netxxx = netxxx.cuda(args.gpu_num)\n",
    "# x = Variable(torch.rand(1,64,5,6)).cuda(args.gpu_num)\n",
    "# y = netxxx(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "def make_dataset(dir, phase):\n",
    "    images_paths = glob.glob(os.path.join(dir, 'clean', '*', '*.png'))\n",
    "    albedo_paths = images_paths[:]\n",
    "    shading_paths = images_paths[:]\n",
    "    pathes = []\n",
    "    for img_path in images_paths:\n",
    "        sp = img_path.split('/'); \n",
    "        if phase == 'train':\n",
    "            if sp[-2] == args.test_scene: continue\n",
    "        else:\n",
    "            if sp[-2] != args.test_scene: continue\n",
    "            \n",
    "        sp[-3] = 'albedo'; \n",
    "        sp = ['/'] + sp; \n",
    "        albedo_path = os.path.join(*sp)\n",
    "        \n",
    "        sp = img_path.split('/'); \n",
    "        sp[-3] = 'shading'; \n",
    "        sp[-1] = sp[-1].replace('frame', 'out')\n",
    "        sp = ['/'] + sp; \n",
    "        shading_path = os.path.join(*sp)\n",
    "        \n",
    "        pathes.append((img_path, albedo_path, shading_path))\n",
    "    return pathes\n",
    "\n",
    "class MyImageFolder(data_utils.Dataset):\n",
    "    def __init__(self, root, phase='train', transform=None, target_transform=None,\n",
    "                loader=default_loader):\n",
    "        imgs = make_dataset(root, phase)\n",
    "        if len(imgs) == 0:\n",
    "            raise(RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n",
    "                               \"Supported image extensions are: \" + \",\".join(args.img_extentions)))\n",
    "\n",
    "        self.root = root\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path, albedo_path, shading_path = self.imgs[index]\n",
    "        \n",
    "        img = self.loader(img_path)\n",
    "        albedo = self.loader(albedo_path)\n",
    "        shading = self.loader(shading_path)\n",
    "        \n",
    "        if self.transform is not None: img = self.transform(img)\n",
    "        if self.transform is not None: albedo = self.transform(albedo)\n",
    "        if self.transform is not None: shading = self.transform(shading)\n",
    "        \n",
    "        scene = img_path.split('/')[-2]\n",
    "        return img, albedo, shading, scene, img_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "train_dataset = MyImageFolder(args.train_dir, 'train', \n",
    "                       transforms.Compose(\n",
    "        [transforms.RandomCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ))\n",
    "test_dataset = MyImageFolder(args.train_dir, 'test', \n",
    "                       transforms.Compose(\n",
    "        [transforms.CenterCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ))\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset,1,True,num_workers=1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,1,False,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "[Defination](https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py)\n",
    "* DenseNet-121: num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16)\n",
    "    * First Convolution: 32M -> 16M -> 8M\n",
    "    * every transition: 8M -> 4M -> 2M (downsample 1/2, except the last block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = models.__dict__[args.arch](pretrained=args.pretrained)\n",
    "\n",
    "# for param in densenet.parameters():\n",
    "#     param.requires_grad = False\n",
    "if platform.system() == 'Linux':\n",
    "    densenet = densenet.cuda(args.gpu_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet (\n",
      "  (features): Sequential (\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu0): ReLU (inplace)\n",
      "    (pool0): MaxPool2d (size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
      "    (denseblock1): _DenseBlock (\n",
      "      (denselayer1): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition (\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock (\n",
      "      (denselayer1): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition (\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock (\n",
      "      (denselayer1): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition (\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d (size=2, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock (\n",
      "      (denselayer1): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.2): ReLU (inplace)\n",
      "        (conv.2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (classifier): Linear (1024 -> 1000)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class PreTrainedModel(nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super(PreTrainedModel, self).__init__()\n",
    "        common_features_net = nn.Sequential(*list(pretrained.children())[0:1])\n",
    "        self.net_16M = nn.Sequential(OrderedDict([\n",
    "            ('conv0', common_features_net[0].conv0),\n",
    "            ('norm0', common_features_net[0].norm0),\n",
    "            ('relu0', common_features_net[0].relu0)\n",
    "        ]))\n",
    "        self.net_8M = nn.Sequential(OrderedDict([\n",
    "            ('pool0', common_features_net[0].pool0)\n",
    "        ]))\n",
    "        self.net_4M = nn.Sequential(OrderedDict([\n",
    "            ('denseblock1', common_features_net[0].denseblock1),\n",
    "            ('transition1', common_features_net[0].transition1)\n",
    "        ]))\n",
    "        self.net_2M = nn.Sequential(OrderedDict([\n",
    "            ('denseblock2', common_features_net[0].denseblock2),\n",
    "            ('transition2', common_features_net[0].transition2)\n",
    "        ]))\n",
    "        self.net_1M = nn.Sequential(OrderedDict([\n",
    "            ('denseblock3', common_features_net[0].denseblock3),\n",
    "            ('transition3', common_features_net[0].transition3),\n",
    "            ('denseblock4', common_features_net[0].denseblock4)\n",
    "        ]))\n",
    "    def forward(self, ft_32M):\n",
    "        \n",
    "        pretrained_features = [0]*5\n",
    "        pretrained_features[0] = self.net_16M(ft_32M)\n",
    "        pretrained_features[1]  = self.net_8M(pretrained_features[0])\n",
    "        pretrained_features[2]  = self.net_4M(pretrained_features[1])\n",
    "        pretrained_features[3]  = self.net_2M(pretrained_features[2])\n",
    "        pretrained_features[4]  = self.net_1M(pretrained_features[3])\n",
    "        return pretrained_features.cuda(args.gpu_num)\n",
    "\n",
    "if args.debug == True:\n",
    "#     pass\n",
    "    print(densenet)\n",
    "#     common_features_net = nn.Sequential(*list(densenet.children())[0:1])\n",
    "#     net_x = nn.Sequential(OrderedDict([\n",
    "#             ('conv0', common_features_net[0].conv0),\n",
    "#     ]))\n",
    "    \n",
    "#     \"\"\"\n",
    "#         debug: copy/clone\n",
    "# #     \"\"\"\n",
    "# #     print net_x\n",
    "#     t = nn.Sequential(*list(net_x.children()))\n",
    "\n",
    "#     for param in _8M.parameters():\n",
    "#         print param.data\n",
    "\n",
    "#     for param in t.parameters():\n",
    "#         param.data = (param.data*2)\n",
    "#     print \"@@@@@@\"\n",
    "\n",
    "#     for param in t.parameters():\n",
    "#         print param.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class _DenseLayer(nn.Sequential):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.add_module('norm.1', nn.BatchNorm2d(num_input_features)),\n",
    "        self.add_module('relu.1', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv.1', nn.Conv2d(num_input_features, bn_size *\n",
    "                        growth_rate, kernel_size=1, stride=1, bias=False)),\n",
    "        self.add_module('norm.2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "        self.add_module('relu.2', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv.2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                        kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_features = super(_DenseLayer, self).forward(x)\n",
    "        if self.drop_rate > 0:\n",
    "            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)\n",
    "        return torch.cat([x, new_features], 1)\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate, bn_size, drop_rate)\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "\n",
    "class _MyTransition(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(_MyTransition, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module('pool', nn.AvgPool2d(kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "\n",
    "    \n",
    "class GradientNet(nn.Module):\n",
    "    def build_blocks(self, num_block, num_init_features):\n",
    "        bn_size = 4\n",
    "        growth_rate = 32\n",
    "        drop_rate = 0\n",
    "        num_features = num_init_features\n",
    "        features = nn.Sequential()\n",
    "        for i, num_layers in enumerate(num_block):\n",
    "            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n",
    "                                bn_size=bn_size, growth_rate=growth_rate, drop_rate=drop_rate)\n",
    "            features.add_module('denseblock%d' % (i + 1), block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            \n",
    "            trans = _MyTransition(num_input_features=num_features, num_output_features=num_features // 2)\n",
    "            features.add_module('transition%d' % (i + 1), trans)\n",
    "            num_features = num_features // 2\n",
    "        return features.cuda(args.gpu_num)\n",
    "    \n",
    "    def __init__(self, pretrained_model):\n",
    "        super(GradientNet, self).__init__()\n",
    "        self.block_config = [(3,3,3),(6,6,6),(12,12,12),(16,16,16),(24,24,24)]\n",
    "        self.num_input_features = [64,64,128,256,1024]\n",
    "        self.upsample_config = [2,4,8,16,32]\n",
    "        \n",
    "        self.pretrained_model = pretrained_model\n",
    "        \n",
    "        self.denseblocks = [nn.Sequential()] * len(self.block_config)\n",
    "        for i in range(0, len(self.block_config)):\n",
    "            self.denseblocks[i] = self.build_blocks(self.block_config[i], self.num_input_features[i])\n",
    "#         self.tmplayer = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.upsamples = [0] * len(self.block_config)\n",
    "        stride = 2\n",
    "        self.num_upsample_input_features = [92,176,352,480,800]\n",
    "        for i in range(0, len(self.block_config)):\n",
    "            self.upsamples[i] = nn.ConvTranspose2d(in_channels=self.num_upsample_input_features[i], \n",
    "                                                   out_channels=3, kernel_size=self.upsample_config[i], \n",
    "                                    stride=stride, padding=0, \n",
    "                                                   output_padding=0, groups=1, bias=True, dilation=1)\n",
    "            if platform.system() == 'Linux': \n",
    "                self.upsamples[i] = self.upsamples[i].cuda(args.gpu_num)\n",
    "            stride = stride * 2\n",
    "        \n",
    "        self.merge = nn.Sequential()\n",
    "        self.merge_in_channels =  (3*len(self.block_config), 64, 32, 16)\n",
    "        self.merge_out_channels = (                      64, 32, 16,  3)\n",
    "        for i in range(0, len(self.merge_out_channels)): \n",
    "            self.merge.add_module('merge.conv{}'.format(i), \n",
    "                                  nn.Conv2d(in_channels=self.merge_in_channels[i], \n",
    "                                            out_channels=self.merge_out_channels[i], kernel_size=1))\n",
    "            self.merge.add_module('merge.relu{}'.format(i), nn.ReLU(inplace=True))\n",
    "                                    \n",
    "    def forward(self, ft_input):\n",
    "        ft_pretrained = self.pretrained_model(ft_input)\n",
    "#         if args.debug == True: \n",
    "#             for i,v in enumerate(ft_pretrained): \n",
    "#                 print '{}th ft_pretrained shape = {}'.format(i, v.data.shape)\n",
    "#         print(\"ft_pretrained[0] = \", ft_pretrained[0])\n",
    "#         print(\"denseblocks[0] = \", self.denseblocks[0])\n",
    "#         tmp1= self.tmplayer(ft_pretrained[0])\n",
    "        ft_predict = [b(ft_pretrained[i]) for i, b in enumerate(self.denseblocks)]\n",
    "#         if args.debug == True: \n",
    "#             for i,v in enumerate(ft_predict): \n",
    "#                 print '{}th ft_predict shape = {}'.format(i, v.data.shape)\n",
    "        ft_upsampled = [up(ft_predict[i]) for i, up in enumerate(self.upsamples)]\n",
    "        ft_concated = torch.cat(ft_upsampled, 1)\n",
    "        ft_merged = self.merge(ft_concated)\n",
    "        ft_output = ft_upsampled + [ft_merged]\n",
    "        for k,v in enumerate(ft_output): ft_output[k] = v.cuda(args.gpu_num)\n",
    "        return ft_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer & Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = PreTrainedModel(densenet)\n",
    "net = GradientNet(pretrained)\n",
    "\n",
    "if platform.system() == \"Linux\": \n",
    "    net = net.cuda(args.gpu_num)\n",
    "mse_losses = [nn.MSELoss()] * 6\n",
    "optimizer = optim.SGD(net.parameters(), lr=args.base_lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-16587eca898f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mft_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m#             if epoch >= 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lwp/workspace/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-4d86465eca17>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ft_input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mft_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mft_pretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;31m#         if args.debug == True:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m#             for i,v in enumerate(ft_pretrained):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lwp/workspace/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-042fbd3c114d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ft_32M)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mpretrained_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_2M\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mpretrained_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_1M\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpretrained_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "args.display_curindex = 0\n",
    "for epoch in range(args.epoches):\n",
    "    print('epoch: {}'.format(epoch))\n",
    "    run_losses = [0] * len(args.training_thresholds)\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        if test_scene[0] == 'alley_1':\n",
    "            print('alley_1 yes')\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if platform.system() == 'Linux':\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "            gt_albedo = gt_albedo.cuda(args.gpu_num)\n",
    "            gt_shading = gt_shading.cuda(args.gpu_num)\n",
    "        \n",
    "        run_losses = [Variable(torch.Tensor([0])).cuda(args.gpu_num)] * len(mse_losses)\n",
    "        for (i,threshold) in enumerate(args.training_thresholds):\n",
    "            if epoch >= threshold:\n",
    "                optimizer.zero_grad()\n",
    "                ft_predict = net(input_img)\n",
    "#             if epoch >= 0:\n",
    "                if i == 5: s = 1.\n",
    "                else: s = (2**(i+1))\n",
    "                gt = gt_albedo.cpu().data.numpy()\n",
    "                n,c,h,w = gt.shape\n",
    "                gt = gt[0,:,:,:]\n",
    "                gt = gt.transpose((1,2,0))\n",
    "                _, _, h2, w2 = ft_predict[i].cpu().data.numpy().shape\n",
    "                gt = cv2.resize(gt, (h2,w2))\n",
    "                gt = cv2.resize(gt, (h,w))\n",
    "                gt = gt.transpose((2,0,1))\n",
    "                gt = gt[np.newaxis, :]\n",
    "                gt = Variable(torch.from_numpy(gt))\n",
    "                if platform.system() == \"Linux\": gt = gt.cuda(args.gpu_num)\n",
    "                run_losses[i] = mse_losses[i](ft_predict[i], gt)\n",
    "                run_losses[i].backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        \n",
    "        if args.display_curindex % args.display_interval == 0:\n",
    "            loss_output = 'ind: ' + str(args.display_curindex)\n",
    "            for i,v in enumerate(run_losses):\n",
    "                if i == len(run_losses)-1: \n",
    "                    loss_output += ' merged: %6f' % (run_losses[-1].data.cpu().numpy()[0])\n",
    "                    continue\n",
    "                loss_output += ' %2dM: %6f' % ((2**(4-i)), (run_losses[i].cpu().data.numpy()[0]))\n",
    "            print(loss_output)\n",
    "        args.display_curindex += 1\n",
    "        \n",
    "    # save at every epoch\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'args' : args,\n",
    "        'state_dict': net.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }, 'snapshot/snapshot-{}.pth.tar'.format(epoch))\n",
    "    \n",
    "    # test \n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if platform.system() == 'Linux':\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "        ft_test = net(input_img)\n",
    "        for k,v in enumerate(ft_test):\n",
    "            v = v[0].cpu().data.numpy()\n",
    "            v = v.transpose(1,2,0)\n",
    "            print(v.shape, v.min(), v.max())\n",
    "            cv2.imwrite('snapshot/snapshot-{}-{}.png'.format(epoch, k), v*255)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named graphviz",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7784240a69a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgraphviz\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDigraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named graphviz"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.creator)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
