{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, platform, datetime, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import functional as F\n",
    "# import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc\n",
    "\n",
    "from myimagefolder import MyImageFolder\n",
    "from mymodel import GradientNet\n",
    "from myargs import Args\n",
    "from myutils import MyUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('debian', 'jessie/sid', '')\n"
     ]
    }
   ],
   "source": [
    "myutils = MyUtils()\n",
    "\n",
    "args = Args()\n",
    "args.test_scene = 'alley_1'\n",
    "args.arch = \"densenet121\"\n",
    "args.epoches = 500\n",
    "args.epoches_unary_threshold = 0\n",
    "args.image_h = 256\n",
    "args.image_w = 256\n",
    "args.img_extentions = [\"png\"]\n",
    "args.training_thresholds = [250,200,150,50,0,300]\n",
    "args.base_lr = 1\n",
    "args.lr = args.base_lr\n",
    "args.snapshot_interval = 5000\n",
    "args.debug = True\n",
    "args.gpu_num = 2\n",
    "\n",
    "# growth_rate = (4*(2**(args.gpu_num)))\n",
    "gradient=False\n",
    "transition_scale=2\n",
    "pretrained_scale=4\n",
    "growth_rate = 32\n",
    "writer_comment = 'deconv_ks_8'\n",
    "deconv_ks=8\n",
    "\n",
    "offset = 0.\n",
    "if gradient == True: offset = 0.5\n",
    "\n",
    "args.display_interval = 50\n",
    "args.display_curindex = 0\n",
    "\n",
    "system_ = platform.system()\n",
    "system_dist, system_version, _ = platform.dist()\n",
    "if system_ == \"Darwin\": \n",
    "    args.train_dir = '/Volumes/Transcend/dataset/sintel2'\n",
    "    args.pretrained = False\n",
    "elif platform.dist() ==  ('debian', 'jessie/sid', ''):\n",
    "    args.train_dir = '/home/lwp/workspace/sintel2'\n",
    "    args.pretrained = True\n",
    "elif platform.dist() == ('debian', 'stretch/sid', ''):\n",
    "    args.train_dir = '/home/cad/lwp/workspace/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "\n",
    "if platform.system() == 'Linux': use_gpu = True\n",
    "else: use_gpu = False\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.gpu_num)\n",
    "    \n",
    "\n",
    "print(platform.dist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = MyImageFolder(args.train_dir, 'train',\n",
    "                       transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ), random_crop=True, \n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "test_dataset = MyImageFolder(args.train_dir, 'test', \n",
    "                       transforms.Compose(\n",
    "        [transforms.CenterCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ), random_crop=False,\n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset,1,True,num_workers=1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "[Defination](https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py)\n",
    "* DenseNet-121: num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16)\n",
    "    * First Convolution: 32M -> 16M -> 8M\n",
    "    * every transition: 8M -> 4M -> 2M (downsample 1/2, except the last block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenet = models.__dict__[args.arch](pretrained=args.pretrained)\n",
    "\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if use_gpu: densenet.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ ConvTranspose2d weight 0.002867696673382022\n",
      "_ ConvTranspose2d weight 0.002867696673382022\n",
      "_ ConvTranspose2d weight 0.003031695312954162\n",
      "_ ConvTranspose2d weight 0.003031695312954162\n",
      "_ ConvTranspose2d weight 0.004419417382415922\n"
     ]
    }
   ],
   "source": [
    "ss = 6\n",
    "s0 = ss*5\n",
    "# s0 = 2\n",
    "\n",
    "args.display_curindex = 0\n",
    "args.base_lr = 0.05\n",
    "args.display_interval = 20\n",
    "args.momentum = 0.9\n",
    "args.epoches = 240\n",
    "args.training_thresholds = [0,0,0,0,0,s0]\n",
    "args.training_merge_thresholds = [s0+ss*3*3,s0+ss*2*3, s0+ss*1*3, s0, -1, s0+ss*4*3]\n",
    "args.power = 0.5\n",
    "\n",
    "\n",
    "\n",
    "# pretrained = PreTrainedModel(densenet)\n",
    "# if use_gpu: \n",
    "#     pretrained.cuda()\n",
    "\n",
    "\n",
    "net = GradientNet(densenet=densenet, growth_rate=growth_rate, \n",
    "                  transition_scale=transition_scale, pretrained_scale=pretrained_scale,\n",
    "                 gradient=gradient, deconv_ks=deconv_ks)\n",
    "if use_gpu:\n",
    "    net.cuda()\n",
    "\n",
    "if use_gpu: \n",
    "    mse_losses = [nn.MSELoss().cuda()] * 6\n",
    "    test_losses = [nn.MSELoss().cuda()] * 6\n",
    "    mse_merge_losses = [nn.MSELoss().cuda()] * 6\n",
    "    test_merge_losses = [nn.MSELoss().cuda()] * 6\n",
    "else:\n",
    "    mse_losses = [nn.MSELoss()] * 6\n",
    "    mse_merge_losses = [nn.MSELoss()] * 6\n",
    "    test_losses = [nn.MSELoss()] * 6\n",
    "    test_merge_losses = [nn.MSELoss()] * 6    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(epoch, go_through_merge=False, phase='train'):\n",
    "    if phase == 'train': net.train()\n",
    "    else: net.eval()\n",
    "    \n",
    "    test_losses_trainphase = [0] * len(args.training_thresholds)\n",
    "    test_cnts_trainphase   = [0.00001] * len(args.training_thresholds)  \n",
    "    test_merge_losses_trainphase = [0] * len(args.training_thresholds)\n",
    "    test_merge_cnts_trainphase   = [0.00001] * len(args.training_thresholds)\n",
    "    \n",
    "    for ind, data in enumerate(test_loader, 0):\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "        \n",
    "#         pretrained.train(); ft_pretreained = pretrained(input_img)\n",
    "        ft_test, merged_RGB = net(input_img, go_through_merge=go_through_merge)\n",
    "            \n",
    "        for i,v in enumerate(ft_test):\n",
    "            if epoch < args.training_thresholds[i]: continue\n",
    "            if i == 5: s = 1\n",
    "            else: s = (2**(i+1))\n",
    "            gt0 = gt_albedo.cpu().data.numpy()\n",
    "            n,c,h,w = gt0.shape\n",
    "            gt, display = myutils.processGt(gt0, scale_factor=s, gd=gradient, return_image=True)\n",
    "            gt_mg, display_mg = myutils.processGt(gt0, scale_factor=s//2, gd=gradient, return_image=True)\n",
    "            \n",
    "            if use_gpu: \n",
    "                gt = gt.cuda()\n",
    "                gt_mg = gt_mg.cuda()\n",
    "            \n",
    "            if i != 5: \n",
    "                loss = mse_losses[i](ft_test[i], gt)\n",
    "                test_losses_trainphase[i] += loss.data.cpu().numpy()[0]\n",
    "                test_cnts_trainphase[i] += 1\n",
    "            \n",
    "            if go_through_merge != False and i != 4:\n",
    "                if ((go_through_merge == '32M') or\n",
    "                    (go_through_merge == '16M' and i != 5) or  \n",
    "                    (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                    (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                    (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "                    if i==5: gt2=gt\n",
    "                    else: gt2=gt_mg\n",
    "#                     print(i)\n",
    "#                     print('merge size', merged_RGB[i].size())\n",
    "#                     print('gt2 size', gt2.size())\n",
    "                    loss = mse_merge_losses[i](merged_RGB[i], gt2)\n",
    "                    test_merge_losses_trainphase[i] += loss.data.cpu().numpy()[0]\n",
    "                    test_merge_cnts_trainphase[i] += 1\n",
    "            \n",
    "\n",
    "            \n",
    "            if ind == 0: \n",
    "                if i != 5:\n",
    "                    v = v[0].cpu().data.numpy()\n",
    "                    v = v.transpose(1,2,0)\n",
    "                    v = v[:,:,0:3]\n",
    "                    cv2.imwrite('snapshot{}/test-phase_{}-{}-{}.png'.format(args.gpu_num, phase, epoch, i), (v[:,:,::-1]+offset)*255)\n",
    "                if go_through_merge != False and i != 4:\n",
    "                    if ((go_through_merge == '32M') or\n",
    "                    (go_through_merge == '16M' and i != 5) or  \n",
    "                    (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                    (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                    (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "                        v = merged_RGB[i][0].cpu().data.numpy()\n",
    "                        v = v.transpose(1,2,0)\n",
    "                        v = v[:,:,0:3]\n",
    "                        cv2.imwrite('snapshot{}/test-mg-phase_{}-{}-{}.png'.format(args.gpu_num, phase, epoch, i), (v[:,:,::-1]+offset)*255)\n",
    "                    \n",
    "    run_losses = test_losses_trainphase\n",
    "    run_cnts = test_cnts_trainphase\n",
    "    writer.add_scalars('16M loss', {'test 16M phase {}'.format(phase): np.array([run_losses[0]/ run_cnts[0]])}, global_step=epoch)  \n",
    "    writer.add_scalars('8M loss', {'test 8M phase {}'.format(phase): np.array([run_losses[1]/ run_cnts[1]])}, global_step=epoch) \n",
    "    writer.add_scalars('4M loss', {'test 4M phase {}'.format(phase): np.array([run_losses[2]/ run_cnts[2]])}, global_step=epoch) \n",
    "    writer.add_scalars('2M loss', {'test 2M ': np.array([run_losses[3]/ run_cnts[3]])}, global_step=epoch) \n",
    "    writer.add_scalars('1M loss', {'test 1M phase {}'.format(phase): np.array([run_losses[4]/ run_cnts[4]])}, global_step=epoch) \n",
    "    writer.add_scalars('merged loss', {'test merged phase {}'.format(phase): np.array([run_losses[5]/ run_cnts[5]])}, global_step=epoch)\n",
    "    \n",
    "    run_losses = test_merge_losses_trainphase\n",
    "    run_cnts = test_merge_cnts_trainphase\n",
    "    writer.add_scalars('16M loss', {'mg test 16M phase {}'.format(phase): np.array([run_losses[0]/ run_cnts[0]])}, global_step=epoch)  \n",
    "    writer.add_scalars('8M loss', {'mg test 8M phase {}'.format(phase): np.array([run_losses[1]/ run_cnts[1]])}, global_step=epoch) \n",
    "    writer.add_scalars('4M loss', {'mg test 4M phase {}'.format(phase): np.array([run_losses[2]/ run_cnts[2]])}, global_step=epoch) \n",
    "    writer.add_scalars('2M loss', {'mg test 2M ': np.array([run_losses[3]/ run_cnts[3]])}, global_step=epoch) \n",
    "    writer.add_scalars('1M loss', {'mg test 1M phase {}'.format(phase): np.array([run_losses[4]/ run_cnts[4]])}, global_step=epoch) \n",
    "    writer.add_scalars('merged loss', {'mg test merged phase {}'.format(phase): np.array([run_losses[5]/ run_cnts[5]])}, global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [2017-12-12 15:51:03]\n",
      " 16M: 0.044779  8M: 0.044469  4M: 0.044478  2M: 0.042394  1M: 0.041049 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 1 [2017-12-12 15:52:21]\n",
      " 16M: 0.029744  8M: 0.031700  4M: 0.033917  2M: 0.036005  1M: 0.035106 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 2 [2017-12-12 15:53:38]\n",
      " 16M: 0.024183  8M: 0.024196  4M: 0.025284  2M: 0.032436  1M: 0.032831 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 3 [2017-12-12 15:54:55]\n",
      " 16M: 0.020454  8M: 0.020052  4M: 0.022068  2M: 0.029257  1M: 0.032964 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 4 [2017-12-12 15:56:12]\n",
      " 16M: 0.016141  8M: 0.016512  4M: 0.017161  2M: 0.022403  1M: 0.026175 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 5 [2017-12-12 15:57:35]\n",
      " 16M: 0.014111  8M: 0.014734  4M: 0.015243  2M: 0.018968  1M: 0.021324 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 6 [2017-12-12 15:58:53]\n",
      " 16M: 0.013383  8M: 0.013378  4M: 0.014453  2M: 0.017718  1M: 0.019220 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 7 [2017-12-12 16:00:10]\n",
      " 16M: 0.012830  8M: 0.013023  4M: 0.013270  2M: 0.015624  1M: 0.017234 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 8 [2017-12-12 16:01:28]\n",
      " 16M: 0.011638  8M: 0.011444  4M: 0.011213  2M: 0.012823  1M: 0.013991 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 9 [2017-12-12 16:02:45]\n",
      " 16M: 0.011490  8M: 0.011272  4M: 0.011181  2M: 0.012286  1M: 0.013336 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 10 [2017-12-12 16:04:08]\n",
      " 16M: 0.010601  8M: 0.010669  4M: 0.010276  2M: 0.011708  1M: 0.012343 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 11 [2017-12-12 16:05:26]\n",
      " 16M: 0.009788  8M: 0.010012  4M: 0.009279  2M: 0.010826  1M: 0.011553 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 12 [2017-12-12 16:06:42]\n",
      " 16M: 0.009568  8M: 0.009249  4M: 0.008812  2M: 0.010153  1M: 0.010724 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 13 [2017-12-12 16:07:58]\n",
      " 16M: 0.009298  8M: 0.009057  4M: 0.008486  2M: 0.009863  1M: 0.010344 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 14 [2017-12-12 16:09:14]\n",
      " 16M: 0.008983  8M: 0.008656  4M: 0.007966  2M: 0.009517  1M: 0.010124 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 15 [2017-12-12 16:10:36]\n",
      " 16M: 0.008821  8M: 0.008608  4M: 0.007667  2M: 0.009271  1M: 0.009484 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 16 [2017-12-12 16:11:52]\n",
      " 16M: 0.008475  8M: 0.008194  4M: 0.007451  2M: 0.008979  1M: 0.009494 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 17 [2017-12-12 16:13:08]\n",
      " 16M: 0.007979  8M: 0.007740  4M: 0.006972  2M: 0.008597  1M: 0.008985 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 18 [2017-12-12 16:14:25]\n",
      " 16M: 0.008258  8M: 0.007960  4M: 0.007167  2M: 0.008604  1M: 0.009330 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 19 [2017-12-12 16:15:41]\n",
      " 16M: 0.008139  8M: 0.007862  4M: 0.006984  2M: 0.008306  1M: 0.008988 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 20 [2017-12-12 16:17:03]\n",
      " 16M: 0.007565  8M: 0.007434  4M: 0.006698  2M: 0.007859  1M: 0.008458 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 21 [2017-12-12 16:18:19]\n",
      " 16M: 0.007385  8M: 0.007222  4M: 0.006395  2M: 0.007588  1M: 0.008200 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 22 [2017-12-12 16:19:35]\n",
      " 16M: 0.007287  8M: 0.007078  4M: 0.006311  2M: 0.007337  1M: 0.008405 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 23 [2017-12-12 16:20:52]\n",
      " 16M: 0.007324  8M: 0.007188  4M: 0.006308  2M: 0.007167  1M: 0.008061 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 24 [2017-12-12 16:22:08]\n",
      " 16M: 0.007184  8M: 0.006825  4M: 0.005956  2M: 0.006878  1M: 0.007505 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 25 [2017-12-12 16:23:29]\n",
      " 16M: 0.007025  8M: 0.006884  4M: 0.005996  2M: 0.006920  1M: 0.007530 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 26 [2017-12-12 16:24:45]\n",
      " 16M: 0.006854  8M: 0.006634  4M: 0.005754  2M: 0.006752  1M: 0.007133 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 27 [2017-12-12 16:26:02]\n",
      " 16M: 0.006717  8M: 0.006523  4M: 0.005562  2M: 0.006503  1M: 0.007156 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 28 [2017-12-12 16:27:18]\n",
      " 16M: 0.006536  8M: 0.006316  4M: 0.005546  2M: 0.006402  1M: 0.006877 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 29 [2017-12-12 16:28:34]\n",
      " 16M: 0.006423  8M: 0.006198  4M: 0.005352  2M: 0.006078  1M: 0.006351 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 30 [2017-12-12 16:29:55]\n",
      " 16M: 0.008021  8M: 0.007766  4M: 0.006825  2M: 0.009198  1M: 0.008836 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.030889 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 31 [2017-12-12 16:31:28]\n",
      " 16M: 0.007722  8M: 0.007380  4M: 0.006550  2M: 0.010426  1M: 0.009235 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.020150 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 32 [2017-12-12 16:33:02]\n",
      " 16M: 0.007576  8M: 0.007210  4M: 0.006183  2M: 0.009302  1M: 0.009310 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.016143 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 33 [2017-12-12 16:34:35]\n",
      " 16M: 0.007166  8M: 0.006773  4M: 0.005905  2M: 0.007711  1M: 0.008016 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.013461 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 34 [2017-12-12 16:36:09]\n",
      " 16M: 0.006532  8M: 0.006299  4M: 0.005538  2M: 0.006957  1M: 0.007154 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.011950 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 35 [2017-12-12 16:37:49]\n",
      " 16M: 0.006309  8M: 0.006100  4M: 0.005386  2M: 0.006842  1M: 0.007135 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.012071 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 36 [2017-12-12 16:39:22]\n",
      " 16M: 0.008157  8M: 0.008344  4M: 0.006849  2M: 0.008351  1M: 0.008609 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.014355 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 37 [2017-12-12 16:40:55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.007360  8M: 0.007245  4M: 0.006043  2M: 0.007862  1M: 0.008436 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.013035 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 38 [2017-12-12 16:42:30]\n",
      " 16M: 0.006705  8M: 0.006462  4M: 0.005644  2M: 0.007059  1M: 0.007466 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.011224 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 39 [2017-12-12 16:44:02]\n",
      " 16M: 0.006701  8M: 0.006521  4M: 0.005606  2M: 0.007053  1M: 0.007344 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.011131 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 40 [2017-12-12 16:45:40]\n",
      " 16M: 0.006334  8M: 0.006137  4M: 0.005195  2M: 0.006444  1M: 0.006555 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.010163 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 41 [2017-12-12 16:47:14]\n",
      " 16M: 0.005974  8M: 0.005788  4M: 0.004939  2M: 0.006021  1M: 0.006822 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.009560 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 42 [2017-12-12 16:48:48]\n",
      " 16M: 0.007149  8M: 0.006900  4M: 0.006117  2M: 0.007516  1M: 0.007875 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.011888 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 43 [2017-12-12 16:50:22]\n",
      " 16M: 0.006793  8M: 0.006616  4M: 0.005624  2M: 0.007059  1M: 0.007364 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.010844 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 44 [2017-12-12 16:51:55]\n",
      " 16M: 0.006928  8M: 0.006644  4M: 0.005466  2M: 0.006646  1M: 0.006887 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.010000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 45 [2017-12-12 16:53:34]\n",
      " 16M: 0.006450  8M: 0.006168  4M: 0.005384  2M: 0.006348  1M: 0.006514 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.009519 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 46 [2017-12-12 16:55:08]\n",
      " 16M: 0.006044  8M: 0.005833  4M: 0.004862  2M: 0.005884  1M: 0.005955 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.008922 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 47 [2017-12-12 16:56:42]\n",
      " 16M: 0.005649  8M: 0.005547  4M: 0.004828  2M: 0.005903  1M: 0.006009 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.008854 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 48 [2017-12-12 16:58:15]\n",
      " 16M: 0.007112  8M: 0.006997  4M: 0.008424  2M: 0.007647  1M: 0.007190 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.027277 mg  2M: 0.011557 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 49 [2017-12-12 17:00:10]\n",
      " 16M: 0.007079  8M: 0.006644  4M: 0.007672  2M: 0.009240  1M: 0.007249 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.016530 mg  2M: 0.012248 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 50 [2017-12-12 17:02:13]\n",
      " 16M: 0.006461  8M: 0.006210  4M: 0.006445  2M: 0.008600  1M: 0.006757 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.013337 mg  2M: 0.011550 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 51 [2017-12-12 17:04:11]\n",
      " 16M: 0.005964  8M: 0.005722  4M: 0.005621  2M: 0.007220  1M: 0.006204 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.011308 mg  2M: 0.010066 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 52 [2017-12-12 17:06:07]\n",
      " 16M: 0.005869  8M: 0.005601  4M: 0.005286  2M: 0.006744  1M: 0.005955 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.009727 mg  2M: 0.009492 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 53 [2017-12-12 17:08:02]\n",
      " 16M: 0.006163  8M: 0.005815  4M: 0.005053  2M: 0.006414  1M: 0.005875 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.008955 mg  2M: 0.009020 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 54 [2017-12-12 17:09:56]\n",
      " 16M: 0.006713  8M: 0.006561  4M: 0.006540  2M: 0.007696  1M: 0.007039 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.011472 mg  2M: 0.010832 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 55 [2017-12-12 17:11:57]\n",
      " 16M: 0.006262  8M: 0.006152  4M: 0.006060  2M: 0.007449  1M: 0.006604 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.010162 mg  2M: 0.010058 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 56 [2017-12-12 17:13:50]\n",
      " 16M: 0.006217  8M: 0.005965  4M: 0.005754  2M: 0.007183  1M: 0.006539 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.009854 mg  2M: 0.009862 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 57 [2017-12-12 17:15:45]\n",
      " 16M: 0.005862  8M: 0.005646  4M: 0.005175  2M: 0.006365  1M: 0.005979 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.008483 mg  2M: 0.009003 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 58 [2017-12-12 17:17:40]\n",
      " 16M: 0.005675  8M: 0.005381  4M: 0.004883  2M: 0.005928  1M: 0.005634 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.007849 mg  2M: 0.008437 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 59 [2017-12-12 17:19:36]\n",
      " 16M: 0.005444  8M: 0.005101  4M: 0.004592  2M: 0.005559  1M: 0.005453 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.007541 mg  2M: 0.008196 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 60 [2017-12-12 17:21:37]\n",
      " 16M: 0.005920  8M: 0.005689  4M: 0.005709  2M: 0.006240  1M: 0.006033 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.009219 mg  2M: 0.009166 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 61 [2017-12-12 17:23:32]\n",
      " 16M: 0.006191  8M: 0.006084  4M: 0.005309  2M: 0.006568  1M: 0.006065 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.008651 mg  2M: 0.009196 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 62 [2017-12-12 17:25:27]\n",
      " 16M: 0.006041  8M: 0.005689  4M: 0.005290  2M: 0.006175  1M: 0.005857 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.008088 mg  2M: 0.008861 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 63 [2017-12-12 17:27:23]\n",
      " 16M: 0.005420  8M: 0.005324  4M: 0.004685  2M: 0.005542  1M: 0.005493 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.007425 mg  2M: 0.008186 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 64 [2017-12-12 17:29:18]\n",
      " 16M: 0.005290  8M: 0.005110  4M: 0.004550  2M: 0.005375  1M: 0.005158 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.006983 mg  2M: 0.007816 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 65 [2017-12-12 17:31:18]\n",
      " 16M: 0.005260  8M: 0.005064  4M: 0.004481  2M: 0.005147  1M: 0.005078 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.006778 mg  2M: 0.007608 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 66 [2017-12-12 17:33:13]\n",
      " 16M: 0.005950  8M: 0.008470  4M: 0.007981  2M: 0.006479  1M: 0.006257 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.024986 mg  4M: 0.011496 mg  2M: 0.009750 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 67 [2017-12-12 17:35:38]\n",
      " 16M: 0.005722  8M: 0.007630  4M: 0.007998  2M: 0.008527  1M: 0.006695 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.014775 mg  4M: 0.011605 mg  2M: 0.011136 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 68 [2017-12-12 17:38:03]\n",
      " 16M: 0.005741  8M: 0.006801  4M: 0.006049  2M: 0.006570  1M: 0.006301 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.011669 mg  4M: 0.008922 mg  2M: 0.009287 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 69 [2017-12-12 17:40:29]\n",
      " 16M: 0.005391  8M: 0.005904  4M: 0.005153  2M: 0.005773  1M: 0.005617 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.009137 mg  4M: 0.007691 mg  2M: 0.008408 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 70 [2017-12-12 17:42:59]\n",
      " 16M: 0.005207  8M: 0.005538  4M: 0.004795  2M: 0.005874  1M: 0.005692 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.008313 mg  4M: 0.007357 mg  2M: 0.008399 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 71 [2017-12-12 17:45:24]\n",
      " 16M: 0.004982  8M: 0.005296  4M: 0.004645  2M: 0.005425  1M: 0.005296 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.008172 mg  4M: 0.007164 mg  2M: 0.007954 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 72 [2017-12-12 17:47:51]\n",
      " 16M: 0.005905  8M: 0.006625  4M: 0.005745  2M: 0.006292  1M: 0.005781 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.009900 mg  4M: 0.008249 mg  2M: 0.008765 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 73 [2017-12-12 17:50:14]\n",
      " 16M: 0.005610  8M: 0.006153  4M: 0.005461  2M: 0.006228  1M: 0.005759 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.008920 mg  4M: 0.008026 mg  2M: 0.008672 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 74 [2017-12-12 17:52:39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.005748  8M: 0.006065  4M: 0.005216  2M: 0.006087  1M: 0.005749 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.008429 mg  4M: 0.007763 mg  2M: 0.008639 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 75 [2017-12-12 17:55:09]\n",
      " 16M: 0.005345  8M: 0.005430  4M: 0.004709  2M: 0.005613  1M: 0.005098 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.007565 mg  4M: 0.007041 mg  2M: 0.007951 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 76 [2017-12-12 17:57:34]\n",
      " 16M: 0.005166  8M: 0.005237  4M: 0.004553  2M: 0.005361  1M: 0.005134 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.006910 mg  4M: 0.006719 mg  2M: 0.007803 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 77 [2017-12-12 18:00:01]\n",
      " 16M: 0.005080  8M: 0.005118  4M: 0.004406  2M: 0.005206  1M: 0.004828 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.006840 mg  4M: 0.006637 mg  2M: 0.007626 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 78 [2017-12-12 18:02:25]\n",
      " 16M: 0.005948  8M: 0.006507  4M: 0.005440  2M: 0.006226  1M: 0.005636 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.008529 mg  4M: 0.007864 mg  2M: 0.008535 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 79 [2017-12-12 18:04:50]\n",
      " 16M: 0.005396  8M: 0.005597  4M: 0.004796  2M: 0.005478  1M: 0.005158 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.007446 mg  4M: 0.007138 mg  2M: 0.007865 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 80 [2017-12-12 18:07:21]\n",
      " 16M: 0.005412  8M: 0.005464  4M: 0.004740  2M: 0.005337  1M: 0.005305 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.007132 mg  4M: 0.007016 mg  2M: 0.007920 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 81 [2017-12-12 18:09:46]\n",
      " 16M: 0.005172  8M: 0.005198  4M: 0.004439  2M: 0.005093  1M: 0.004959 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.006704 mg  4M: 0.006596 mg  2M: 0.007540 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 82 [2017-12-12 18:12:12]\n",
      " 16M: 0.004874  8M: 0.004900  4M: 0.004214  2M: 0.004870  1M: 0.004623 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.006216 mg  4M: 0.006272 mg  2M: 0.007184 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 83 [2017-12-12 18:14:37]\n",
      " 16M: 0.004872  8M: 0.004774  4M: 0.004134  2M: 0.004878  1M: 0.004633 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.006099 mg  4M: 0.006097 mg  2M: 0.007134 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 84 [2017-12-12 18:17:03]\n",
      " 16M: 0.006565  8M: 0.006875  4M: 0.007361  2M: 0.006067  1M: 0.005509 merged: 0.000000\n",
      " mg 16M: 0.020634 mg  8M: 0.010266 mg  4M: 0.009716 mg  2M: 0.009166 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 85 [2017-12-12 18:20:45]\n",
      " 16M: 0.005933  8M: 0.006068  4M: 0.005534  2M: 0.006045  1M: 0.005360 merged: 0.000000\n",
      " mg 16M: 0.010790 mg  8M: 0.007931 mg  4M: 0.007853 mg  2M: 0.008553 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 86 [2017-12-12 18:24:20]\n",
      " 16M: 0.005804  8M: 0.006113  4M: 0.005115  2M: 0.005734  1M: 0.005101 merged: 0.000000\n",
      " mg 16M: 0.009373 mg  8M: 0.007630 mg  4M: 0.007235 mg  2M: 0.008001 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 87 [2017-12-12 18:27:56]\n",
      " 16M: 0.005251  8M: 0.005304  4M: 0.004480  2M: 0.005237  1M: 0.004890 merged: 0.000000\n",
      " mg 16M: 0.007795 mg  8M: 0.006691 mg  4M: 0.006540 mg  2M: 0.007536 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 88 [2017-12-12 18:31:31]\n",
      " 16M: 0.004886  8M: 0.004905  4M: 0.004260  2M: 0.004875  1M: 0.004624 merged: 0.000000\n",
      " mg 16M: 0.006751 mg  8M: 0.006098 mg  4M: 0.006232 mg  2M: 0.007228 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 89 [2017-12-12 18:35:04]\n",
      " 16M: 0.004882  8M: 0.004953  4M: 0.004197  2M: 0.004835  1M: 0.004577 merged: 0.000000\n",
      " mg 16M: 0.006584 mg  8M: 0.006317 mg  4M: 0.006101 mg  2M: 0.007260 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 90 [2017-12-12 18:38:46]\n",
      " 16M: 0.006102  8M: 0.005984  4M: 0.005497  2M: 0.005894  1M: 0.005097 merged: 0.000000\n",
      " mg 16M: 0.009185 mg  8M: 0.007761 mg  4M: 0.007739 mg  2M: 0.008280 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 91 [2017-12-12 18:42:21]\n",
      " 16M: 0.005923  8M: 0.005831  4M: 0.006278  2M: 0.005976  1M: 0.005380 merged: 0.000000\n",
      " mg 16M: 0.008452 mg  8M: 0.007568 mg  4M: 0.007844 mg  2M: 0.008319 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 92 [2017-12-12 18:45:54]\n",
      " 16M: 0.005558  8M: 0.005484  4M: 0.005229  2M: 0.005468  1M: 0.005092 merged: 0.000000\n",
      " mg 16M: 0.007232 mg  8M: 0.006960 mg  4M: 0.007170 mg  2M: 0.007846 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 93 [2017-12-12 18:49:27]\n",
      " 16M: 0.005221  8M: 0.005205  4M: 0.004684  2M: 0.005169  1M: 0.004774 merged: 0.000000\n",
      " mg 16M: 0.006395 mg  8M: 0.006335 mg  4M: 0.006602 mg  2M: 0.007507 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 94 [2017-12-12 18:53:00]\n",
      " 16M: 0.004809  8M: 0.004735  4M: 0.004291  2M: 0.004834  1M: 0.004692 merged: 0.000000\n",
      " mg 16M: 0.005884 mg  8M: 0.005909 mg  4M: 0.006255 mg  2M: 0.007248 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 95 [2017-12-12 18:56:40]\n",
      " 16M: 0.004622  8M: 0.004583  4M: 0.004109  2M: 0.004622  1M: 0.004375 merged: 0.000000\n",
      " mg 16M: 0.005537 mg  8M: 0.005607 mg  4M: 0.005911 mg  2M: 0.006946 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 96 [2017-12-12 19:00:14]\n",
      " 16M: 0.005821  8M: 0.005964  4M: 0.005301  2M: 0.005405  1M: 0.004995 merged: 0.000000\n",
      " mg 16M: 0.007263 mg  8M: 0.007107 mg  4M: 0.007120 mg  2M: 0.007735 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 97 [2017-12-12 19:03:47]\n",
      " 16M: 0.005420  8M: 0.005232  4M: 0.004687  2M: 0.005089  1M: 0.005009 merged: 0.000000\n",
      " mg 16M: 0.006557 mg  8M: 0.006431 mg  4M: 0.006648 mg  2M: 0.007594 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 98 [2017-12-12 19:07:21]\n",
      " 16M: 0.005158  8M: 0.004960  4M: 0.004316  2M: 0.004829  1M: 0.004915 merged: 0.000000\n",
      " mg 16M: 0.006097 mg  8M: 0.006074 mg  4M: 0.006352 mg  2M: 0.007278 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 99 [2017-12-12 19:10:55]\n",
      " 16M: 0.004923  8M: 0.004780  4M: 0.004294  2M: 0.004769  1M: 0.004685 merged: 0.000000\n",
      " mg 16M: 0.005686 mg  8M: 0.005747 mg  4M: 0.006131 mg  2M: 0.007150 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 100 [2017-12-12 19:14:35]\n",
      " 16M: 0.004708  8M: 0.004551  4M: 0.003991  2M: 0.004545  1M: 0.004496 merged: 0.000000\n",
      " mg 16M: 0.005319 mg  8M: 0.005502 mg  4M: 0.005843 mg  2M: 0.006915 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 101 [2017-12-12 19:18:09]\n",
      " 16M: 0.004627  8M: 0.004607  4M: 0.004098  2M: 0.004440  1M: 0.004498 merged: 0.000000\n",
      " mg 16M: 0.005405 mg  8M: 0.005509 mg  4M: 0.005828 mg  2M: 0.006889 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 102 [2017-12-12 19:21:42]\n",
      " 16M: 0.007251  8M: 0.007453  4M: 0.008199  2M: 0.006240  1M: 0.005741 merged: 0.000000\n",
      " mg 16M: 0.012265 mg  8M: 0.009260 mg  4M: 0.009518 mg  2M: 0.009135 mg  1M: 0.000000mg merged: 0.012265\n",
      "epoch: 103 [2017-12-12 19:26:11]\n",
      " 16M: 0.008246  8M: 0.009462  4M: 0.007800  2M: 0.007413  1M: 0.006571 merged: 0.000000\n",
      " mg 16M: 0.013856 mg  8M: 0.012118 mg  4M: 0.011792 mg  2M: 0.011252 mg  1M: 0.000000mg merged: 0.013856\n",
      "epoch: 104 [2017-12-12 19:30:37]\n",
      " 16M: 0.007549  8M: 0.008122  4M: 0.007308  2M: 0.008238  1M: 0.006671 merged: 0.000000\n",
      " mg 16M: 0.011579 mg  8M: 0.009971 mg  4M: 0.010145 mg  2M: 0.010823 mg  1M: 0.000000mg merged: 0.011579\n",
      "epoch: 105 [2017-12-12 19:35:13]\n",
      " 16M: 0.006633  8M: 0.006916  4M: 0.005782  2M: 0.006212  1M: 0.006026 merged: 0.000000\n",
      " mg 16M: 0.009185 mg  8M: 0.008107 mg  4M: 0.008194 mg  2M: 0.008968 mg  1M: 0.000000mg merged: 0.009185\n",
      "epoch: 106 [2017-12-12 19:39:46]\n",
      " 16M: 0.006463  8M: 0.006718  4M: 0.005555  2M: 0.006185  1M: 0.006426 merged: 0.000000\n",
      " mg 16M: 0.008203 mg  8M: 0.007994 mg  4M: 0.008186 mg  2M: 0.009120 mg  1M: 0.000000mg merged: 0.008203\n",
      "epoch: 107 [2017-12-12 19:44:14]\n",
      " 16M: 0.006049  8M: 0.006316  4M: 0.005280  2M: 0.006622  1M: 0.005531 merged: 0.000000\n",
      " mg 16M: 0.007701 mg  8M: 0.007357 mg  4M: 0.007582 mg  2M: 0.008698 mg  1M: 0.000000mg merged: 0.007701\n",
      "epoch: 108 [2017-12-12 19:48:45]\n",
      " 16M: 0.005757  8M: 0.006109  4M: 0.004865  2M: 0.006798  1M: 0.005429 merged: 0.000000\n",
      " mg 16M: 0.006923 mg  8M: 0.007014 mg  4M: 0.007247 mg  2M: 0.008798 mg  1M: 0.000000mg merged: 0.006923\n",
      "epoch: 109 [2017-12-12 19:53:17]\n",
      " 16M: 0.005358  8M: 0.005516  4M: 0.004921  2M: 0.005522  1M: 0.005286 merged: 0.000000\n",
      " mg 16M: 0.006495 mg  8M: 0.006575 mg  4M: 0.006937 mg  2M: 0.007954 mg  1M: 0.000000mg merged: 0.006495\n",
      "epoch: 110 [2017-12-12 19:58:00]\n",
      " 16M: 0.005350  8M: 0.005270  4M: 0.004554  2M: 0.005212  1M: 0.005259 merged: 0.000000\n",
      " mg 16M: 0.006269 mg  8M: 0.006191 mg  4M: 0.006497 mg  2M: 0.007562 mg  1M: 0.000000mg merged: 0.006269\n",
      "epoch: 111 [2017-12-12 20:02:29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.005478  8M: 0.005750  4M: 0.004978  2M: 0.005467  1M: 0.005164 merged: 0.000000\n",
      " mg 16M: 0.006445 mg  8M: 0.006585 mg  4M: 0.006765 mg  2M: 0.007834 mg  1M: 0.000000mg merged: 0.006445\n",
      "epoch: 112 [2017-12-12 20:07:01]\n",
      " 16M: 0.005596  8M: 0.005490  4M: 0.004622  2M: 0.005273  1M: 0.004785 merged: 0.000000\n",
      " mg 16M: 0.006208 mg  8M: 0.006382 mg  4M: 0.006573 mg  2M: 0.007608 mg  1M: 0.000000mg merged: 0.006208\n",
      "epoch: 113 [2017-12-12 20:11:31]\n",
      " 16M: 0.005223  8M: 0.005065  4M: 0.004623  2M: 0.005191  1M: 0.004972 merged: 0.000000\n",
      " mg 16M: 0.005945 mg  8M: 0.006061 mg  4M: 0.006479 mg  2M: 0.007557 mg  1M: 0.000000mg merged: 0.005945\n",
      "epoch: 114 [2017-12-12 20:16:00]\n",
      " 16M: 0.005105  8M: 0.004973  4M: 0.004367  2M: 0.005096  1M: 0.004627 merged: 0.000000\n",
      " mg 16M: 0.005676 mg  8M: 0.005893 mg  4M: 0.006284 mg  2M: 0.007319 mg  1M: 0.000000mg merged: 0.005676\n",
      "epoch: 115 [2017-12-12 20:20:36]\n",
      " 16M: 0.004973  8M: 0.004853  4M: 0.004189  2M: 0.004754  1M: 0.004529 merged: 0.000000\n",
      " mg 16M: 0.005359 mg  8M: 0.005682 mg  4M: 0.006085 mg  2M: 0.007110 mg  1M: 0.000000mg merged: 0.005359\n",
      "epoch: 116 [2017-12-12 20:25:07]\n",
      " 16M: 0.005111  8M: 0.005150  4M: 0.004323  2M: 0.004946  1M: 0.004693 merged: 0.000000\n",
      " mg 16M: 0.005761 mg  8M: 0.005886 mg  4M: 0.006197 mg  2M: 0.007230 mg  1M: 0.000000mg merged: 0.005761\n",
      "epoch: 117 [2017-12-12 20:29:37]\n",
      " 16M: 0.005082  8M: 0.004935  4M: 0.004399  2M: 0.004968  1M: 0.004454 merged: 0.000000\n",
      " mg 16M: 0.005575 mg  8M: 0.005779 mg  4M: 0.006213 mg  2M: 0.007247 mg  1M: 0.000000mg merged: 0.005575\n",
      "epoch: 118 [2017-12-12 20:34:07]\n",
      " 16M: 0.004931  8M: 0.004978  4M: 0.004226  2M: 0.004859  1M: 0.004617 merged: 0.000000\n",
      " mg 16M: 0.005258 mg  8M: 0.005663 mg  4M: 0.006057 mg  2M: 0.007188 mg  1M: 0.000000mg merged: 0.005258\n",
      "epoch: 119 [2017-12-12 20:38:37]\n",
      " 16M: 0.004926  8M: 0.005092  4M: 0.004109  2M: 0.004700  1M: 0.004573 merged: 0.000000\n",
      " mg 16M: 0.005314 mg  8M: 0.005754 mg  4M: 0.006058 mg  2M: 0.007054 mg  1M: 0.000000mg merged: 0.005314\n",
      "epoch: 120 [2017-12-12 20:43:13]\n",
      " 16M: 0.004959  8M: 0.004922  4M: 0.004164  2M: 0.004778  1M: 0.004559 merged: 0.000000\n",
      " mg 16M: 0.005210 mg  8M: 0.005655 mg  4M: 0.005988 mg  2M: 0.006999 mg  1M: 0.000000mg merged: 0.005210\n",
      "epoch: 121 [2017-12-12 20:47:45]\n",
      " 16M: 0.004811  8M: 0.004841  4M: 0.004071  2M: 0.004621  1M: 0.004341 merged: 0.000000\n",
      " mg 16M: 0.005105 mg  8M: 0.005521 mg  4M: 0.005892 mg  2M: 0.006926 mg  1M: 0.000000mg merged: 0.005105\n",
      "epoch: 122 [2017-12-12 20:52:23]\n",
      " 16M: 0.004931  8M: 0.004921  4M: 0.004109  2M: 0.004600  1M: 0.004686 merged: 0.000000\n",
      " mg 16M: 0.005219 mg  8M: 0.005599 mg  4M: 0.005954 mg  2M: 0.006960 mg  1M: 0.000000mg merged: 0.005219\n",
      "epoch: 123 [2017-12-12 20:56:54]\n",
      " 16M: 0.004661  8M: 0.004710  4M: 0.003995  2M: 0.004532  1M: 0.004514 merged: 0.000000\n",
      " mg 16M: 0.004845 mg  8M: 0.005355 mg  4M: 0.005778 mg  2M: 0.006813 mg  1M: 0.000000mg merged: 0.004845\n",
      "epoch: 124 [2017-12-12 21:01:31]\n",
      " 16M: 0.004799  8M: 0.004783  4M: 0.003930  2M: 0.004474  1M: 0.004328 merged: 0.000000\n",
      " mg 16M: 0.004942 mg  8M: 0.005350 mg  4M: 0.005694 mg  2M: 0.006687 mg  1M: 0.000000mg merged: 0.004942\n",
      "epoch: 125 [2017-12-12 21:06:17]\n",
      " 16M: 0.004766  8M: 0.004638  4M: 0.003924  2M: 0.004433  1M: 0.004378 merged: 0.000000\n",
      " mg 16M: 0.004841 mg  8M: 0.005301 mg  4M: 0.005641 mg  2M: 0.006658 mg  1M: 0.000000mg merged: 0.004841\n",
      "epoch: 126 [2017-12-12 21:10:56]\n",
      " 16M: 0.004610  8M: 0.004631  4M: 0.003843  2M: 0.004412  1M: 0.004336 merged: 0.000000\n",
      " mg 16M: 0.004669 mg  8M: 0.005191 mg  4M: 0.005584 mg  2M: 0.006698 mg  1M: 0.000000mg merged: 0.004669\n",
      "epoch: 127 [2017-12-12 21:15:35]\n",
      " 16M: 0.004731  8M: 0.004685  4M: 0.003934  2M: 0.004580  1M: 0.004401 merged: 0.000000\n",
      " mg 16M: 0.004770 mg  8M: 0.005257 mg  4M: 0.005725 mg  2M: 0.006822 mg  1M: 0.000000mg merged: 0.004770\n",
      "epoch: 128 [2017-12-12 21:20:12]\n",
      " 16M: 0.004510  8M: 0.004498  4M: 0.003783  2M: 0.004488  1M: 0.004231 merged: 0.000000\n",
      " mg 16M: 0.004536 mg  8M: 0.005068 mg  4M: 0.005517 mg  2M: 0.006619 mg  1M: 0.000000mg merged: 0.004536\n",
      "epoch: 129 [2017-12-12 21:24:51]\n",
      " 16M: 0.004596  8M: 0.004478  4M: 0.003810  2M: 0.004400  1M: 0.004084 merged: 0.000000\n",
      " mg 16M: 0.004541 mg  8M: 0.005078 mg  4M: 0.005567 mg  2M: 0.006631 mg  1M: 0.000000mg merged: 0.004541\n",
      "epoch: 130 [2017-12-12 21:29:37]\n",
      " 16M: 0.004350  8M: 0.004412  4M: 0.003827  2M: 0.004283  1M: 0.004149 merged: 0.000000\n",
      " mg 16M: 0.004449 mg  8M: 0.004998 mg  4M: 0.005481 mg  2M: 0.006471 mg  1M: 0.000000mg merged: 0.004449\n",
      "epoch: 131 [2017-12-12 21:34:15]\n",
      " 16M: 0.004623  8M: 0.004607  4M: 0.003812  2M: 0.004400  1M: 0.004325 merged: 0.000000\n",
      " mg 16M: 0.004689 mg  8M: 0.005232 mg  4M: 0.005600 mg  2M: 0.006696 mg  1M: 0.000000mg merged: 0.004689\n",
      "epoch: 132 [2017-12-12 21:38:53]\n",
      " 16M: 0.004525  8M: 0.004385  4M: 0.003730  2M: 0.004308  1M: 0.004243 merged: 0.000000\n",
      " mg 16M: 0.004411 mg  8M: 0.004956 mg  4M: 0.005438 mg  2M: 0.006560 mg  1M: 0.000000mg merged: 0.004411\n",
      "epoch: 133 [2017-12-12 21:43:31]\n",
      " 16M: 0.004310  8M: 0.004342  4M: 0.003656  2M: 0.004249  1M: 0.004116 merged: 0.000000\n",
      " mg 16M: 0.004408 mg  8M: 0.004858 mg  4M: 0.005313 mg  2M: 0.006423 mg  1M: 0.000000mg merged: 0.004408\n",
      "epoch: 134 [2017-12-12 21:48:10]\n",
      " 16M: 0.004520  8M: 0.004358  4M: 0.003673  2M: 0.004274  1M: 0.004104 merged: 0.000000\n",
      " mg 16M: 0.004373 mg  8M: 0.004880 mg  4M: 0.005324 mg  2M: 0.006389 mg  1M: 0.000000mg merged: 0.004373\n",
      "epoch: 135 [2017-12-12 21:52:56]\n",
      " 16M: 0.004416  8M: 0.004385  4M: 0.003768  2M: 0.004329  1M: 0.004155 merged: 0.000000\n",
      " mg 16M: 0.004310 mg  8M: 0.004924 mg  4M: 0.005439 mg  2M: 0.006531 mg  1M: 0.000000mg merged: 0.004310\n",
      "epoch: 136 [2017-12-12 21:57:33]\n",
      " 16M: 0.004328  8M: 0.004269  4M: 0.003746  2M: 0.004779  1M: 0.004279 merged: 0.000000\n",
      " mg 16M: 0.004357 mg  8M: 0.004919 mg  4M: 0.005538 mg  2M: 0.006844 mg  1M: 0.000000mg merged: 0.004357\n",
      "epoch: 137 [2017-12-12 22:02:13]\n",
      " 16M: 0.004401  8M: 0.004337  4M: 0.004007  2M: 0.004482  1M: 0.004077 merged: 0.000000\n",
      " mg 16M: 0.004430 mg  8M: 0.004968 mg  4M: 0.005529 mg  2M: 0.006566 mg  1M: 0.000000mg merged: 0.004430\n",
      "epoch: 138 [2017-12-12 22:06:52]\n",
      " 16M: 0.004346  8M: 0.004326  4M: 0.004051  2M: 0.004590  1M: 0.004133 merged: 0.000000\n",
      " mg 16M: 0.004330 mg  8M: 0.004963 mg  4M: 0.005627 mg  2M: 0.006765 mg  1M: 0.000000mg merged: 0.004330\n",
      "epoch: 139 [2017-12-12 22:11:30]\n",
      " 16M: 0.004348  8M: 0.004263  4M: 0.003771  2M: 0.004537  1M: 0.004049 merged: 0.000000\n",
      " mg 16M: 0.004283 mg  8M: 0.004845 mg  4M: 0.005375 mg  2M: 0.006546 mg  1M: 0.000000mg merged: 0.004283\n",
      "epoch: 140 [2017-12-12 22:16:16]\n",
      " 16M: 0.004427  8M: 0.004314  4M: 0.003778  2M: 0.004230  1M: 0.003984 merged: 0.000000\n",
      " mg 16M: 0.004390 mg  8M: 0.004901 mg  4M: 0.005354 mg  2M: 0.006379 mg  1M: 0.000000mg merged: 0.004390\n",
      "epoch: 141 [2017-12-12 22:20:54]\n",
      " 16M: 0.004175  8M: 0.004149  4M: 0.003604  2M: 0.004159  1M: 0.004026 merged: 0.000000\n",
      " mg 16M: 0.004107 mg  8M: 0.004757 mg  4M: 0.005246 mg  2M: 0.006304 mg  1M: 0.000000mg merged: 0.004107\n",
      "epoch: 142 [2017-12-12 22:25:32]\n",
      " 16M: 0.004165  8M: 0.004180  4M: 0.003598  2M: 0.004259  1M: 0.003911 merged: 0.000000\n",
      " mg 16M: 0.004039 mg  8M: 0.004697 mg  4M: 0.005217 mg  2M: 0.006375 mg  1M: 0.000000mg merged: 0.004039\n",
      "epoch: 143 [2017-12-12 22:30:10]\n",
      " 16M: 0.004078  8M: 0.004064  4M: 0.003634  2M: 0.004044  1M: 0.003925 merged: 0.000000\n",
      " mg 16M: 0.004045 mg  8M: 0.004693 mg  4M: 0.005271 mg  2M: 0.006236 mg  1M: 0.000000mg merged: 0.004045\n",
      "epoch: 144 [2017-12-12 22:34:49]\n",
      " 16M: 0.004088  8M: 0.004023  4M: 0.003499  2M: 0.004046  1M: 0.003936 merged: 0.000000\n",
      " mg 16M: 0.003957 mg  8M: 0.004609 mg  4M: 0.005124 mg  2M: 0.006231 mg  1M: 0.000000mg merged: 0.003957\n",
      "epoch: 145 [2017-12-12 22:39:35]\n",
      " 16M: 0.004103  8M: 0.004079  4M: 0.003522  2M: 0.003976  1M: 0.003854 merged: 0.000000\n",
      " mg 16M: 0.004045 mg  8M: 0.004644 mg  4M: 0.005113 mg  2M: 0.006106 mg  1M: 0.000000mg merged: 0.004045\n",
      "epoch: 146 [2017-12-12 22:44:11]\n",
      " 16M: 0.004010  8M: 0.003988  4M: 0.003393  2M: 0.003999  1M: 0.003799 merged: 0.000000\n",
      " mg 16M: 0.003873 mg  8M: 0.004470 mg  4M: 0.004920 mg  2M: 0.006022 mg  1M: 0.000000mg merged: 0.003873\n",
      "epoch: 147 [2017-12-12 22:48:41]\n",
      " 16M: 0.004076  8M: 0.004023  4M: 0.003505  2M: 0.005038  1M: 0.003849 merged: 0.000000\n",
      " mg 16M: 0.003968 mg  8M: 0.004600 mg  4M: 0.005170 mg  2M: 0.006710 mg  1M: 0.000000mg merged: 0.003968\n",
      "epoch: 148 [2017-12-12 22:53:10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.004107  8M: 0.004129  4M: 0.003565  2M: 0.004534  1M: 0.003876 merged: 0.000000\n",
      " mg 16M: 0.004025 mg  8M: 0.004667 mg  4M: 0.005222 mg  2M: 0.006428 mg  1M: 0.000000mg merged: 0.004025\n",
      "epoch: 149 [2017-12-12 22:57:41]\n",
      " 16M: 0.003934  8M: 0.003890  4M: 0.003452  2M: 0.004280  1M: 0.003732 merged: 0.000000\n",
      " mg 16M: 0.003863 mg  8M: 0.004524 mg  4M: 0.005065 mg  2M: 0.006225 mg  1M: 0.000000mg merged: 0.003863\n",
      "epoch: 150 [2017-12-12 23:02:19]\n",
      " 16M: 0.003976  8M: 0.003988  4M: 0.003463  2M: 0.004211  1M: 0.003809 merged: 0.000000\n",
      " mg 16M: 0.003880 mg  8M: 0.004601 mg  4M: 0.005125 mg  2M: 0.006312 mg  1M: 0.000000mg merged: 0.003880\n",
      "epoch: 151 [2017-12-12 23:06:50]\n",
      " 16M: 0.004095  8M: 0.004043  4M: 0.003451  2M: 0.004192  1M: 0.003788 merged: 0.000000\n",
      " mg 16M: 0.003901 mg  8M: 0.004577 mg  4M: 0.005102 mg  2M: 0.006240 mg  1M: 0.000000mg merged: 0.003901\n",
      "epoch: 152 [2017-12-12 23:11:19]\n",
      " 16M: 0.003976  8M: 0.004005  4M: 0.003394  2M: 0.004105  1M: 0.003695 merged: 0.000000\n",
      " mg 16M: 0.003846 mg  8M: 0.004518 mg  4M: 0.005015 mg  2M: 0.006140 mg  1M: 0.000000mg merged: 0.003846\n",
      "epoch: 153 [2017-12-12 23:15:49]\n",
      " 16M: 0.004015  8M: 0.003935  4M: 0.003360  2M: 0.004002  1M: 0.003735 merged: 0.000000\n",
      " mg 16M: 0.003891 mg  8M: 0.004519 mg  4M: 0.005026 mg  2M: 0.006100 mg  1M: 0.000000mg merged: 0.003891\n",
      "epoch: 154 [2017-12-12 23:20:19]\n",
      " 16M: 0.003953  8M: 0.003853  4M: 0.003222  2M: 0.003985  1M: 0.003775 merged: 0.000000\n",
      " mg 16M: 0.003701 mg  8M: 0.004378 mg  4M: 0.004837 mg  2M: 0.006011 mg  1M: 0.000000mg merged: 0.003701\n",
      "epoch: 155 [2017-12-12 23:24:56]\n",
      " 16M: 0.003895  8M: 0.003915  4M: 0.003284  2M: 0.003929  1M: 0.003638 merged: 0.000000\n",
      " mg 16M: 0.003746 mg  8M: 0.004419 mg  4M: 0.004908 mg  2M: 0.005958 mg  1M: 0.000000mg merged: 0.003746\n",
      "epoch: 156 [2017-12-12 23:29:25]\n",
      " 16M: 0.003962  8M: 0.004186  4M: 0.003333  2M: 0.003945  1M: 0.003767 merged: 0.000000\n",
      " mg 16M: 0.003797 mg  8M: 0.004533 mg  4M: 0.004930 mg  2M: 0.006041 mg  1M: 0.000000mg merged: 0.003797\n",
      "epoch: 157 [2017-12-12 23:33:54]\n",
      " 16M: 0.004051  8M: 0.004094  4M: 0.003396  2M: 0.003980  1M: 0.003631 merged: 0.000000\n",
      " mg 16M: 0.003825 mg  8M: 0.004511 mg  4M: 0.004960 mg  2M: 0.006032 mg  1M: 0.000000mg merged: 0.003825\n",
      "epoch: 158 [2017-12-12 23:38:23]\n",
      " 16M: 0.003947  8M: 0.003978  4M: 0.003329  2M: 0.003911  1M: 0.003771 merged: 0.000000\n",
      " mg 16M: 0.003755 mg  8M: 0.004460 mg  4M: 0.004939 mg  2M: 0.006002 mg  1M: 0.000000mg merged: 0.003755\n",
      "epoch: 159 [2017-12-12 23:42:54]\n",
      " 16M: 0.003797  8M: 0.003780  4M: 0.003225  2M: 0.003875  1M: 0.003606 merged: 0.000000\n",
      " mg 16M: 0.003620 mg  8M: 0.004327 mg  4M: 0.004864 mg  2M: 0.005979 mg  1M: 0.000000mg merged: 0.003620\n",
      "epoch: 160 [2017-12-12 23:47:29]\n",
      " 16M: 0.003923  8M: 0.003931  4M: 0.003311  2M: 0.003901  1M: 0.003786 merged: 0.000000\n",
      " mg 16M: 0.003729 mg  8M: 0.004444 mg  4M: 0.004959 mg  2M: 0.006125 mg  1M: 0.000000mg merged: 0.003729\n",
      "epoch: 161 [2017-12-12 23:51:58]\n",
      " 16M: 0.003838  8M: 0.003829  4M: 0.003322  2M: 0.003800  1M: 0.003606 merged: 0.000000\n",
      " mg 16M: 0.003649 mg  8M: 0.004355 mg  4M: 0.004886 mg  2M: 0.005948 mg  1M: 0.000000mg merged: 0.003649\n",
      "epoch: 162 [2017-12-12 23:56:28]\n",
      " 16M: 0.003779  8M: 0.003729  4M: 0.003177  2M: 0.003767  1M: 0.003562 merged: 0.000000\n",
      " mg 16M: 0.003602 mg  8M: 0.004303 mg  4M: 0.004788 mg  2M: 0.005825 mg  1M: 0.000000mg merged: 0.003602\n",
      "epoch: 163 [2017-12-13 00:00:59]\n",
      " 16M: 0.003842  8M: 0.003861  4M: 0.003281  2M: 0.003947  1M: 0.003809 merged: 0.000000\n",
      " mg 16M: 0.003635 mg  8M: 0.004348 mg  4M: 0.004882 mg  2M: 0.006065 mg  1M: 0.000000mg merged: 0.003635\n",
      "epoch: 164 [2017-12-13 00:05:31]\n",
      " 16M: 0.003836  8M: 0.003826  4M: 0.003238  2M: 0.003844  1M: 0.003654 merged: 0.000000\n",
      " mg 16M: 0.003632 mg  8M: 0.004332 mg  4M: 0.004836 mg  2M: 0.005977 mg  1M: 0.000000mg merged: 0.003632\n",
      "epoch: 165 [2017-12-13 00:10:09]\n",
      " 16M: 0.003845  8M: 0.003809  4M: 0.003232  2M: 0.003773  1M: 0.003564 merged: 0.000000\n",
      " mg 16M: 0.003562 mg  8M: 0.004243 mg  4M: 0.004729 mg  2M: 0.005768 mg  1M: 0.000000mg merged: 0.003562\n",
      "epoch: 166 [2017-12-13 00:14:40]\n",
      " 16M: 0.003906  8M: 0.003852  4M: 0.003282  2M: 0.003812  1M: 0.003661 merged: 0.000000\n",
      " mg 16M: 0.003646 mg  8M: 0.004351 mg  4M: 0.004895 mg  2M: 0.005987 mg  1M: 0.000000mg merged: 0.003646\n",
      "epoch: 167 [2017-12-13 00:19:11]\n",
      " 16M: 0.003765  8M: 0.003737  4M: 0.003270  2M: 0.003795  1M: 0.003633 merged: 0.000000\n",
      " mg 16M: 0.003611 mg  8M: 0.004319 mg  4M: 0.004918 mg  2M: 0.005984 mg  1M: 0.000000mg merged: 0.003611\n",
      "epoch: 168 [2017-12-13 00:23:43]\n",
      " 16M: 0.003871  8M: 0.003743  4M: 0.003198  2M: 0.003683  1M: 0.003571 merged: 0.000000\n",
      " mg 16M: 0.003566 mg  8M: 0.004245 mg  4M: 0.004741 mg  2M: 0.005740 mg  1M: 0.000000mg merged: 0.003566\n",
      "epoch: 169 [2017-12-13 00:28:13]\n",
      " 16M: 0.003743  8M: 0.003723  4M: 0.003204  2M: 0.003729  1M: 0.003533 merged: 0.000000\n",
      " mg 16M: 0.003504 mg  8M: 0.004212 mg  4M: 0.004724 mg  2M: 0.005779 mg  1M: 0.000000mg merged: 0.003504\n",
      "epoch: 170 [2017-12-13 00:32:50]\n",
      " 16M: 0.003736  8M: 0.003688  4M: 0.003175  2M: 0.003687  1M: 0.003554 merged: 0.000000\n",
      " mg 16M: 0.003517 mg  8M: 0.004238 mg  4M: 0.004739 mg  2M: 0.005758 mg  1M: 0.000000mg merged: 0.003517\n",
      "epoch: 171 [2017-12-13 00:37:20]\n",
      " 16M: 0.003612  8M: 0.003660  4M: 0.003118  2M: 0.003625  1M: 0.003445 merged: 0.000000\n",
      " mg 16M: 0.003427 mg  8M: 0.004139 mg  4M: 0.004628 mg  2M: 0.005639 mg  1M: 0.000000mg merged: 0.003427\n",
      "epoch: 172 [2017-12-13 00:41:50]\n",
      " 16M: 0.003780  8M: 0.003715  4M: 0.003156  2M: 0.003619  1M: 0.003547 merged: 0.000000\n",
      " mg 16M: 0.003525 mg  8M: 0.004215 mg  4M: 0.004720 mg  2M: 0.005725 mg  1M: 0.000000mg merged: 0.003525\n",
      "epoch: 173 [2017-12-13 00:46:22]\n",
      " 16M: 0.003631  8M: 0.003586  4M: 0.003075  2M: 0.003631  1M: 0.003461 merged: 0.000000\n",
      " mg 16M: 0.003381 mg  8M: 0.004099 mg  4M: 0.004639 mg  2M: 0.005677 mg  1M: 0.000000mg merged: 0.003381\n",
      "epoch: 174 [2017-12-13 00:50:53]\n",
      " 16M: 0.003650  8M: 0.003590  4M: 0.003077  2M: 0.003621  1M: 0.003477 merged: 0.000000\n",
      " mg 16M: 0.003410 mg  8M: 0.004106 mg  4M: 0.004618 mg  2M: 0.005631 mg  1M: 0.000000mg merged: 0.003410\n",
      "epoch: 175 [2017-12-13 00:55:30]\n",
      " 16M: 0.003645  8M: 0.003638  4M: 0.003074  2M: 0.003634  1M: 0.003440 merged: 0.000000\n",
      " mg 16M: 0.003394 mg  8M: 0.004123 mg  4M: 0.004643 mg  2M: 0.005699 mg  1M: 0.000000mg merged: 0.003394\n",
      "epoch: 176 [2017-12-13 01:00:01]\n",
      " 16M: 0.003701  8M: 0.003666  4M: 0.003128  2M: 0.003703  1M: 0.003471 merged: 0.000000\n",
      " mg 16M: 0.003407 mg  8M: 0.004116 mg  4M: 0.004651 mg  2M: 0.005730 mg  1M: 0.000000mg merged: 0.003407\n",
      "epoch: 177 [2017-12-13 01:04:32]\n",
      " 16M: 0.003625  8M: 0.003622  4M: 0.003084  2M: 0.003597  1M: 0.003429 merged: 0.000000\n",
      " mg 16M: 0.003436 mg  8M: 0.004156 mg  4M: 0.004658 mg  2M: 0.005671 mg  1M: 0.000000mg merged: 0.003436\n",
      "epoch: 178 [2017-12-13 01:09:01]\n",
      " 16M: 0.003667  8M: 0.003646  4M: 0.003163  2M: 0.003592  1M: 0.003502 merged: 0.000000\n",
      " mg 16M: 0.003453 mg  8M: 0.004138 mg  4M: 0.004618 mg  2M: 0.005640 mg  1M: 0.000000mg merged: 0.003453\n",
      "epoch: 179 [2017-12-13 01:13:32]\n",
      " 16M: 0.003628  8M: 0.003635  4M: 0.003102  2M: 0.003597  1M: 0.003422 merged: 0.000000\n",
      " mg 16M: 0.003443 mg  8M: 0.004196 mg  4M: 0.004713 mg  2M: 0.005738 mg  1M: 0.000000mg merged: 0.003443\n",
      "epoch: 180 [2017-12-13 01:18:11]\n",
      " 16M: 0.003441  8M: 0.003461  4M: 0.003000  2M: 0.003453  1M: 0.003369 merged: 0.000000\n",
      " mg 16M: 0.003241 mg  8M: 0.003966 mg  4M: 0.004512 mg  2M: 0.005485 mg  1M: 0.000000mg merged: 0.003241\n",
      "epoch: 181 [2017-12-13 01:22:42]\n",
      " 16M: 0.003589  8M: 0.003513  4M: 0.003001  2M: 0.003542  1M: 0.003408 merged: 0.000000\n",
      " mg 16M: 0.003333 mg  8M: 0.004034 mg  4M: 0.004559 mg  2M: 0.005592 mg  1M: 0.000000mg merged: 0.003333\n",
      "epoch: 182 [2017-12-13 01:27:12]\n",
      " 16M: 0.003455  8M: 0.003431  4M: 0.002980  2M: 0.003569  1M: 0.003375 merged: 0.000000\n",
      " mg 16M: 0.003249 mg  8M: 0.003971 mg  4M: 0.004529 mg  2M: 0.005614 mg  1M: 0.000000mg merged: 0.003249\n",
      "epoch: 183 [2017-12-13 01:31:42]\n",
      " 16M: 0.003573  8M: 0.003465  4M: 0.002940  2M: 0.003451  1M: 0.003407 merged: 0.000000\n",
      " mg 16M: 0.003267 mg  8M: 0.003975 mg  4M: 0.004486 mg  2M: 0.005448 mg  1M: 0.000000mg merged: 0.003267\n",
      "epoch: 184 [2017-12-13 01:36:14]\n",
      " 16M: 0.003557  8M: 0.003585  4M: 0.003014  2M: 0.003595  1M: 0.003397 merged: 0.000000\n",
      " mg 16M: 0.003386 mg  8M: 0.004106 mg  4M: 0.004563 mg  2M: 0.005538 mg  1M: 0.000000mg merged: 0.003386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 185 [2017-12-13 01:40:51]\n",
      " 16M: 0.003513  8M: 0.003519  4M: 0.002985  2M: 0.003540  1M: 0.003383 merged: 0.000000\n",
      " mg 16M: 0.003275 mg  8M: 0.004033 mg  4M: 0.004570 mg  2M: 0.005589 mg  1M: 0.000000mg merged: 0.003275\n",
      "epoch: 186 [2017-12-13 01:45:20]\n",
      " 16M: 0.003506  8M: 0.003516  4M: 0.003023  2M: 0.003517  1M: 0.003424 merged: 0.000000\n",
      " mg 16M: 0.003275 mg  8M: 0.004042 mg  4M: 0.004576 mg  2M: 0.005605 mg  1M: 0.000000mg merged: 0.003275\n",
      "epoch: 187 [2017-12-13 01:49:50]\n",
      " 16M: 0.003440  8M: 0.003450  4M: 0.002944  2M: 0.003462  1M: 0.003378 merged: 0.000000\n",
      " mg 16M: 0.003194 mg  8M: 0.003950 mg  4M: 0.004507 mg  2M: 0.005522 mg  1M: 0.000000mg merged: 0.003194\n",
      "epoch: 188 [2017-12-13 01:54:19]\n",
      " 16M: 0.003518  8M: 0.003461  4M: 0.002961  2M: 0.003514  1M: 0.003309 merged: 0.000000\n",
      " mg 16M: 0.003224 mg  8M: 0.003944 mg  4M: 0.004491 mg  2M: 0.005527 mg  1M: 0.000000mg merged: 0.003224\n",
      "epoch: 189 [2017-12-13 01:58:49]\n",
      " 16M: 0.003572  8M: 0.003501  4M: 0.002998  2M: 0.003503  1M: 0.003376 merged: 0.000000\n",
      " mg 16M: 0.003318 mg  8M: 0.004011 mg  4M: 0.004532 mg  2M: 0.005563 mg  1M: 0.000000mg merged: 0.003318\n",
      "epoch: 190 [2017-12-13 02:03:26]\n",
      " 16M: 0.003484  8M: 0.003454  4M: 0.002963  2M: 0.003402  1M: 0.003344 merged: 0.000000\n",
      " mg 16M: 0.003244 mg  8M: 0.003959 mg  4M: 0.004477 mg  2M: 0.005464 mg  1M: 0.000000mg merged: 0.003244\n",
      "epoch: 191 [2017-12-13 02:07:55]\n",
      " 16M: 0.003430  8M: 0.003475  4M: 0.002934  2M: 0.003472  1M: 0.003271 merged: 0.000000\n",
      " mg 16M: 0.003179 mg  8M: 0.003933 mg  4M: 0.004470 mg  2M: 0.005482 mg  1M: 0.000000mg merged: 0.003179\n",
      "epoch: 192 [2017-12-13 02:12:24]\n",
      " 16M: 0.003509  8M: 0.003482  4M: 0.003002  2M: 0.003507  1M: 0.003311 merged: 0.000000\n",
      " mg 16M: 0.003222 mg  8M: 0.004005 mg  4M: 0.004556 mg  2M: 0.005551 mg  1M: 0.000000mg merged: 0.003222\n",
      "epoch: 193 [2017-12-13 02:16:53]\n",
      " 16M: 0.003509  8M: 0.003417  4M: 0.002933  2M: 0.003513  1M: 0.003385 merged: 0.000000\n",
      " mg 16M: 0.003222 mg  8M: 0.003945 mg  4M: 0.004491 mg  2M: 0.005524 mg  1M: 0.000000mg merged: 0.003222\n",
      "epoch: 194 [2017-12-13 02:21:23]\n",
      " 16M: 0.003458  8M: 0.003372  4M: 0.002894  2M: 0.003357  1M: 0.003277 merged: 0.000000\n",
      " mg 16M: 0.003155 mg  8M: 0.003897 mg  4M: 0.004432 mg  2M: 0.005365 mg  1M: 0.000000mg merged: 0.003155\n",
      "epoch: 195 [2017-12-13 02:25:59]\n",
      " 16M: 0.003461  8M: 0.003404  4M: 0.002892  2M: 0.003420  1M: 0.003260 merged: 0.000000\n",
      " mg 16M: 0.003151 mg  8M: 0.003843 mg  4M: 0.004350 mg  2M: 0.005366 mg  1M: 0.000000mg merged: 0.003151\n",
      "epoch: 196 [2017-12-13 02:30:29]\n",
      " 16M: 0.003300  8M: 0.003276  4M: 0.002831  2M: 0.003261  1M: 0.003160 merged: 0.000000\n",
      " mg 16M: 0.003051 mg  8M: 0.003757 mg  4M: 0.004245 mg  2M: 0.005169 mg  1M: 0.000000mg merged: 0.003051\n",
      "epoch: 197 [2017-12-13 02:34:59]\n",
      " 16M: 0.003441  8M: 0.003428  4M: 0.002900  2M: 0.003363  1M: 0.003238 merged: 0.000000\n",
      " mg 16M: 0.003153 mg  8M: 0.003866 mg  4M: 0.004379 mg  2M: 0.005336 mg  1M: 0.000000mg merged: 0.003153\n",
      "epoch: 198 [2017-12-13 02:39:28]\n",
      " 16M: 0.003418  8M: 0.003420  4M: 0.002927  2M: 0.003424  1M: 0.003351 merged: 0.000000\n",
      " mg 16M: 0.003156 mg  8M: 0.003916 mg  4M: 0.004463 mg  2M: 0.005515 mg  1M: 0.000000mg merged: 0.003156\n",
      "epoch: 199 [2017-12-13 02:43:58]\n",
      " 16M: 0.003409  8M: 0.003532  4M: 0.002968  2M: 0.003399  1M: 0.003307 merged: 0.000000\n",
      " mg 16M: 0.003128 mg  8M: 0.003897 mg  4M: 0.004411 mg  2M: 0.005351 mg  1M: 0.000000mg merged: 0.003128\n",
      "epoch: 200 [2017-12-13 02:48:36]\n",
      " 16M: 0.003421  8M: 0.003465  4M: 0.002901  2M: 0.003389  1M: 0.003243 merged: 0.000000\n",
      " mg 16M: 0.003139 mg  8M: 0.003913 mg  4M: 0.004411 mg  2M: 0.005340 mg  1M: 0.000000mg merged: 0.003139\n",
      "epoch: 201 [2017-12-13 02:53:08]\n",
      " 16M: 0.003379  8M: 0.003391  4M: 0.002887  2M: 0.003363  1M: 0.003276 merged: 0.000000\n",
      " mg 16M: 0.003097 mg  8M: 0.003844 mg  4M: 0.004366 mg  2M: 0.005330 mg  1M: 0.000000mg merged: 0.003097\n",
      "epoch: 202 [2017-12-13 02:57:36]\n",
      " 16M: 0.003387  8M: 0.003330  4M: 0.002874  2M: 0.003342  1M: 0.003270 merged: 0.000000\n",
      " mg 16M: 0.003088 mg  8M: 0.003847 mg  4M: 0.004386 mg  2M: 0.005369 mg  1M: 0.000000mg merged: 0.003088\n",
      "epoch: 203 [2017-12-13 03:02:07]\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "writer = SummaryWriter(comment='-{}'.format(writer_comment))\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "optimizer = optim.SGD(parameters, lr=args.base_lr, momentum=args.momentum)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, beg, end, reset_lr=None, base_lr=args.base_lr):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "#         print('para gp', param_group)\n",
    "        if reset_lr != None:\n",
    "            param_group['lr'] = reset_lr\n",
    "            continue\n",
    "        param_group['lr'] = base_lr * (float(end-epoch)/(end-beg)) ** (args.power)\n",
    "        if param_group['lr'] < 1.0e-8: param_group['lr'] = 1.0e-8\n",
    "        \n",
    "\n",
    "for epoch in range(args.epoches):\n",
    "#     epoch = 234\n",
    "    net.train()\n",
    "    print('epoch: {} [{}]'.format(epoch, datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "    if epoch < args.training_thresholds[-1]: \n",
    "        adjust_learning_rate(optimizer, epoch, beg=0, end=s0-1)\n",
    "    elif epoch < args.training_merge_thresholds[-1]:\n",
    "        adjust_learning_rate(optimizer, (epoch-s0)%(ss), beg=0, end=ss-1, base_lr=args.base_lr)\n",
    "    else:\n",
    "        adjust_learning_rate(optimizer, epoch, beg=args.training_merge_thresholds[-1], end=args.epoches-1, base_lr=args.base_lr)  \n",
    "        \n",
    "        \n",
    "    if epoch < args.training_thresholds[-1]: go_through_merge = False\n",
    "    elif epoch >= args.training_merge_thresholds[5]: go_through_merge = '32M'\n",
    "    elif epoch >= args.training_merge_thresholds[0]: go_through_merge = '16M'\n",
    "    elif epoch >= args.training_merge_thresholds[1]: go_through_merge = '08M'\n",
    "    elif epoch >= args.training_merge_thresholds[2]: go_through_merge = '04M'\n",
    "    elif epoch >= args.training_merge_thresholds[3]: go_through_merge = '02M'\n",
    "\n",
    "    run_losses = [0] * len(args.training_thresholds)\n",
    "    run_cnts   = [0.00001] * len(args.training_thresholds)\n",
    "    run_merge_losses = [0] * len(args.training_thresholds)\n",
    "    run_merge_cnts   = [0.00001] * len(args.training_thresholds)\n",
    "    if (epoch in args.training_thresholds) == True: \n",
    "        adjust_learning_rate(optimizer, epoch, reset_lr=args.base_lr, beg=-1, end=-1)\n",
    "    if (epoch in args.training_merge_thresholds) == True:\n",
    "        adjust_learning_rate(optimizer, epoch, reset_lr=args.base_lr, beg=-1, end=-1)\n",
    "        \n",
    "    writer.add_scalar('learning rate', optimizer.param_groups[0]['lr'], global_step=epoch)\n",
    "    for ind, data in enumerate(train_loader, 0):\n",
    "#         if  ind == 1 : break\n",
    "        \"\"\"prepare  training data\"\"\"\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        im = input_img[0,:,:,:].numpy(); im = im.transpose(1,2,0); im = im[:,:,::-1]*255\n",
    "        input_img, gt_albedo, gt_shading = Variable(input_img), Variable(gt_albedo), Variable(gt_shading)\n",
    "        if use_gpu: input_img, gt_albedo, gt_shading = input_img.cuda(), gt_albedo.cuda(), gt_shading.cuda()\n",
    "\n",
    "        if args.display_curindex % args.display_interval == 0: cv2.imwrite('snapshot{}/input.png'.format(args.gpu_num), im)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "            \n",
    "        ft_predict, merged_RGB = net(input_img, go_through_merge=go_through_merge)\n",
    "        for i, threshold in enumerate(args.training_thresholds):\n",
    "            if epoch >= threshold:\n",
    "#             if epoch >= 0:\n",
    "                \"\"\"prepare resized gt\"\"\"\n",
    "                if i == 5: s = 1\n",
    "                else: s = (2**(i+1))\n",
    "                gt0 = gt_albedo.cpu().data.numpy()\n",
    "                n,c,h,w = gt0.shape\n",
    "                gt, display = myutils.processGt(gt0, scale_factor=s, gd=gradient, return_image=True)\n",
    "                gt_mg, display_mg = myutils.processGt(gt0, scale_factor=s//2, gd=gradient, return_image=True)\n",
    "                if use_gpu: \n",
    "                    gt = gt.cuda()\n",
    "                    gt_mg = gt_mg.cuda()\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    display = display[:,:,0:3]\n",
    "                    cv2.imwrite('snapshot{}/gt-{}-{}.png'.format(args.gpu_num, epoch, i), display[:,:,::-1]*255)                \n",
    "                \n",
    "                \"\"\"compute loss\"\"\"\n",
    "                if i != 5: \n",
    "                    loss = mse_losses[i](ft_predict[i], gt)\n",
    "                    run_losses[i] += loss.data.cpu().numpy()[0]\n",
    "                    loss.backward(retain_graph=True)\n",
    "                    run_cnts[i] += 1\n",
    "                \n",
    "                if go_through_merge != False and i != 4:\n",
    "                    if ((go_through_merge == '32M') or\n",
    "                    (go_through_merge == '16M' and i != 5) or  \n",
    "                    (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                    (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                    (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "#                         print(epoch, go_through_merge, i)\n",
    "                        \n",
    "#                         print (merged_RGB[i].cpu().data.numpy().max(), merged_RGB[i].cpu().data.numpy().min())\n",
    "                        if i==5: gt2=gt\n",
    "                        else: gt2=gt_mg\n",
    "#                         print(i)\n",
    "#                         print('merge size', merged_RGB[i].size())\n",
    "#                         print('gt2 size', gt2.size())\n",
    "                        loss = mse_merge_losses[i](merged_RGB[i], gt2)\n",
    "                        run_merge_losses[i] += loss.data.cpu().numpy()[0]\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        run_merge_cnts[i] += 1\n",
    "                \n",
    "                \"\"\"save training image\"\"\"\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    \n",
    "                    if i != 5:\n",
    "                        im = (ft_predict[i].cpu().data.numpy()[0].transpose((1,2,0))+offset) * 255\n",
    "                        im = im[:,:,0:3]\n",
    "                        \n",
    "                        cv2.imwrite('snapshot{}/train-{}-{}.png'.format(args.gpu_num, epoch, i), im[:,:,::-1])\n",
    "                    \n",
    "                    if go_through_merge != False and i != 4:\n",
    "                        if ((go_through_merge == '32M') or\n",
    "                        (go_through_merge == '16M' and i != 5) or  \n",
    "                        (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                        (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                        (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "                            im = (merged_RGB[i].cpu().data.numpy()[0].transpose((1,2,0))+offset) * 255\n",
    "                            im = im[:,:,0:3]\n",
    "                            cv2.imwrite('snapshot{}/train-mg-{}-{}.png'.format(args.gpu_num, epoch, i), im[:,:,::-1])\n",
    "        optimizer.step()\n",
    "        args.display_curindex += 1\n",
    "\n",
    "    \"\"\" every epoch \"\"\"\n",
    "#     loss_output = 'ind: ' + str(args.display_curindex)\n",
    "    loss_output = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i,v in enumerate(run_losses):\n",
    "        if i == len(run_losses)-1: \n",
    "            loss_output += ' merged: %6f' % (run_losses[i] / run_cnts[i])\n",
    "            continue\n",
    "        loss_output += ' %2dM: %6f' % ((2**(4-i)), (run_losses[i] / run_cnts[i]))\n",
    "    print(loss_output)\n",
    "    loss_output = ''\n",
    "    for i,v in enumerate(run_merge_losses):\n",
    "        if i == len(run_merge_losses)-1: \n",
    "            loss_output += 'mg merged: %6f' % (run_merge_losses[i] / run_merge_cnts[i])\n",
    "            continue\n",
    "        loss_output += ' mg %2dM: %6f' % ((2**(4-i)), (run_merge_losses[i] / run_merge_cnts[i]))\n",
    "    print(loss_output)\n",
    "    \n",
    "    \"\"\"save at every epoch\"\"\"\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'args' : args,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, 'snapshot{}/snapshot-{}.pth.tar'.format(args.gpu_num, epoch))\n",
    "    \n",
    "    # test \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        test_model(epoch, phase='train', go_through_merge=go_through_merge)\n",
    "        test_model(epoch, phase='test', go_through_merge=go_through_merge)\n",
    "\n",
    "        writer.add_scalars('16M loss', {'train 16M ': np.array([run_losses[0]/ run_cnts[0]])}, global_step=epoch)  \n",
    "        writer.add_scalars('8M loss', {'train 8M ': np.array([run_losses[1]/ run_cnts[1]])}, global_step=epoch) \n",
    "        writer.add_scalars('4M loss', {'train 4M ': np.array([run_losses[2]/ run_cnts[2]])}, global_step=epoch) \n",
    "        writer.add_scalars('2M loss', {'train 2M ': np.array([run_losses[3]/ run_cnts[3]])}, global_step=epoch) \n",
    "        writer.add_scalars('1M loss', {'train 1M ': np.array([run_losses[4]/ run_cnts[4]])}, global_step=epoch) \n",
    "        writer.add_scalars('merged loss', {'train merged ': np.array([run_losses[5]/ run_cnts[5]])}, global_step=epoch) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"10240,10240\"), format='svg')\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = Variable(torch.zeros(1,3,256,256))\n",
    "# y = net(x.cuda())\n",
    "# g = make_dot(y[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g.render('net-transition_scale_{}'.format(transition_scale)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
