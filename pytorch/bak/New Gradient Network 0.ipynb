{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, platform, datetime, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import functional as F\n",
    "# import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc\n",
    "\n",
    "from myimagefolder import MyImageFolder\n",
    "from mymodel import GradientNet\n",
    "from myargs import Args\n",
    "from myutils import MyUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('debian', 'jessie/sid', '')\n"
     ]
    }
   ],
   "source": [
    "myutils = MyUtils()\n",
    "\n",
    "args = Args()\n",
    "args.test_scene = 'alley_1'\n",
    "args.arch = \"densenet121\"\n",
    "args.epoches = 500\n",
    "args.epoches_unary_threshold = 0\n",
    "args.image_h = 256\n",
    "args.image_w = 256\n",
    "args.img_extentions = [\"png\"]\n",
    "args.training_thresholds = [250,200,150,50,0,300]\n",
    "args.base_lr = 1\n",
    "args.lr = args.base_lr\n",
    "args.snapshot_interval = 5000\n",
    "args.debug = True\n",
    "args.gpu_num = 0\n",
    "\n",
    "# growth_rate = (4*(2**(args.gpu_num)))\n",
    "gradient=False\n",
    "transition_scale=2\n",
    "pretrained_scale=4\n",
    "growth_rate = 32\n",
    "writer_comment = 'deconv_ks_6'\n",
    "deconv_ks=6\n",
    "\n",
    "offset = 0.\n",
    "if gradient == True: offset = 0.5\n",
    "\n",
    "args.display_interval = 50\n",
    "args.display_curindex = 0\n",
    "\n",
    "system_ = platform.system()\n",
    "system_dist, system_version, _ = platform.dist()\n",
    "if system_ == \"Darwin\": \n",
    "    args.train_dir = '/Volumes/Transcend/dataset/sintel2'\n",
    "    args.pretrained = False\n",
    "elif platform.dist() ==  ('debian', 'jessie/sid', ''):\n",
    "    args.train_dir = '/home/lwp/workspace/sintel2'\n",
    "    args.pretrained = True\n",
    "elif platform.dist() == ('debian', 'stretch/sid', ''):\n",
    "    args.train_dir = '/home/cad/lwp/workspace/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "\n",
    "if platform.system() == 'Linux': use_gpu = True\n",
    "else: use_gpu = False\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.gpu_num)\n",
    "    \n",
    "\n",
    "print(platform.dist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = MyImageFolder(args.train_dir, 'train',\n",
    "                       transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ), random_crop=True, \n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "test_dataset = MyImageFolder(args.train_dir, 'test', \n",
    "                       transforms.Compose(\n",
    "        [transforms.CenterCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ), random_crop=False,\n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset,1,True,num_workers=1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "[Defination](https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py)\n",
    "* DenseNet-121: num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16)\n",
    "    * First Convolution: 32M -> 16M -> 8M\n",
    "    * every transition: 8M -> 4M -> 2M (downsample 1/2, except the last block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenet = models.__dict__[args.arch](pretrained=args.pretrained)\n",
    "\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if use_gpu: densenet.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ ConvTranspose2d weight 0.002867696673382022\n",
      "_ ConvTranspose2d weight 0.002867696673382022\n",
      "_ ConvTranspose2d weight 0.003031695312954162\n",
      "_ ConvTranspose2d weight 0.003031695312954162\n",
      "_ ConvTranspose2d weight 0.004419417382415922\n"
     ]
    }
   ],
   "source": [
    "ss = 6\n",
    "s0 = ss*5\n",
    "# s0 = 2\n",
    "\n",
    "args.display_curindex = 0\n",
    "args.base_lr = 0.05\n",
    "args.display_interval = 20\n",
    "args.momentum = 0.9\n",
    "args.epoches = 240\n",
    "args.training_thresholds = [0,0,0,0,0,s0]\n",
    "args.training_merge_thresholds = [s0+ss*3*3,s0+ss*2*3, s0+ss*1*3, s0, -1, s0+ss*4*3]\n",
    "args.power = 0.5\n",
    "\n",
    "\n",
    "\n",
    "# pretrained = PreTrainedModel(densenet)\n",
    "# if use_gpu: \n",
    "#     pretrained.cuda()\n",
    "\n",
    "\n",
    "net = GradientNet(densenet=densenet, growth_rate=growth_rate, \n",
    "                  transition_scale=transition_scale, pretrained_scale=pretrained_scale,\n",
    "                 gradient=gradient, deconv_ks=6)\n",
    "if use_gpu:\n",
    "    net.cuda()\n",
    "\n",
    "if use_gpu: \n",
    "    mse_losses = [nn.MSELoss().cuda()] * 6\n",
    "    test_losses = [nn.MSELoss().cuda()] * 6\n",
    "    mse_merge_losses = [nn.MSELoss().cuda()] * 6\n",
    "    test_merge_losses = [nn.MSELoss().cuda()] * 6\n",
    "else:\n",
    "    mse_losses = [nn.MSELoss()] * 6\n",
    "    mse_merge_losses = [nn.MSELoss()] * 6\n",
    "    test_losses = [nn.MSELoss()] * 6\n",
    "    test_merge_losses = [nn.MSELoss()] * 6    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(epoch, go_through_merge=False, phase='train'):\n",
    "    if phase == 'train': net.train()\n",
    "    else: net.eval()\n",
    "    \n",
    "    test_losses_trainphase = [0] * len(args.training_thresholds)\n",
    "    test_cnts_trainphase   = [0.00001] * len(args.training_thresholds)  \n",
    "    test_merge_losses_trainphase = [0] * len(args.training_thresholds)\n",
    "    test_merge_cnts_trainphase   = [0.00001] * len(args.training_thresholds)\n",
    "    \n",
    "    for ind, data in enumerate(test_loader, 0):\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "        \n",
    "#         pretrained.train(); ft_pretreained = pretrained(input_img)\n",
    "        ft_test, merged_RGB = net(input_img, go_through_merge=go_through_merge)\n",
    "            \n",
    "        for i,v in enumerate(ft_test):\n",
    "            if epoch < args.training_thresholds[i]: continue\n",
    "            if i == 5: s = 1\n",
    "            else: s = (2**(i+1))\n",
    "            gt0 = gt_albedo.cpu().data.numpy()\n",
    "            n,c,h,w = gt0.shape\n",
    "            gt, display = myutils.processGt(gt0, scale_factor=s, gd=gradient, return_image=True)\n",
    "            gt_mg, display_mg = myutils.processGt(gt0, scale_factor=s//2, gd=gradient, return_image=True)\n",
    "            \n",
    "            if use_gpu: \n",
    "                gt = gt.cuda()\n",
    "                gt_mg = gt_mg.cuda()\n",
    "            \n",
    "            if i != 5: \n",
    "                loss = mse_losses[i](ft_test[i], gt)\n",
    "                test_losses_trainphase[i] += loss.data.cpu().numpy()[0]\n",
    "                test_cnts_trainphase[i] += 1\n",
    "            \n",
    "            if go_through_merge != False and i != 4:\n",
    "                if ((go_through_merge == '32M') or\n",
    "                    (go_through_merge == '16M' and i != 5) or  \n",
    "                    (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                    (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                    (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "                    if i==5: gt2=gt\n",
    "                    else: gt2=gt_mg\n",
    "#                     print(i)\n",
    "#                     print('merge size', merged_RGB[i].size())\n",
    "#                     print('gt2 size', gt2.size())\n",
    "                    loss = mse_merge_losses[i](merged_RGB[i], gt2)\n",
    "                    test_merge_losses_trainphase[i] += loss.data.cpu().numpy()[0]\n",
    "                    test_merge_cnts_trainphase[i] += 1\n",
    "            \n",
    "\n",
    "            \n",
    "            if ind == 0: \n",
    "                if i != 5:\n",
    "                    v = v[0].cpu().data.numpy()\n",
    "                    v = v.transpose(1,2,0)\n",
    "                    v = v[:,:,0:3]\n",
    "                    cv2.imwrite('snapshot{}/test-phase_{}-{}-{}.png'.format(args.gpu_num, phase, epoch, i), (v[:,:,::-1]+offset)*255)\n",
    "                if go_through_merge != False and i != 4:\n",
    "                    if ((go_through_merge == '32M') or\n",
    "                    (go_through_merge == '16M' and i != 5) or  \n",
    "                    (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                    (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                    (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "                        v = merged_RGB[i][0].cpu().data.numpy()\n",
    "                        v = v.transpose(1,2,0)\n",
    "                        v = v[:,:,0:3]\n",
    "                        cv2.imwrite('snapshot{}/test-mg-phase_{}-{}-{}.png'.format(args.gpu_num, phase, epoch, i), (v[:,:,::-1]+offset)*255)\n",
    "                    \n",
    "    run_losses = test_losses_trainphase\n",
    "    run_cnts = test_cnts_trainphase\n",
    "    writer.add_scalars('16M loss', {'test 16M phase {}'.format(phase): np.array([run_losses[0]/ run_cnts[0]])}, global_step=epoch)  \n",
    "    writer.add_scalars('8M loss', {'test 8M phase {}'.format(phase): np.array([run_losses[1]/ run_cnts[1]])}, global_step=epoch) \n",
    "    writer.add_scalars('4M loss', {'test 4M phase {}'.format(phase): np.array([run_losses[2]/ run_cnts[2]])}, global_step=epoch) \n",
    "    writer.add_scalars('2M loss', {'test 2M ': np.array([run_losses[3]/ run_cnts[3]])}, global_step=epoch) \n",
    "    writer.add_scalars('1M loss', {'test 1M phase {}'.format(phase): np.array([run_losses[4]/ run_cnts[4]])}, global_step=epoch) \n",
    "    writer.add_scalars('merged loss', {'test merged phase {}'.format(phase): np.array([run_losses[5]/ run_cnts[5]])}, global_step=epoch)\n",
    "    \n",
    "    run_losses = test_merge_losses_trainphase\n",
    "    run_cnts = test_merge_cnts_trainphase\n",
    "    writer.add_scalars('16M loss', {'mg test 16M phase {}'.format(phase): np.array([run_losses[0]/ run_cnts[0]])}, global_step=epoch)  \n",
    "    writer.add_scalars('8M loss', {'mg test 8M phase {}'.format(phase): np.array([run_losses[1]/ run_cnts[1]])}, global_step=epoch) \n",
    "    writer.add_scalars('4M loss', {'mg test 4M phase {}'.format(phase): np.array([run_losses[2]/ run_cnts[2]])}, global_step=epoch) \n",
    "    writer.add_scalars('2M loss', {'mg test 2M ': np.array([run_losses[3]/ run_cnts[3]])}, global_step=epoch) \n",
    "    writer.add_scalars('1M loss', {'mg test 1M phase {}'.format(phase): np.array([run_losses[4]/ run_cnts[4]])}, global_step=epoch) \n",
    "    writer.add_scalars('merged loss', {'mg test merged phase {}'.format(phase): np.array([run_losses[5]/ run_cnts[5]])}, global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [2017-12-12 15:50:57]\n",
      " 16M: 0.042977  8M: 0.043304  4M: 0.043403  2M: 0.041431  1M: 0.039645 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 1 [2017-12-12 15:52:16]\n",
      " 16M: 0.032856  8M: 0.032205  4M: 0.035232  2M: 0.037625  1M: 0.036856 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 2 [2017-12-12 15:53:34]\n",
      " 16M: 0.023343  8M: 0.022938  4M: 0.024168  2M: 0.032162  1M: 0.032214 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 3 [2017-12-12 15:54:51]\n",
      " 16M: 0.020468  8M: 0.020176  4M: 0.020150  2M: 0.027763  1M: 0.031778 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 4 [2017-12-12 15:56:09]\n",
      " 16M: 0.019116  8M: 0.018726  4M: 0.019295  2M: 0.023594  1M: 0.026976 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 5 [2017-12-12 15:57:32]\n",
      " 16M: 0.016312  8M: 0.015675  4M: 0.016235  2M: 0.018690  1M: 0.022302 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 6 [2017-12-12 15:58:50]\n",
      " 16M: 0.014584  8M: 0.013867  4M: 0.013851  2M: 0.015869  1M: 0.017986 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 7 [2017-12-12 16:00:09]\n",
      " 16M: 0.013864  8M: 0.013874  4M: 0.012863  2M: 0.014143  1M: 0.016086 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 8 [2017-12-12 16:01:28]\n",
      " 16M: 0.013122  8M: 0.012208  4M: 0.012181  2M: 0.013439  1M: 0.014455 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 9 [2017-12-12 16:02:47]\n",
      " 16M: 0.011918  8M: 0.011718  4M: 0.011410  2M: 0.011731  1M: 0.013160 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 10 [2017-12-12 16:04:10]\n",
      " 16M: 0.010804  8M: 0.011034  4M: 0.009756  2M: 0.011451  1M: 0.012207 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 11 [2017-12-12 16:05:30]\n",
      " 16M: 0.010425  8M: 0.010265  4M: 0.009341  2M: 0.010835  1M: 0.011334 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 12 [2017-12-12 16:06:47]\n",
      " 16M: 0.010043  8M: 0.009936  4M: 0.008750  2M: 0.009674  1M: 0.010889 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 13 [2017-12-12 16:08:04]\n",
      " 16M: 0.010107  8M: 0.009553  4M: 0.008424  2M: 0.010095  1M: 0.010900 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 14 [2017-12-12 16:09:22]\n",
      " 16M: 0.009462  8M: 0.009212  4M: 0.008357  2M: 0.009501  1M: 0.010079 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 15 [2017-12-12 16:10:44]\n",
      " 16M: 0.009080  8M: 0.008897  4M: 0.007823  2M: 0.008919  1M: 0.009848 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 16 [2017-12-12 16:12:01]\n",
      " 16M: 0.008681  8M: 0.008435  4M: 0.007448  2M: 0.008511  1M: 0.009324 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 17 [2017-12-12 16:13:18]\n",
      " 16M: 0.008712  8M: 0.008364  4M: 0.007708  2M: 0.008402  1M: 0.009244 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 18 [2017-12-12 16:14:35]\n",
      " 16M: 0.008277  8M: 0.007810  4M: 0.006917  2M: 0.007882  1M: 0.008675 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 19 [2017-12-12 16:15:52]\n",
      " 16M: 0.008335  8M: 0.007939  4M: 0.006893  2M: 0.007783  1M: 0.008934 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 20 [2017-12-12 16:17:13]\n",
      " 16M: 0.007956  8M: 0.007852  4M: 0.006690  2M: 0.007602  1M: 0.008405 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 21 [2017-12-12 16:18:31]\n",
      " 16M: 0.007860  8M: 0.007509  4M: 0.006552  2M: 0.007392  1M: 0.008581 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 22 [2017-12-12 16:19:47]\n",
      " 16M: 0.007498  8M: 0.007175  4M: 0.006235  2M: 0.006919  1M: 0.007883 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 23 [2017-12-12 16:21:04]\n",
      " 16M: 0.007585  8M: 0.007200  4M: 0.006213  2M: 0.007041  1M: 0.008036 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 24 [2017-12-12 16:22:20]\n",
      " 16M: 0.007409  8M: 0.007037  4M: 0.006073  2M: 0.006757  1M: 0.007649 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 25 [2017-12-12 16:23:42]\n",
      " 16M: 0.007216  8M: 0.006869  4M: 0.006001  2M: 0.006613  1M: 0.007707 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 26 [2017-12-12 16:24:59]\n",
      " 16M: 0.007005  8M: 0.006650  4M: 0.005727  2M: 0.006200  1M: 0.007063 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 27 [2017-12-12 16:26:15]\n",
      " 16M: 0.006853  8M: 0.006563  4M: 0.005672  2M: 0.006350  1M: 0.007289 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 28 [2017-12-12 16:27:33]\n",
      " 16M: 0.006600  8M: 0.006334  4M: 0.005413  2M: 0.006087  1M: 0.006986 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 29 [2017-12-12 16:28:49]\n",
      " 16M: 0.006672  8M: 0.006105  4M: 0.005382  2M: 0.005878  1M: 0.006784 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 30 [2017-12-12 16:30:11]\n",
      " 16M: 0.008768  8M: 0.008152  4M: 0.006967  2M: 0.008802  1M: 0.009295 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.034545 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 31 [2017-12-12 16:31:45]\n",
      " 16M: 0.007899  8M: 0.007804  4M: 0.006682  2M: 0.009497  1M: 0.009526 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.019000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 32 [2017-12-12 16:33:16]\n",
      " 16M: 0.007482  8M: 0.007105  4M: 0.006288  2M: 0.008303  1M: 0.008973 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.015692 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 33 [2017-12-12 16:34:49]\n",
      " 16M: 0.007126  8M: 0.006972  4M: 0.005969  2M: 0.007480  1M: 0.008014 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.013657 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 34 [2017-12-12 16:36:23]\n",
      " 16M: 0.006887  8M: 0.006640  4M: 0.005574  2M: 0.006965  1M: 0.007678 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.012495 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 35 [2017-12-12 16:38:02]\n",
      " 16M: 0.006512  8M: 0.006140  4M: 0.005338  2M: 0.006687  1M: 0.007858 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.012276 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 36 [2017-12-12 16:39:35]\n",
      " 16M: 0.007787  8M: 0.007329  4M: 0.006316  2M: 0.008179  1M: 0.008701 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.014358 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 37 [2017-12-12 16:41:07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.007287  8M: 0.006939  4M: 0.006002  2M: 0.007452  1M: 0.007962 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.013242 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 38 [2017-12-12 16:42:41]\n",
      " 16M: 0.007310  8M: 0.006874  4M: 0.005870  2M: 0.007083  1M: 0.007649 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.011966 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 39 [2017-12-12 16:44:16]\n",
      " 16M: 0.006690  8M: 0.006342  4M: 0.005486  2M: 0.006373  1M: 0.006714 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.010593 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 40 [2017-12-12 16:45:56]\n",
      " 16M: 0.006452  8M: 0.006066  4M: 0.005232  2M: 0.006021  1M: 0.006759 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.010080 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 41 [2017-12-12 16:47:28]\n",
      " 16M: 0.006408  8M: 0.006068  4M: 0.005314  2M: 0.006100  1M: 0.007171 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.009833 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 42 [2017-12-12 16:49:02]\n",
      " 16M: 0.007411  8M: 0.006883  4M: 0.005838  2M: 0.007163  1M: 0.007504 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.011225 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 43 [2017-12-12 16:50:35]\n",
      " 16M: 0.007410  8M: 0.007499  4M: 0.006096  2M: 0.007544  1M: 0.007665 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.011610 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 44 [2017-12-12 16:52:09]\n",
      " 16M: 0.006705  8M: 0.006373  4M: 0.005447  2M: 0.006403  1M: 0.006872 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.010011 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 45 [2017-12-12 16:53:46]\n",
      " 16M: 0.006359  8M: 0.006113  4M: 0.005042  2M: 0.006005  1M: 0.006339 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.009261 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 46 [2017-12-12 16:55:17]\n",
      " 16M: 0.006343  8M: 0.006006  4M: 0.005034  2M: 0.005882  1M: 0.006427 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.009199 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 47 [2017-12-12 16:56:51]\n",
      " 16M: 0.006042  8M: 0.005754  4M: 0.004798  2M: 0.005470  1M: 0.005821 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.008654 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 48 [2017-12-12 16:58:23]\n",
      " 16M: 0.007331  8M: 0.006751  4M: 0.015086  2M: 0.008004  1M: 0.007849 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.032709 mg  2M: 0.012573 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 49 [2017-12-12 17:00:18]\n",
      " 16M: 0.006969  8M: 0.006271  4M: 0.009791  2M: 0.007329  1M: 0.007851 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.017601 mg  2M: 0.011491 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 50 [2017-12-12 17:02:17]\n",
      " 16M: 0.006432  8M: 0.005965  4M: 0.008265  2M: 0.006599  1M: 0.007047 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.013906 mg  2M: 0.010242 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 51 [2017-12-12 17:04:15]\n",
      " 16M: 0.006204  8M: 0.005829  4M: 0.007206  2M: 0.006225  1M: 0.006590 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.011738 mg  2M: 0.009567 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 52 [2017-12-12 17:06:10]\n",
      " 16M: 0.005830  8M: 0.005450  4M: 0.006249  2M: 0.005614  1M: 0.006068 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.010088 mg  2M: 0.008840 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 53 [2017-12-12 17:08:04]\n",
      " 16M: 0.005890  8M: 0.005425  4M: 0.005786  2M: 0.005611  1M: 0.006086 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.009839 mg  2M: 0.008995 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 54 [2017-12-12 17:09:57]\n",
      " 16M: 0.006637  8M: 0.006534  4M: 0.007461  2M: 0.006288  1M: 0.006581 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.011853 mg  2M: 0.009713 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 55 [2017-12-12 17:11:56]\n",
      " 16M: 0.006615  8M: 0.006241  4M: 0.006878  2M: 0.006533  1M: 0.006716 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.011087 mg  2M: 0.009799 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 56 [2017-12-12 17:13:51]\n",
      " 16M: 0.006411  8M: 0.006120  4M: 0.007432  2M: 0.006042  1M: 0.006309 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.010369 mg  2M: 0.009240 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 57 [2017-12-12 17:15:45]\n",
      " 16M: 0.005904  8M: 0.005745  4M: 0.006090  2M: 0.005568  1M: 0.006126 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.009185 mg  2M: 0.008706 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 58 [2017-12-12 17:17:39]\n",
      " 16M: 0.005527  8M: 0.005159  4M: 0.005242  2M: 0.005097  1M: 0.005467 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.007884 mg  2M: 0.007792 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 59 [2017-12-12 17:19:32]\n",
      " 16M: 0.005525  8M: 0.005291  4M: 0.005479  2M: 0.005177  1M: 0.005586 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.008038 mg  2M: 0.008054 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 60 [2017-12-12 17:21:32]\n",
      " 16M: 0.006212  8M: 0.005897  4M: 0.005992  2M: 0.005827  1M: 0.006130 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.009361 mg  2M: 0.008824 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 61 [2017-12-12 17:23:26]\n",
      " 16M: 0.006102  8M: 0.005760  4M: 0.005767  2M: 0.005617  1M: 0.005947 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.008792 mg  2M: 0.008652 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 62 [2017-12-12 17:25:20]\n",
      " 16M: 0.006045  8M: 0.005583  4M: 0.005529  2M: 0.005494  1M: 0.005947 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.008358 mg  2M: 0.008427 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 63 [2017-12-12 17:27:14]\n",
      " 16M: 0.005728  8M: 0.005384  4M: 0.005317  2M: 0.005156  1M: 0.005717 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.007789 mg  2M: 0.007999 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 64 [2017-12-12 17:29:08]\n",
      " 16M: 0.005503  8M: 0.005121  4M: 0.004859  2M: 0.004863  1M: 0.005185 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.007184 mg  2M: 0.007498 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 65 [2017-12-12 17:31:07]\n",
      " 16M: 0.005283  8M: 0.005061  4M: 0.004718  2M: 0.004767  1M: 0.005089 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.007096 mg  2M: 0.007460 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 66 [2017-12-12 17:33:01]\n",
      " 16M: 0.006298  8M: 0.007976  4M: 0.007749  2M: 0.006429  1M: 0.006390 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.023685 mg  4M: 0.011243 mg  2M: 0.009671 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 67 [2017-12-12 17:35:23]\n",
      " 16M: 0.006166  8M: 0.006960  4M: 0.006665  2M: 0.006056  1M: 0.006453 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.013507 mg  4M: 0.009593 mg  2M: 0.009313 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 68 [2017-12-12 17:37:44]\n",
      " 16M: 0.005715  8M: 0.006177  4M: 0.005521  2M: 0.005469  1M: 0.005782 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.010622 mg  4M: 0.008128 mg  2M: 0.008335 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 69 [2017-12-12 17:40:07]\n",
      " 16M: 0.005583  8M: 0.005924  4M: 0.005363  2M: 0.005415  1M: 0.005703 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.009484 mg  4M: 0.007874 mg  2M: 0.008222 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 70 [2017-12-12 17:42:35]\n",
      " 16M: 0.005333  8M: 0.005399  4M: 0.004955  2M: 0.005085  1M: 0.005245 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.008158 mg  4M: 0.007200 mg  2M: 0.007653 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 71 [2017-12-12 17:44:59]\n",
      " 16M: 0.005161  8M: 0.005309  4M: 0.004892  2M: 0.004962  1M: 0.005371 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.007721 mg  4M: 0.007288 mg  2M: 0.007759 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 72 [2017-12-12 17:47:23]\n",
      " 16M: 0.006124  8M: 0.006682  4M: 0.005708  2M: 0.005986  1M: 0.006448 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.009805 mg  4M: 0.008402 mg  2M: 0.008877 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 73 [2017-12-12 17:49:44]\n",
      " 16M: 0.005884  8M: 0.006185  4M: 0.005514  2M: 0.005487  1M: 0.005768 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.008948 mg  4M: 0.008190 mg  2M: 0.008427 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 74 [2017-12-12 17:52:07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.005684  8M: 0.005851  4M: 0.005226  2M: 0.005218  1M: 0.005376 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.007964 mg  4M: 0.007442 mg  2M: 0.007972 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 75 [2017-12-12 17:54:36]\n",
      " 16M: 0.005372  8M: 0.005311  4M: 0.004765  2M: 0.004969  1M: 0.005264 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.007264 mg  4M: 0.007015 mg  2M: 0.007615 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 76 [2017-12-12 17:57:00]\n",
      " 16M: 0.005297  8M: 0.005189  4M: 0.004626  2M: 0.004853  1M: 0.005153 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.007024 mg  4M: 0.006780 mg  2M: 0.007592 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 77 [2017-12-12 17:59:23]\n",
      " 16M: 0.005019  8M: 0.004971  4M: 0.004438  2M: 0.004706  1M: 0.005059 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.006588 mg  4M: 0.006566 mg  2M: 0.007456 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 78 [2017-12-12 18:01:46]\n",
      " 16M: 0.005698  8M: 0.005570  4M: 0.005058  2M: 0.005068  1M: 0.005417 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.007645 mg  4M: 0.007331 mg  2M: 0.007820 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 79 [2017-12-12 18:04:09]\n",
      " 16M: 0.005530  8M: 0.005603  4M: 0.004998  2M: 0.005184  1M: 0.005223 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.007437 mg  4M: 0.007121 mg  2M: 0.007733 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 80 [2017-12-12 18:06:38]\n",
      " 16M: 0.005288  8M: 0.005259  4M: 0.004667  2M: 0.004774  1M: 0.005046 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.006939 mg  4M: 0.006700 mg  2M: 0.007435 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 81 [2017-12-12 18:09:01]\n",
      " 16M: 0.005122  8M: 0.005222  4M: 0.004444  2M: 0.004590  1M: 0.004921 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.006564 mg  4M: 0.006448 mg  2M: 0.007182 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 82 [2017-12-12 18:11:25]\n",
      " 16M: 0.004976  8M: 0.004897  4M: 0.004339  2M: 0.004524  1M: 0.004728 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.006251 mg  4M: 0.006284 mg  2M: 0.007090 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 83 [2017-12-12 18:13:49]\n",
      " 16M: 0.004882  8M: 0.004758  4M: 0.004273  2M: 0.004453  1M: 0.004601 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.006113 mg  4M: 0.006220 mg  2M: 0.007089 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 84 [2017-12-12 18:16:14]\n",
      " 16M: 0.009555  8M: 0.006814  4M: 0.006570  2M: 0.006168  1M: 0.005351 merged: 0.000000\n",
      " mg 16M: 0.021183 mg  8M: 0.009952 mg  4M: 0.008815 mg  2M: 0.009191 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 85 [2017-12-12 18:19:55]\n",
      " 16M: 0.006915  8M: 0.006325  4M: 0.009228  2M: 0.006430  1M: 0.005810 merged: 0.000000\n",
      " mg 16M: 0.011663 mg  8M: 0.008836 mg  4M: 0.010587 mg  2M: 0.009776 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 86 [2017-12-12 18:23:28]\n",
      " 16M: 0.006289  8M: 0.005660  4M: 0.005853  2M: 0.005326  1M: 0.005343 merged: 0.000000\n",
      " mg 16M: 0.009288 mg  8M: 0.007595 mg  4M: 0.007890 mg  2M: 0.008100 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 87 [2017-12-12 18:27:00]\n",
      " 16M: 0.005652  8M: 0.005230  4M: 0.005240  2M: 0.005030  1M: 0.005123 merged: 0.000000\n",
      " mg 16M: 0.007755 mg  8M: 0.006777 mg  4M: 0.007201 mg  2M: 0.007754 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 88 [2017-12-12 18:30:33]\n",
      " 16M: 0.005438  8M: 0.005007  4M: 0.004860  2M: 0.004829  1M: 0.004893 merged: 0.000000\n",
      " mg 16M: 0.007077 mg  8M: 0.006346 mg  4M: 0.006705 mg  2M: 0.007378 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 89 [2017-12-12 18:34:07]\n",
      " 16M: 0.005157  8M: 0.004882  4M: 0.004660  2M: 0.004656  1M: 0.004749 merged: 0.000000\n",
      " mg 16M: 0.006647 mg  8M: 0.006188 mg  4M: 0.006494 mg  2M: 0.007421 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 90 [2017-12-12 18:37:46]\n",
      " 16M: 0.006258  8M: 0.006145  4M: 0.005600  2M: 0.005797  1M: 0.005276 merged: 0.000000\n",
      " mg 16M: 0.008815 mg  8M: 0.007725 mg  4M: 0.007671 mg  2M: 0.008360 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 91 [2017-12-12 18:41:19]\n",
      " 16M: 0.006112  8M: 0.005501  4M: 0.005578  2M: 0.005068  1M: 0.005261 merged: 0.000000\n",
      " mg 16M: 0.007817 mg  8M: 0.007007 mg  4M: 0.007359 mg  2M: 0.008000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 92 [2017-12-12 18:44:50]\n",
      " 16M: 0.005351  8M: 0.004957  4M: 0.004756  2M: 0.004773  1M: 0.004975 merged: 0.000000\n",
      " mg 16M: 0.006629 mg  8M: 0.006326 mg  4M: 0.006694 mg  2M: 0.007503 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 93 [2017-12-12 18:48:21]\n",
      " 16M: 0.005170  8M: 0.004871  4M: 0.004517  2M: 0.004528  1M: 0.004801 merged: 0.000000\n",
      " mg 16M: 0.006151 mg  8M: 0.006038 mg  4M: 0.006364 mg  2M: 0.007245 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 94 [2017-12-12 18:51:53]\n",
      " 16M: 0.005012  8M: 0.004650  4M: 0.004307  2M: 0.004469  1M: 0.004523 merged: 0.000000\n",
      " mg 16M: 0.005720 mg  8M: 0.005716 mg  4M: 0.006118 mg  2M: 0.007059 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 95 [2017-12-12 18:55:32]\n",
      " 16M: 0.005026  8M: 0.004753  4M: 0.004366  2M: 0.004529  1M: 0.004582 merged: 0.000000\n",
      " mg 16M: 0.005818 mg  8M: 0.005886 mg  4M: 0.006194 mg  2M: 0.007108 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 96 [2017-12-12 18:59:05]\n",
      " 16M: 0.006131  8M: 0.006047  4M: 0.006390  2M: 0.005107  1M: 0.005080 merged: 0.000000\n",
      " mg 16M: 0.007563 mg  8M: 0.007266 mg  4M: 0.007545 mg  2M: 0.007823 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 97 [2017-12-12 19:02:37]\n",
      " 16M: 0.005465  8M: 0.005204  4M: 0.005261  2M: 0.004860  1M: 0.004979 merged: 0.000000\n",
      " mg 16M: 0.006643 mg  8M: 0.006554 mg  4M: 0.006863 mg  2M: 0.007415 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 98 [2017-12-12 19:06:10]\n",
      " 16M: 0.005528  8M: 0.005192  4M: 0.004979  2M: 0.004686  1M: 0.004722 merged: 0.000000\n",
      " mg 16M: 0.006296 mg  8M: 0.006291 mg  4M: 0.006565 mg  2M: 0.007152 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 99 [2017-12-12 19:09:42]\n",
      " 16M: 0.005119  8M: 0.004778  4M: 0.004680  2M: 0.004307  1M: 0.004527 merged: 0.000000\n",
      " mg 16M: 0.005654 mg  8M: 0.005713 mg  4M: 0.006103 mg  2M: 0.006753 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 100 [2017-12-12 19:13:22]\n",
      " 16M: 0.004871  8M: 0.004522  4M: 0.004218  2M: 0.004244  1M: 0.004368 merged: 0.000000\n",
      " mg 16M: 0.005371 mg  8M: 0.005522 mg  4M: 0.005940 mg  2M: 0.006748 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 101 [2017-12-12 19:16:54]\n",
      " 16M: 0.004729  8M: 0.004556  4M: 0.004297  2M: 0.004337  1M: 0.004444 merged: 0.000000\n",
      " mg 16M: 0.005236 mg  8M: 0.005534 mg  4M: 0.005932 mg  2M: 0.006899 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 102 [2017-12-12 19:20:26]\n",
      " 16M: 0.006943  8M: 0.005932  4M: 0.005683  2M: 0.004928  1M: 0.004809 merged: 0.000000\n",
      " mg 16M: 0.010839 mg  8M: 0.007489 mg  4M: 0.007456 mg  2M: 0.007600 mg  1M: 0.000000mg merged: 0.010839\n",
      "epoch: 103 [2017-12-12 19:24:52]\n",
      " 16M: 0.008075  8M: 0.008068  4M: 0.008094  2M: 0.006138  1M: 0.005996 merged: 0.000000\n",
      " mg 16M: 0.011919 mg  8M: 0.009644 mg  4M: 0.010328 mg  2M: 0.009706 mg  1M: 0.000000mg merged: 0.011919\n",
      "epoch: 104 [2017-12-12 19:29:20]\n",
      " 16M: 0.007731  8M: 0.006825  4M: 0.006830  2M: 0.006749  1M: 0.005913 merged: 0.000000\n",
      " mg 16M: 0.010352 mg  8M: 0.008609 mg  4M: 0.009603 mg  2M: 0.009635 mg  1M: 0.000000mg merged: 0.010352\n",
      "epoch: 105 [2017-12-12 19:33:55]\n",
      " 16M: 0.006520  8M: 0.006071  4M: 0.005465  2M: 0.005375  1M: 0.005492 merged: 0.000000\n",
      " mg 16M: 0.008438 mg  8M: 0.007314 mg  4M: 0.007605 mg  2M: 0.008332 mg  1M: 0.000000mg merged: 0.008438\n",
      "epoch: 106 [2017-12-12 19:38:23]\n",
      " 16M: 0.006407  8M: 0.005713  4M: 0.005448  2M: 0.005272  1M: 0.005880 merged: 0.000000\n",
      " mg 16M: 0.007866 mg  8M: 0.007145 mg  4M: 0.007742 mg  2M: 0.008444 mg  1M: 0.000000mg merged: 0.007866\n",
      "epoch: 107 [2017-12-12 19:42:50]\n",
      " 16M: 0.006602  8M: 0.006112  4M: 0.006054  2M: 0.005314  1M: 0.005673 merged: 0.000000\n",
      " mg 16M: 0.008446 mg  8M: 0.007158 mg  4M: 0.007643 mg  2M: 0.008093 mg  1M: 0.000000mg merged: 0.008446\n",
      "epoch: 108 [2017-12-12 19:47:19]\n",
      " 16M: 0.005949  8M: 0.006024  4M: 0.005617  2M: 0.005076  1M: 0.005313 merged: 0.000000\n",
      " mg 16M: 0.007169 mg  8M: 0.006829 mg  4M: 0.007125 mg  2M: 0.007739 mg  1M: 0.000000mg merged: 0.007169\n",
      "epoch: 109 [2017-12-12 19:51:47]\n",
      " 16M: 0.006127  8M: 0.005700  4M: 0.006375  2M: 0.005798  1M: 0.006581 merged: 0.000000\n",
      " mg 16M: 0.007308 mg  8M: 0.006976 mg  4M: 0.007764 mg  2M: 0.008543 mg  1M: 0.000000mg merged: 0.007308\n",
      "epoch: 110 [2017-12-12 19:56:29]\n",
      " 16M: 0.005643  8M: 0.005231  4M: 0.005227  2M: 0.005274  1M: 0.005444 merged: 0.000000\n",
      " mg 16M: 0.006315 mg  8M: 0.006289 mg  4M: 0.006899 mg  2M: 0.007812 mg  1M: 0.000000mg merged: 0.006315\n",
      "epoch: 111 [2017-12-12 20:00:57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.005504  8M: 0.005096  4M: 0.004802  2M: 0.004810  1M: 0.005031 merged: 0.000000\n",
      " mg 16M: 0.005984 mg  8M: 0.006135 mg  4M: 0.006644 mg  2M: 0.007484 mg  1M: 0.000000mg merged: 0.005984\n",
      "epoch: 112 [2017-12-12 20:05:27]\n",
      " 16M: 0.005476  8M: 0.005168  4M: 0.004675  2M: 0.004665  1M: 0.005035 merged: 0.000000\n",
      " mg 16M: 0.005949 mg  8M: 0.005942 mg  4M: 0.006313 mg  2M: 0.007225 mg  1M: 0.000000mg merged: 0.005949\n",
      "epoch: 113 [2017-12-12 20:09:55]\n",
      " 16M: 0.005617  8M: 0.005778  4M: 0.004968  2M: 0.004912  1M: 0.005256 merged: 0.000000\n",
      " mg 16M: 0.006244 mg  8M: 0.006281 mg  4M: 0.006728 mg  2M: 0.007584 mg  1M: 0.000000mg merged: 0.006244\n",
      "epoch: 114 [2017-12-12 20:14:21]\n",
      " 16M: 0.005302  8M: 0.005097  4M: 0.004850  2M: 0.004827  1M: 0.004800 merged: 0.000000\n",
      " mg 16M: 0.005848 mg  8M: 0.006115 mg  4M: 0.006666 mg  2M: 0.007473 mg  1M: 0.000000mg merged: 0.005848\n",
      "epoch: 115 [2017-12-12 20:18:58]\n",
      " 16M: 0.005293  8M: 0.005044  4M: 0.004708  2M: 0.004619  1M: 0.004750 merged: 0.000000\n",
      " mg 16M: 0.005697 mg  8M: 0.005812 mg  4M: 0.006301 mg  2M: 0.007110 mg  1M: 0.000000mg merged: 0.005697\n",
      "epoch: 116 [2017-12-12 20:23:25]\n",
      " 16M: 0.005056  8M: 0.004678  4M: 0.004432  2M: 0.004518  1M: 0.004582 merged: 0.000000\n",
      " mg 16M: 0.005335 mg  8M: 0.005578 mg  4M: 0.006156 mg  2M: 0.007028 mg  1M: 0.000000mg merged: 0.005335\n",
      "epoch: 117 [2017-12-12 20:27:53]\n",
      " 16M: 0.005197  8M: 0.004780  4M: 0.004596  2M: 0.004579  1M: 0.004563 merged: 0.000000\n",
      " mg 16M: 0.005521 mg  8M: 0.005559 mg  4M: 0.006000 mg  2M: 0.006876 mg  1M: 0.000000mg merged: 0.005521\n",
      "epoch: 118 [2017-12-12 20:32:25]\n",
      " 16M: 0.005150  8M: 0.004713  4M: 0.004479  2M: 0.004491  1M: 0.004749 merged: 0.000000\n",
      " mg 16M: 0.005153 mg  8M: 0.005520 mg  4M: 0.006115 mg  2M: 0.007052 mg  1M: 0.000000mg merged: 0.005153\n",
      "epoch: 119 [2017-12-12 20:36:54]\n",
      " 16M: 0.004982  8M: 0.004677  4M: 0.004345  2M: 0.004383  1M: 0.004525 merged: 0.000000\n",
      " mg 16M: 0.005169 mg  8M: 0.005467 mg  4M: 0.005978 mg  2M: 0.006851 mg  1M: 0.000000mg merged: 0.005169\n",
      "epoch: 120 [2017-12-12 20:41:30]\n",
      " 16M: 0.005055  8M: 0.004647  4M: 0.004493  2M: 0.004407  1M: 0.004344 merged: 0.000000\n",
      " mg 16M: 0.005070 mg  8M: 0.005412 mg  4M: 0.006018 mg  2M: 0.006826 mg  1M: 0.000000mg merged: 0.005070\n",
      "epoch: 121 [2017-12-12 20:46:03]\n",
      " 16M: 0.005000  8M: 0.004801  4M: 0.004359  2M: 0.004435  1M: 0.004560 merged: 0.000000\n",
      " mg 16M: 0.005066 mg  8M: 0.005466 mg  4M: 0.006024 mg  2M: 0.006916 mg  1M: 0.000000mg merged: 0.005066\n",
      "epoch: 122 [2017-12-12 20:50:40]\n",
      " 16M: 0.004809  8M: 0.004614  4M: 0.004159  2M: 0.004307  1M: 0.004369 merged: 0.000000\n",
      " mg 16M: 0.004908 mg  8M: 0.005269 mg  4M: 0.005782 mg  2M: 0.006719 mg  1M: 0.000000mg merged: 0.004908\n",
      "epoch: 123 [2017-12-12 20:55:07]\n",
      " 16M: 0.004722  8M: 0.004476  4M: 0.004050  2M: 0.004210  1M: 0.004393 merged: 0.000000\n",
      " mg 16M: 0.004794 mg  8M: 0.005213 mg  4M: 0.005756 mg  2M: 0.006715 mg  1M: 0.000000mg merged: 0.004794\n",
      "epoch: 124 [2017-12-12 20:59:41]\n",
      " 16M: 0.004745  8M: 0.004375  4M: 0.004036  2M: 0.004178  1M: 0.004279 merged: 0.000000\n",
      " mg 16M: 0.004807 mg  8M: 0.005154 mg  4M: 0.005628 mg  2M: 0.006576 mg  1M: 0.000000mg merged: 0.004807\n",
      "epoch: 125 [2017-12-12 21:04:26]\n",
      " 16M: 0.004860  8M: 0.004484  4M: 0.004089  2M: 0.004182  1M: 0.004506 merged: 0.000000\n",
      " mg 16M: 0.004712 mg  8M: 0.005122 mg  4M: 0.005676 mg  2M: 0.006643 mg  1M: 0.000000mg merged: 0.004712\n",
      "epoch: 126 [2017-12-12 21:09:05]\n",
      " 16M: 0.004834  8M: 0.004516  4M: 0.004192  2M: 0.004351  1M: 0.004424 merged: 0.000000\n",
      " mg 16M: 0.005102 mg  8M: 0.005388 mg  4M: 0.006025 mg  2M: 0.006766 mg  1M: 0.000000mg merged: 0.005102\n",
      "epoch: 127 [2017-12-12 21:13:42]\n",
      " 16M: 0.004730  8M: 0.004457  4M: 0.004274  2M: 0.004379  1M: 0.004386 merged: 0.000000\n",
      " mg 16M: 0.004672 mg  8M: 0.005190 mg  4M: 0.006126 mg  2M: 0.006831 mg  1M: 0.000000mg merged: 0.004672\n",
      "epoch: 128 [2017-12-12 21:18:20]\n",
      " 16M: 0.004890  8M: 0.004659  4M: 0.004310  2M: 0.004768  1M: 0.004532 merged: 0.000000\n",
      " mg 16M: 0.004911 mg  8M: 0.005445 mg  4M: 0.006438 mg  2M: 0.007404 mg  1M: 0.000000mg merged: 0.004911\n",
      "epoch: 129 [2017-12-12 21:22:57]\n",
      " 16M: 0.004537  8M: 0.004241  4M: 0.004005  2M: 0.004967  1M: 0.004329 merged: 0.000000\n",
      " mg 16M: 0.004693 mg  8M: 0.005214 mg  4M: 0.006274 mg  2M: 0.007659 mg  1M: 0.000000mg merged: 0.004693\n",
      "epoch: 130 [2017-12-12 21:27:43]\n",
      " 16M: 0.004788  8M: 0.004401  4M: 0.004037  2M: 0.004750  1M: 0.004422 merged: 0.000000\n",
      " mg 16M: 0.004881 mg  8M: 0.005288 mg  4M: 0.006175 mg  2M: 0.007388 mg  1M: 0.000000mg merged: 0.004881\n",
      "epoch: 131 [2017-12-12 21:32:20]\n",
      " 16M: 0.004458  8M: 0.004241  4M: 0.003829  2M: 0.004825  1M: 0.004248 merged: 0.000000\n",
      " mg 16M: 0.004431 mg  8M: 0.005020 mg  4M: 0.005778 mg  2M: 0.007297 mg  1M: 0.000000mg merged: 0.004431\n",
      "epoch: 132 [2017-12-12 21:36:57]\n",
      " 16M: 0.004406  8M: 0.004160  4M: 0.003815  2M: 0.004978  1M: 0.004182 merged: 0.000000\n",
      " mg 16M: 0.004465 mg  8M: 0.004984 mg  4M: 0.005746 mg  2M: 0.007411 mg  1M: 0.000000mg merged: 0.004465\n",
      "epoch: 133 [2017-12-12 21:41:33]\n",
      " 16M: 0.004411  8M: 0.004188  4M: 0.003799  2M: 0.004656  1M: 0.004080 merged: 0.000000\n",
      " mg 16M: 0.004481 mg  8M: 0.004959 mg  4M: 0.005728 mg  2M: 0.007149 mg  1M: 0.000000mg merged: 0.004481\n",
      "epoch: 134 [2017-12-12 21:46:11]\n",
      " 16M: 0.004493  8M: 0.004248  4M: 0.003858  2M: 0.004675  1M: 0.004240 merged: 0.000000\n",
      " mg 16M: 0.004482 mg  8M: 0.005051 mg  4M: 0.005739 mg  2M: 0.007131 mg  1M: 0.000000mg merged: 0.004482\n",
      "epoch: 135 [2017-12-12 21:50:57]\n",
      " 16M: 0.004497  8M: 0.004317  4M: 0.003822  2M: 0.004363  1M: 0.004113 merged: 0.000000\n",
      " mg 16M: 0.004426 mg  8M: 0.005032 mg  4M: 0.005714 mg  2M: 0.006948 mg  1M: 0.000000mg merged: 0.004426\n",
      "epoch: 136 [2017-12-12 21:55:33]\n",
      " 16M: 0.004512  8M: 0.004333  4M: 0.003762  2M: 0.004545  1M: 0.004174 merged: 0.000000\n",
      " mg 16M: 0.004429 mg  8M: 0.004948 mg  4M: 0.005611 mg  2M: 0.007089 mg  1M: 0.000000mg merged: 0.004429\n",
      "epoch: 137 [2017-12-12 22:00:11]\n",
      " 16M: 0.004427  8M: 0.004216  4M: 0.003682  2M: 0.004274  1M: 0.004086 merged: 0.000000\n",
      " mg 16M: 0.004290 mg  8M: 0.004872 mg  4M: 0.005514 mg  2M: 0.006774 mg  1M: 0.000000mg merged: 0.004290\n",
      "epoch: 138 [2017-12-12 22:04:49]\n",
      " 16M: 0.004633  8M: 0.004298  4M: 0.003889  2M: 0.004414  1M: 0.004127 merged: 0.000000\n",
      " mg 16M: 0.004571 mg  8M: 0.005006 mg  4M: 0.005653 mg  2M: 0.006887 mg  1M: 0.000000mg merged: 0.004571\n",
      "epoch: 139 [2017-12-12 22:09:27]\n",
      " 16M: 0.004361  8M: 0.004118  4M: 0.003780  2M: 0.010410  1M: 0.004185 merged: 0.000000\n",
      " mg 16M: 0.004287 mg  8M: 0.004867 mg  4M: 0.005750 mg  2M: 0.009123 mg  1M: 0.000000mg merged: 0.004287\n",
      "epoch: 140 [2017-12-12 22:14:12]\n",
      " 16M: 0.004602  8M: 0.004474  4M: 0.003904  2M: 0.007085  1M: 0.004216 merged: 0.000000\n",
      " mg 16M: 0.004573 mg  8M: 0.005151 mg  4M: 0.005812 mg  2M: 0.008184 mg  1M: 0.000000mg merged: 0.004573\n",
      "epoch: 141 [2017-12-12 22:18:49]\n",
      " 16M: 0.004392  8M: 0.004206  4M: 0.003775  2M: 0.006148  1M: 0.004204 merged: 0.000000\n",
      " mg 16M: 0.004371 mg  8M: 0.004961 mg  4M: 0.005674 mg  2M: 0.007647 mg  1M: 0.000000mg merged: 0.004371\n",
      "epoch: 142 [2017-12-12 22:23:27]\n",
      " 16M: 0.004435  8M: 0.004123  4M: 0.003745  2M: 0.005523  1M: 0.004353 merged: 0.000000\n",
      " mg 16M: 0.004231 mg  8M: 0.004848 mg  4M: 0.005637 mg  2M: 0.007622 mg  1M: 0.000000mg merged: 0.004231\n",
      "epoch: 143 [2017-12-12 22:28:06]\n",
      " 16M: 0.004302  8M: 0.004092  4M: 0.003733  2M: 0.005134  1M: 0.004650 merged: 0.000000\n",
      " mg 16M: 0.004285 mg  8M: 0.004910 mg  4M: 0.005764 mg  2M: 0.007868 mg  1M: 0.000000mg merged: 0.004285\n",
      "epoch: 144 [2017-12-12 22:32:43]\n",
      " 16M: 0.004231  8M: 0.004017  4M: 0.003661  2M: 0.005053  1M: 0.004260 merged: 0.000000\n",
      " mg 16M: 0.004160 mg  8M: 0.004799 mg  4M: 0.005585 mg  2M: 0.007421 mg  1M: 0.000000mg merged: 0.004160\n",
      "epoch: 145 [2017-12-12 22:37:28]\n",
      " 16M: 0.004350  8M: 0.004053  4M: 0.003706  2M: 0.004908  1M: 0.004169 merged: 0.000000\n",
      " mg 16M: 0.004096 mg  8M: 0.004711 mg  4M: 0.005474 mg  2M: 0.007188 mg  1M: 0.000000mg merged: 0.004096\n",
      "epoch: 146 [2017-12-12 22:42:04]\n",
      " 16M: 0.004385  8M: 0.004096  4M: 0.003655  2M: 0.005214  1M: 0.004359 merged: 0.000000\n",
      " mg 16M: 0.004219 mg  8M: 0.004840 mg  4M: 0.005701 mg  2M: 0.007756 mg  1M: 0.000000mg merged: 0.004219\n",
      "epoch: 147 [2017-12-12 22:46:36]\n",
      " 16M: 0.004189  8M: 0.004046  4M: 0.003673  2M: 0.005061  1M: 0.004152 merged: 0.000000\n",
      " mg 16M: 0.004181 mg  8M: 0.004762 mg  4M: 0.005527 mg  2M: 0.007384 mg  1M: 0.000000mg merged: 0.004181\n",
      "epoch: 148 [2017-12-12 22:51:06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.004285  8M: 0.004001  4M: 0.003650  2M: 0.004705  1M: 0.004140 merged: 0.000000\n",
      " mg 16M: 0.004012 mg  8M: 0.004689 mg  4M: 0.005444 mg  2M: 0.007091 mg  1M: 0.000000mg merged: 0.004012\n",
      "epoch: 149 [2017-12-12 22:55:36]\n",
      " 16M: 0.004342  8M: 0.004011  4M: 0.003553  2M: 0.004498  1M: 0.003979 merged: 0.000000\n",
      " mg 16M: 0.004013 mg  8M: 0.004647 mg  4M: 0.005278 mg  2M: 0.006851 mg  1M: 0.000000mg merged: 0.004013\n",
      "epoch: 150 [2017-12-12 23:00:12]\n",
      " 16M: 0.004365  8M: 0.003953  4M: 0.003540  2M: 0.004500  1M: 0.003929 merged: 0.000000\n",
      " mg 16M: 0.004046 mg  8M: 0.004650 mg  4M: 0.005318 mg  2M: 0.006765 mg  1M: 0.000000mg merged: 0.004046\n",
      "epoch: 151 [2017-12-12 23:04:41]\n",
      " 16M: 0.004082  8M: 0.003907  4M: 0.003478  2M: 0.004455  1M: 0.003961 merged: 0.000000\n",
      " mg 16M: 0.003904 mg  8M: 0.004575 mg  4M: 0.005326 mg  2M: 0.006813 mg  1M: 0.000000mg merged: 0.003904\n",
      "epoch: 152 [2017-12-12 23:09:09]\n",
      " 16M: 0.004084  8M: 0.003853  4M: 0.003555  2M: 0.004469  1M: 0.004012 merged: 0.000000\n",
      " mg 16M: 0.003904 mg  8M: 0.004554 mg  4M: 0.005265 mg  2M: 0.006838 mg  1M: 0.000000mg merged: 0.003904\n",
      "epoch: 153 [2017-12-12 23:13:37]\n",
      " 16M: 0.004138  8M: 0.003884  4M: 0.003631  2M: 0.004972  1M: 0.004113 merged: 0.000000\n",
      " mg 16M: 0.003890 mg  8M: 0.004573 mg  4M: 0.005389 mg  2M: 0.007205 mg  1M: 0.000000mg merged: 0.003890\n",
      "epoch: 154 [2017-12-12 23:18:05]\n",
      " 16M: 0.004131  8M: 0.003937  4M: 0.003563  2M: 0.004908  1M: 0.003989 merged: 0.000000\n",
      " mg 16M: 0.003941 mg  8M: 0.004638 mg  4M: 0.005359 mg  2M: 0.007025 mg  1M: 0.000000mg merged: 0.003941\n",
      "epoch: 155 [2017-12-12 23:22:39]\n",
      " 16M: 0.004118  8M: 0.003840  4M: 0.003520  2M: 0.005112  1M: 0.003945 merged: 0.000000\n",
      " mg 16M: 0.003875 mg  8M: 0.004569 mg  4M: 0.005372 mg  2M: 0.007301 mg  1M: 0.000000mg merged: 0.003875\n",
      "epoch: 156 [2017-12-12 23:27:05]\n",
      " 16M: 0.003967  8M: 0.003772  4M: 0.003408  2M: 0.004834  1M: 0.003921 merged: 0.000000\n",
      " mg 16M: 0.003764 mg  8M: 0.004453 mg  4M: 0.005198 mg  2M: 0.007021 mg  1M: 0.000000mg merged: 0.003764\n",
      "epoch: 157 [2017-12-12 23:31:33]\n",
      " 16M: 0.004126  8M: 0.003804  4M: 0.003477  2M: 0.005423  1M: 0.004031 merged: 0.000000\n",
      " mg 16M: 0.003993 mg  8M: 0.004590 mg  4M: 0.005357 mg  2M: 0.007387 mg  1M: 0.000000mg merged: 0.003993\n",
      "epoch: 158 [2017-12-12 23:36:00]\n",
      " 16M: 0.003964  8M: 0.003746  4M: 0.003376  2M: 0.004960  1M: 0.003763 merged: 0.000000\n",
      " mg 16M: 0.003774 mg  8M: 0.004464 mg  4M: 0.005165 mg  2M: 0.006944 mg  1M: 0.000000mg merged: 0.003774\n",
      "epoch: 159 [2017-12-12 23:40:29]\n",
      " 16M: 0.004013  8M: 0.003760  4M: 0.003370  2M: 0.004855  1M: 0.003835 merged: 0.000000\n",
      " mg 16M: 0.003817 mg  8M: 0.004489 mg  4M: 0.005197 mg  2M: 0.006873 mg  1M: 0.000000mg merged: 0.003817\n",
      "epoch: 160 [2017-12-12 23:45:03]\n",
      " 16M: 0.003960  8M: 0.003790  4M: 0.003381  2M: 0.004893  1M: 0.003974 merged: 0.000000\n",
      " mg 16M: 0.003726 mg  8M: 0.004461 mg  4M: 0.005140 mg  2M: 0.006963 mg  1M: 0.000000mg merged: 0.003726\n",
      "epoch: 161 [2017-12-12 23:49:31]\n",
      " 16M: 0.003926  8M: 0.003743  4M: 0.003367  2M: 0.004890  1M: 0.003881 merged: 0.000000\n",
      " mg 16M: 0.003668 mg  8M: 0.004384 mg  4M: 0.005102 mg  2M: 0.006888 mg  1M: 0.000000mg merged: 0.003668\n",
      "epoch: 162 [2017-12-12 23:54:00]\n",
      " 16M: 0.003806  8M: 0.003631  4M: 0.003253  2M: 0.004501  1M: 0.003692 merged: 0.000000\n",
      " mg 16M: 0.003617 mg  8M: 0.004302 mg  4M: 0.004981 mg  2M: 0.006570 mg  1M: 0.000000mg merged: 0.003617\n",
      "epoch: 163 [2017-12-12 23:58:30]\n",
      " 16M: 0.003838  8M: 0.003673  4M: 0.003327  2M: 0.004437  1M: 0.003874 merged: 0.000000\n",
      " mg 16M: 0.003703 mg  8M: 0.004382 mg  4M: 0.005154 mg  2M: 0.006711 mg  1M: 0.000000mg merged: 0.003703\n",
      "epoch: 164 [2017-12-13 00:03:00]\n",
      " 16M: 0.003923  8M: 0.003766  4M: 0.003474  2M: 0.004405  1M: 0.003858 merged: 0.000000\n",
      " mg 16M: 0.003687 mg  8M: 0.004436 mg  4M: 0.005217 mg  2M: 0.006770 mg  1M: 0.000000mg merged: 0.003687\n",
      "epoch: 165 [2017-12-13 00:07:36]\n",
      " 16M: 0.003831  8M: 0.003640  4M: 0.003323  2M: 0.004218  1M: 0.003883 merged: 0.000000\n",
      " mg 16M: 0.003589 mg  8M: 0.004315 mg  4M: 0.005047 mg  2M: 0.006519 mg  1M: 0.000000mg merged: 0.003589\n",
      "epoch: 166 [2017-12-13 00:12:06]\n",
      " 16M: 0.003849  8M: 0.003684  4M: 0.003333  2M: 0.004235  1M: 0.003840 merged: 0.000000\n",
      " mg 16M: 0.003591 mg  8M: 0.004328 mg  4M: 0.005042 mg  2M: 0.006601 mg  1M: 0.000000mg merged: 0.003591\n",
      "epoch: 167 [2017-12-13 00:16:35]\n",
      " 16M: 0.004005  8M: 0.003819  4M: 0.003409  2M: 0.004602  1M: 0.003849 merged: 0.000000\n",
      " mg 16M: 0.003742 mg  8M: 0.004448 mg  4M: 0.005123 mg  2M: 0.006737 mg  1M: 0.000000mg merged: 0.003742\n",
      "epoch: 168 [2017-12-13 00:21:04]\n",
      " 16M: 0.003844  8M: 0.003619  4M: 0.003228  2M: 0.004239  1M: 0.003623 merged: 0.000000\n",
      " mg 16M: 0.003546 mg  8M: 0.004230 mg  4M: 0.004898 mg  2M: 0.006453 mg  1M: 0.000000mg merged: 0.003546\n",
      "epoch: 169 [2017-12-13 00:25:34]\n",
      " 16M: 0.003839  8M: 0.003613  4M: 0.003224  2M: 0.004233  1M: 0.003849 merged: 0.000000\n",
      " mg 16M: 0.003632 mg  8M: 0.004324 mg  4M: 0.005017 mg  2M: 0.006587 mg  1M: 0.000000mg merged: 0.003632\n",
      "epoch: 170 [2017-12-13 00:30:10]\n",
      " 16M: 0.003834  8M: 0.003625  4M: 0.003219  2M: 0.004228  1M: 0.003689 merged: 0.000000\n",
      " mg 16M: 0.003562 mg  8M: 0.004259 mg  4M: 0.004911 mg  2M: 0.006386 mg  1M: 0.000000mg merged: 0.003562\n",
      "epoch: 171 [2017-12-13 00:34:38]\n",
      " 16M: 0.003767  8M: 0.003539  4M: 0.003165  2M: 0.004077  1M: 0.003831 merged: 0.000000\n",
      " mg 16M: 0.003545 mg  8M: 0.004243 mg  4M: 0.004936 mg  2M: 0.006375 mg  1M: 0.000000mg merged: 0.003545\n",
      "epoch: 172 [2017-12-13 00:39:08]\n",
      " 16M: 0.003728  8M: 0.003479  4M: 0.003191  2M: 0.004015  1M: 0.003671 merged: 0.000000\n",
      " mg 16M: 0.003438 mg  8M: 0.004123 mg  4M: 0.004788 mg  2M: 0.006119 mg  1M: 0.000000mg merged: 0.003438\n",
      "epoch: 173 [2017-12-13 00:43:38]\n",
      " 16M: 0.003827  8M: 0.003723  4M: 0.003258  2M: 0.004225  1M: 0.003846 merged: 0.000000\n",
      " mg 16M: 0.003606 mg  8M: 0.004280 mg  4M: 0.004933 mg  2M: 0.006456 mg  1M: 0.000000mg merged: 0.003606\n",
      "epoch: 174 [2017-12-13 00:48:08]\n",
      " 16M: 0.003674  8M: 0.003505  4M: 0.003184  2M: 0.004100  1M: 0.003777 merged: 0.000000\n",
      " mg 16M: 0.003451 mg  8M: 0.004172 mg  4M: 0.004889 mg  2M: 0.006426 mg  1M: 0.000000mg merged: 0.003451\n",
      "epoch: 175 [2017-12-13 00:52:44]\n",
      " 16M: 0.003714  8M: 0.003478  4M: 0.003136  2M: 0.003989  1M: 0.003700 merged: 0.000000\n",
      " mg 16M: 0.003445 mg  8M: 0.004128 mg  4M: 0.004818 mg  2M: 0.006320 mg  1M: 0.000000mg merged: 0.003445\n",
      "epoch: 176 [2017-12-13 00:57:12]\n",
      " 16M: 0.003665  8M: 0.003501  4M: 0.003139  2M: 0.004022  1M: 0.003697 merged: 0.000000\n",
      " mg 16M: 0.003444 mg  8M: 0.004124 mg  4M: 0.004800 mg  2M: 0.006286 mg  1M: 0.000000mg merged: 0.003444\n",
      "epoch: 177 [2017-12-13 01:01:42]\n",
      " 16M: 0.003754  8M: 0.003594  4M: 0.003207  2M: 0.004033  1M: 0.003646 merged: 0.000000\n",
      " mg 16M: 0.003466 mg  8M: 0.004196 mg  4M: 0.004847 mg  2M: 0.006276 mg  1M: 0.000000mg merged: 0.003466\n",
      "epoch: 178 [2017-12-13 01:06:12]\n",
      " 16M: 0.003725  8M: 0.003497  4M: 0.003144  2M: 0.003845  1M: 0.003524 merged: 0.000000\n",
      " mg 16M: 0.003424 mg  8M: 0.004114 mg  4M: 0.004792 mg  2M: 0.006169 mg  1M: 0.000000mg merged: 0.003424\n",
      "epoch: 179 [2017-12-13 01:10:39]\n",
      " 16M: 0.003822  8M: 0.003612  4M: 0.003210  2M: 0.003868  1M: 0.003578 merged: 0.000000\n",
      " mg 16M: 0.003530 mg  8M: 0.004244 mg  4M: 0.004903 mg  2M: 0.006304 mg  1M: 0.000000mg merged: 0.003530\n",
      "epoch: 180 [2017-12-13 01:15:15]\n",
      " 16M: 0.003624  8M: 0.003521  4M: 0.003139  2M: 0.003860  1M: 0.003569 merged: 0.000000\n",
      " mg 16M: 0.003359 mg  8M: 0.004116 mg  4M: 0.004799 mg  2M: 0.006161 mg  1M: 0.000000mg merged: 0.003359\n",
      "epoch: 181 [2017-12-13 01:19:45]\n",
      " 16M: 0.003613  8M: 0.003438  4M: 0.003077  2M: 0.003675  1M: 0.003461 merged: 0.000000\n",
      " mg 16M: 0.003313 mg  8M: 0.004036 mg  4M: 0.004672 mg  2M: 0.005957 mg  1M: 0.000000mg merged: 0.003313\n",
      "epoch: 182 [2017-12-13 01:24:14]\n",
      " 16M: 0.003674  8M: 0.003478  4M: 0.003178  2M: 0.003793  1M: 0.003577 merged: 0.000000\n",
      " mg 16M: 0.003383 mg  8M: 0.004098 mg  4M: 0.004775 mg  2M: 0.006125 mg  1M: 0.000000mg merged: 0.003383\n",
      "epoch: 183 [2017-12-13 01:28:43]\n",
      " 16M: 0.003636  8M: 0.003438  4M: 0.003096  2M: 0.003763  1M: 0.003554 merged: 0.000000\n",
      " mg 16M: 0.003355 mg  8M: 0.004051 mg  4M: 0.004724 mg  2M: 0.006105 mg  1M: 0.000000mg merged: 0.003355\n",
      "epoch: 184 [2017-12-13 01:33:12]\n",
      " 16M: 0.003602  8M: 0.003379  4M: 0.003044  2M: 0.003778  1M: 0.003564 merged: 0.000000\n",
      " mg 16M: 0.003284 mg  8M: 0.004009 mg  4M: 0.004667 mg  2M: 0.006194 mg  1M: 0.000000mg merged: 0.003284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 185 [2017-12-13 01:37:48]\n",
      " 16M: 0.003568  8M: 0.003383  4M: 0.003068  2M: 0.003823  1M: 0.003578 merged: 0.000000\n",
      " mg 16M: 0.003270 mg  8M: 0.004034 mg  4M: 0.004738 mg  2M: 0.006188 mg  1M: 0.000000mg merged: 0.003270\n",
      "epoch: 186 [2017-12-13 01:42:16]\n",
      " 16M: 0.003639  8M: 0.003457  4M: 0.003104  2M: 0.003731  1M: 0.003580 merged: 0.000000\n",
      " mg 16M: 0.003294 mg  8M: 0.004045 mg  4M: 0.004720 mg  2M: 0.006125 mg  1M: 0.000000mg merged: 0.003294\n",
      "epoch: 187 [2017-12-13 01:46:44]\n",
      " 16M: 0.003488  8M: 0.003335  4M: 0.003003  2M: 0.003607  1M: 0.003424 merged: 0.000000\n",
      " mg 16M: 0.003231 mg  8M: 0.003984 mg  4M: 0.004660 mg  2M: 0.005952 mg  1M: 0.000000mg merged: 0.003231\n",
      "epoch: 188 [2017-12-13 01:51:12]\n",
      " 16M: 0.003557  8M: 0.003356  4M: 0.003059  2M: 0.003769  1M: 0.003554 merged: 0.000000\n",
      " mg 16M: 0.003289 mg  8M: 0.004020 mg  4M: 0.004698 mg  2M: 0.006154 mg  1M: 0.000000mg merged: 0.003289\n",
      "epoch: 189 [2017-12-13 01:55:40]\n",
      " 16M: 0.003570  8M: 0.003394  4M: 0.003086  2M: 0.003749  1M: 0.003561 merged: 0.000000\n",
      " mg 16M: 0.003284 mg  8M: 0.004032 mg  4M: 0.004713 mg  2M: 0.006100 mg  1M: 0.000000mg merged: 0.003284\n",
      "epoch: 190 [2017-12-13 02:00:18]\n",
      " 16M: 0.003525  8M: 0.003354  4M: 0.003015  2M: 0.003706  1M: 0.003418 merged: 0.000000\n",
      " mg 16M: 0.003211 mg  8M: 0.003938 mg  4M: 0.004555 mg  2M: 0.005922 mg  1M: 0.000000mg merged: 0.003211\n",
      "epoch: 191 [2017-12-13 02:04:48]\n",
      " 16M: 0.003632  8M: 0.003389  4M: 0.003060  2M: 0.003810  1M: 0.003488 merged: 0.000000\n",
      " mg 16M: 0.003260 mg  8M: 0.003966 mg  4M: 0.004622 mg  2M: 0.006032 mg  1M: 0.000000mg merged: 0.003260\n",
      "epoch: 192 [2017-12-13 02:09:18]\n",
      " 16M: 0.003464  8M: 0.003301  4M: 0.002972  2M: 0.003637  1M: 0.003447 merged: 0.000000\n",
      " mg 16M: 0.003145 mg  8M: 0.003910 mg  4M: 0.004558 mg  2M: 0.005897 mg  1M: 0.000000mg merged: 0.003145\n",
      "epoch: 193 [2017-12-13 02:13:47]\n",
      " 16M: 0.003562  8M: 0.003388  4M: 0.003031  2M: 0.003701  1M: 0.003443 merged: 0.000000\n",
      " mg 16M: 0.003244 mg  8M: 0.003985 mg  4M: 0.004622 mg  2M: 0.005930 mg  1M: 0.000000mg merged: 0.003244\n",
      "epoch: 194 [2017-12-13 02:18:15]\n",
      " 16M: 0.003496  8M: 0.003271  4M: 0.002958  2M: 0.003575  1M: 0.003348 merged: 0.000000\n",
      " mg 16M: 0.003192 mg  8M: 0.003927 mg  4M: 0.004601 mg  2M: 0.005865 mg  1M: 0.000000mg merged: 0.003192\n",
      "epoch: 195 [2017-12-13 02:22:51]\n",
      " 16M: 0.003469  8M: 0.003334  4M: 0.002975  2M: 0.003554  1M: 0.003353 merged: 0.000000\n",
      " mg 16M: 0.003200 mg  8M: 0.003952 mg  4M: 0.004583 mg  2M: 0.005882 mg  1M: 0.000000mg merged: 0.003200\n",
      "epoch: 196 [2017-12-13 02:27:19]\n",
      " 16M: 0.003553  8M: 0.003361  4M: 0.002987  2M: 0.003575  1M: 0.003370 merged: 0.000000\n",
      " mg 16M: 0.003212 mg  8M: 0.003966 mg  4M: 0.004591 mg  2M: 0.005843 mg  1M: 0.000000mg merged: 0.003212\n",
      "epoch: 197 [2017-12-13 02:31:47]\n",
      " 16M: 0.003497  8M: 0.003307  4M: 0.002962  2M: 0.003546  1M: 0.003314 merged: 0.000000\n",
      " mg 16M: 0.003157 mg  8M: 0.003908 mg  4M: 0.004554 mg  2M: 0.005772 mg  1M: 0.000000mg merged: 0.003157\n",
      "epoch: 198 [2017-12-13 02:36:15]\n",
      " 16M: 0.003556  8M: 0.003348  4M: 0.003043  2M: 0.003610  1M: 0.003451 merged: 0.000000\n",
      " mg 16M: 0.003182 mg  8M: 0.003935 mg  4M: 0.004575 mg  2M: 0.005852 mg  1M: 0.000000mg merged: 0.003182\n",
      "epoch: 199 [2017-12-13 02:40:43]\n",
      " 16M: 0.003465  8M: 0.003318  4M: 0.002947  2M: 0.003501  1M: 0.003315 merged: 0.000000\n",
      " mg 16M: 0.003133 mg  8M: 0.003847 mg  4M: 0.004455 mg  2M: 0.005666 mg  1M: 0.000000mg merged: 0.003133\n",
      "epoch: 200 [2017-12-13 02:45:19]\n",
      " 16M: 0.003492  8M: 0.003333  4M: 0.002973  2M: 0.003526  1M: 0.003358 merged: 0.000000\n",
      " mg 16M: 0.003151 mg  8M: 0.003882 mg  4M: 0.004509 mg  2M: 0.005708 mg  1M: 0.000000mg merged: 0.003151\n",
      "epoch: 201 [2017-12-13 02:49:47]\n",
      " 16M: 0.003370  8M: 0.003242  4M: 0.002912  2M: 0.003616  1M: 0.003338 merged: 0.000000\n",
      " mg 16M: 0.003077 mg  8M: 0.003854 mg  4M: 0.004509 mg  2M: 0.005864 mg  1M: 0.000000mg merged: 0.003077\n",
      "epoch: 202 [2017-12-13 02:54:15]\n",
      " 16M: 0.003443  8M: 0.003259  4M: 0.002955  2M: 0.003625  1M: 0.003490 merged: 0.000000\n",
      " mg 16M: 0.003119 mg  8M: 0.003906 mg  4M: 0.004601 mg  2M: 0.005985 mg  1M: 0.000000mg merged: 0.003119\n",
      "epoch: 203 [2017-12-13 02:58:42]\n",
      " 16M: 0.003430  8M: 0.003239  4M: 0.002915  2M: 0.003608  1M: 0.003358 merged: 0.000000\n",
      " mg 16M: 0.003111 mg  8M: 0.003897 mg  4M: 0.004587 mg  2M: 0.005965 mg  1M: 0.000000mg merged: 0.003111\n",
      "epoch: 204 [2017-12-13 03:03:10]\n",
      " 16M: 0.003419  8M: 0.003231  4M: 0.002926  2M: 0.003618  1M: 0.003486 merged: 0.000000\n",
      " mg 16M: 0.003099 mg  8M: 0.003853 mg  4M: 0.004546 mg  2M: 0.005945 mg  1M: 0.000000mg merged: 0.003099\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "writer = SummaryWriter(comment='-{}'.format(writer_comment))\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "optimizer = optim.SGD(parameters, lr=args.base_lr, momentum=args.momentum)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, beg, end, reset_lr=None, base_lr=args.base_lr):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "#         print('para gp', param_group)\n",
    "        if reset_lr != None:\n",
    "            param_group['lr'] = reset_lr\n",
    "            continue\n",
    "        param_group['lr'] = base_lr * (float(end-epoch)/(end-beg)) ** (args.power)\n",
    "        if param_group['lr'] < 1.0e-8: param_group['lr'] = 1.0e-8\n",
    "        \n",
    "\n",
    "for epoch in range(args.epoches):\n",
    "#     epoch = 234\n",
    "    net.train()\n",
    "    print('epoch: {} [{}]'.format(epoch, datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "    if epoch < args.training_thresholds[-1]: \n",
    "        adjust_learning_rate(optimizer, epoch, beg=0, end=s0-1)\n",
    "    elif epoch < args.training_merge_thresholds[-1]:\n",
    "        adjust_learning_rate(optimizer, (epoch-s0)%(ss), beg=0, end=ss-1, base_lr=args.base_lr)\n",
    "    else:\n",
    "        adjust_learning_rate(optimizer, epoch, beg=args.training_merge_thresholds[-1], end=args.epoches-1, base_lr=args.base_lr)  \n",
    "        \n",
    "        \n",
    "    if epoch < args.training_thresholds[-1]: go_through_merge = False\n",
    "    elif epoch >= args.training_merge_thresholds[5]: go_through_merge = '32M'\n",
    "    elif epoch >= args.training_merge_thresholds[0]: go_through_merge = '16M'\n",
    "    elif epoch >= args.training_merge_thresholds[1]: go_through_merge = '08M'\n",
    "    elif epoch >= args.training_merge_thresholds[2]: go_through_merge = '04M'\n",
    "    elif epoch >= args.training_merge_thresholds[3]: go_through_merge = '02M'\n",
    "\n",
    "    run_losses = [0] * len(args.training_thresholds)\n",
    "    run_cnts   = [0.00001] * len(args.training_thresholds)\n",
    "    run_merge_losses = [0] * len(args.training_thresholds)\n",
    "    run_merge_cnts   = [0.00001] * len(args.training_thresholds)\n",
    "    if (epoch in args.training_thresholds) == True: \n",
    "        adjust_learning_rate(optimizer, epoch, reset_lr=args.base_lr, beg=-1, end=-1)\n",
    "    if (epoch in args.training_merge_thresholds) == True:\n",
    "        adjust_learning_rate(optimizer, epoch, reset_lr=args.base_lr, beg=-1, end=-1)\n",
    "        \n",
    "    writer.add_scalar('learning rate', optimizer.param_groups[0]['lr'], global_step=epoch)\n",
    "    for ind, data in enumerate(train_loader, 0):\n",
    "#         if  ind == 1 : break\n",
    "        \"\"\"prepare  training data\"\"\"\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        im = input_img[0,:,:,:].numpy(); im = im.transpose(1,2,0); im = im[:,:,::-1]*255\n",
    "        input_img, gt_albedo, gt_shading = Variable(input_img), Variable(gt_albedo), Variable(gt_shading)\n",
    "        if use_gpu: input_img, gt_albedo, gt_shading = input_img.cuda(), gt_albedo.cuda(), gt_shading.cuda()\n",
    "\n",
    "        if args.display_curindex % args.display_interval == 0: cv2.imwrite('snapshot{}/input.png'.format(args.gpu_num), im)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "            \n",
    "        ft_predict, merged_RGB = net(input_img, go_through_merge=go_through_merge)\n",
    "        for i, threshold in enumerate(args.training_thresholds):\n",
    "            if epoch >= threshold:\n",
    "#             if epoch >= 0:\n",
    "                \"\"\"prepare resized gt\"\"\"\n",
    "                if i == 5: s = 1\n",
    "                else: s = (2**(i+1))\n",
    "                gt0 = gt_albedo.cpu().data.numpy()\n",
    "                n,c,h,w = gt0.shape\n",
    "                gt, display = myutils.processGt(gt0, scale_factor=s, gd=gradient, return_image=True)\n",
    "                gt_mg, display_mg = myutils.processGt(gt0, scale_factor=s//2, gd=gradient, return_image=True)\n",
    "                if use_gpu: \n",
    "                    gt = gt.cuda()\n",
    "                    gt_mg = gt_mg.cuda()\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    display = display[:,:,0:3]\n",
    "                    cv2.imwrite('snapshot{}/gt-{}-{}.png'.format(args.gpu_num, epoch, i), display[:,:,::-1]*255)                \n",
    "                \n",
    "                \"\"\"compute loss\"\"\"\n",
    "                if i != 5: \n",
    "                    loss = mse_losses[i](ft_predict[i], gt)\n",
    "                    run_losses[i] += loss.data.cpu().numpy()[0]\n",
    "                    loss.backward(retain_graph=True)\n",
    "                    run_cnts[i] += 1\n",
    "                \n",
    "                if go_through_merge != False and i != 4:\n",
    "                    if ((go_through_merge == '32M') or\n",
    "                    (go_through_merge == '16M' and i != 5) or  \n",
    "                    (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                    (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                    (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "#                         print(epoch, go_through_merge, i)\n",
    "                        \n",
    "#                         print (merged_RGB[i].cpu().data.numpy().max(), merged_RGB[i].cpu().data.numpy().min())\n",
    "                        if i==5: gt2=gt\n",
    "                        else: gt2=gt_mg\n",
    "#                         print(i)\n",
    "#                         print('merge size', merged_RGB[i].size())\n",
    "#                         print('gt2 size', gt2.size())\n",
    "                        loss = mse_merge_losses[i](merged_RGB[i], gt2)\n",
    "                        run_merge_losses[i] += loss.data.cpu().numpy()[0]\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        run_merge_cnts[i] += 1\n",
    "                \n",
    "                \"\"\"save training image\"\"\"\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    \n",
    "                    if i != 5:\n",
    "                        im = (ft_predict[i].cpu().data.numpy()[0].transpose((1,2,0))+offset) * 255\n",
    "                        im = im[:,:,0:3]\n",
    "                        \n",
    "                        cv2.imwrite('snapshot{}/train-{}-{}.png'.format(args.gpu_num, epoch, i), im[:,:,::-1])\n",
    "                    \n",
    "                    if go_through_merge != False and i != 4:\n",
    "                        if ((go_through_merge == '32M') or\n",
    "                        (go_through_merge == '16M' and i != 5) or  \n",
    "                        (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                        (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                        (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "                            im = (merged_RGB[i].cpu().data.numpy()[0].transpose((1,2,0))+offset) * 255\n",
    "                            im = im[:,:,0:3]\n",
    "                            cv2.imwrite('snapshot{}/train-mg-{}-{}.png'.format(args.gpu_num, epoch, i), im[:,:,::-1])\n",
    "        optimizer.step()\n",
    "        args.display_curindex += 1\n",
    "\n",
    "    \"\"\" every epoch \"\"\"\n",
    "#     loss_output = 'ind: ' + str(args.display_curindex)\n",
    "    loss_output = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i,v in enumerate(run_losses):\n",
    "        if i == len(run_losses)-1: \n",
    "            loss_output += ' merged: %6f' % (run_losses[i] / run_cnts[i])\n",
    "            continue\n",
    "        loss_output += ' %2dM: %6f' % ((2**(4-i)), (run_losses[i] / run_cnts[i]))\n",
    "    print(loss_output)\n",
    "    loss_output = ''\n",
    "    for i,v in enumerate(run_merge_losses):\n",
    "        if i == len(run_merge_losses)-1: \n",
    "            loss_output += 'mg merged: %6f' % (run_merge_losses[i] / run_merge_cnts[i])\n",
    "            continue\n",
    "        loss_output += ' mg %2dM: %6f' % ((2**(4-i)), (run_merge_losses[i] / run_merge_cnts[i]))\n",
    "    print(loss_output)\n",
    "    \n",
    "    \"\"\"save at every epoch\"\"\"\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'args' : args,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, 'snapshot{}/snapshot-{}.pth.tar'.format(args.gpu_num, epoch))\n",
    "    \n",
    "    # test \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        test_model(epoch, phase='train', go_through_merge=go_through_merge)\n",
    "        test_model(epoch, phase='test', go_through_merge=go_through_merge)\n",
    "\n",
    "        writer.add_scalars('16M loss', {'train 16M ': np.array([run_losses[0]/ run_cnts[0]])}, global_step=epoch)  \n",
    "        writer.add_scalars('8M loss', {'train 8M ': np.array([run_losses[1]/ run_cnts[1]])}, global_step=epoch) \n",
    "        writer.add_scalars('4M loss', {'train 4M ': np.array([run_losses[2]/ run_cnts[2]])}, global_step=epoch) \n",
    "        writer.add_scalars('2M loss', {'train 2M ': np.array([run_losses[3]/ run_cnts[3]])}, global_step=epoch) \n",
    "        writer.add_scalars('1M loss', {'train 1M ': np.array([run_losses[4]/ run_cnts[4]])}, global_step=epoch) \n",
    "        writer.add_scalars('merged loss', {'train merged ': np.array([run_losses[5]/ run_cnts[5]])}, global_step=epoch) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"10240,10240\"), format='svg')\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = Variable(torch.zeros(1,3,256,256))\n",
    "# y = net(x.cuda())\n",
    "# g = make_dot(y[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g.render('net-transition_scale_{}'.format(transition_scale)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
