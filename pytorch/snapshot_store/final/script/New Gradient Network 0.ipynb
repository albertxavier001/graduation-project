{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, platform, datetime, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import functional as F\n",
    "# import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc\n",
    "\n",
    "from myimagefolder import MyImageFolder\n",
    "from mymodel import GradientNet\n",
    "from myargs import Args\n",
    "from myutils import MyUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('debian', 'jessie/sid', '')\n"
     ]
    }
   ],
   "source": [
    "myutils = MyUtils()\n",
    "\n",
    "args = Args()\n",
    "args.arch = \"densenet121\"\n",
    "args.epoches = 500\n",
    "args.epoches_unary_threshold = 0\n",
    "args.image_h = 256\n",
    "args.image_w = 256\n",
    "args.img_extentions = [\"png\"]\n",
    "args.training_thresholds = [250,200,150,50,0,300]\n",
    "args.base_lr = 1\n",
    "args.lr = args.base_lr\n",
    "args.snapshot_interval = 5000\n",
    "args.debug = True\n",
    "\n",
    "\n",
    "# growth_rate = (4*(2**(args.gpu_num)))\n",
    "transition_scale=2\n",
    "pretrained_scale=4\n",
    "growth_rate = 32\n",
    "\n",
    "#######\n",
    "# args.test_scene = ['alley_2', 'bamboo_2', 'bandage_2', 'cave_4', 'market_5', 'mountain_1', 'shaman_3', 'sleeping_2', 'temple_3']\n",
    "args.test_scene = 'bandage_2'\n",
    "gradient=False\n",
    "args.gpu_num = 0\n",
    "#######\n",
    "\n",
    "writer_comment = '{}_rgb'.format(args.test_scene)\n",
    "if gradient == True:\n",
    "    writer_comment = '{}_gd'.format(args.test_scene)\n",
    "\n",
    "offset = 0.\n",
    "if gradient == True: offset = 0.5\n",
    "\n",
    "args.display_interval = 50\n",
    "args.display_curindex = 0\n",
    "\n",
    "system_ = platform.system()\n",
    "system_dist, system_version, _ = platform.dist()\n",
    "if system_ == \"Darwin\": \n",
    "    args.train_dir = '/Volumes/Transcend/dataset/sintel2'\n",
    "    args.pretrained = False\n",
    "elif platform.dist() ==  ('debian', 'jessie/sid', ''):\n",
    "    args.train_dir = '/home/lwp/workspace/sintel2'\n",
    "    args.pretrained = True\n",
    "elif platform.dist() == ('debian', 'stretch/sid', ''):\n",
    "    args.train_dir = '/home/cad/lwp/workspace/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "\n",
    "if platform.system() == 'Linux': use_gpu = True\n",
    "else: use_gpu = False\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.gpu_num)\n",
    "    \n",
    "\n",
    "print(platform.dist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = MyImageFolder(args.train_dir, 'train',\n",
    "                       transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ), random_crop=True, \n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "test_dataset = MyImageFolder(args.train_dir, 'test', \n",
    "                       transforms.Compose(\n",
    "        [transforms.CenterCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ), random_crop=False,\n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset,1,True,num_workers=1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "[Defination](https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py)\n",
    "* DenseNet-121: num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16)\n",
    "    * First Convolution: 32M -> 16M -> 8M\n",
    "    * every transition: 8M -> 4M -> 2M (downsample 1/2, except the last block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenet = models.__dict__[args.arch](pretrained=args.pretrained)\n",
    "\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if use_gpu: densenet.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ ConvTranspose2d weight 0.002867696673382022\n",
      "_ ConvTranspose2d weight 0.002867696673382022\n",
      "_ ConvTranspose2d weight 0.003031695312954162\n",
      "_ ConvTranspose2d weight 0.003031695312954162\n",
      "_ ConvTranspose2d weight 0.004419417382415922\n"
     ]
    }
   ],
   "source": [
    "ss = 6\n",
    "s0 = ss*5\n",
    "# s0 = 2\n",
    "\n",
    "args.display_curindex = 0\n",
    "args.base_lr = 0.05\n",
    "args.display_interval = 20\n",
    "args.momentum = 0.9\n",
    "args.epoches = 240\n",
    "args.training_thresholds = [0,0,0,0,0,s0]\n",
    "args.training_merge_thresholds = [s0+ss*3*3,s0+ss*2*3, s0+ss*1*3, s0, -1, s0+ss*4*3]\n",
    "args.power = 0.5\n",
    "\n",
    "\n",
    "\n",
    "# pretrained = PreTrainedModel(densenet)\n",
    "# if use_gpu: \n",
    "#     pretrained.cuda()\n",
    "\n",
    "\n",
    "net = GradientNet(densenet=densenet, growth_rate=growth_rate, \n",
    "                  transition_scale=transition_scale, pretrained_scale=pretrained_scale,\n",
    "                 gradient=gradient)\n",
    "if use_gpu:\n",
    "    net.cuda()\n",
    "\n",
    "if use_gpu: \n",
    "    mse_losses = [nn.MSELoss().cuda()] * 6\n",
    "    test_losses = [nn.MSELoss().cuda()] * 6\n",
    "    mse_merge_losses = [nn.MSELoss().cuda()] * 6\n",
    "    test_merge_losses = [nn.MSELoss().cuda()] * 6\n",
    "else:\n",
    "    mse_losses = [nn.MSELoss()] * 6\n",
    "    mse_merge_losses = [nn.MSELoss()] * 6\n",
    "    test_losses = [nn.MSELoss()] * 6\n",
    "    test_merge_losses = [nn.MSELoss()] * 6    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(epoch, go_through_merge=False, phase='train'):\n",
    "    if phase == 'train': net.train()\n",
    "    else: net.eval()\n",
    "    \n",
    "    test_losses_trainphase = [0] * len(args.training_thresholds)\n",
    "    test_cnts_trainphase   = [0.00001] * len(args.training_thresholds)  \n",
    "    test_merge_losses_trainphase = [0] * len(args.training_thresholds)\n",
    "    test_merge_cnts_trainphase   = [0.00001] * len(args.training_thresholds)\n",
    "    \n",
    "    for ind, data in enumerate(test_loader, 0):\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "        \n",
    "#         pretrained.train(); ft_pretreained = pretrained(input_img)\n",
    "        ft_test, merged_RGB = net(input_img, go_through_merge=go_through_merge)\n",
    "            \n",
    "        for i,v in enumerate(ft_test):\n",
    "            if epoch < args.training_thresholds[i]: continue\n",
    "            if i == 5: s = 1\n",
    "            else: s = (2**(i+1))\n",
    "            gt0 = gt_albedo.cpu().data.numpy()\n",
    "            n,c,h,w = gt0.shape\n",
    "            gt, display = myutils.processGt(gt0, scale_factor=s, gd=gradient, return_image=True)\n",
    "            gt_mg, display_mg = myutils.processGt(gt0, scale_factor=s//2, gd=gradient, return_image=True)\n",
    "            \n",
    "            if use_gpu: \n",
    "                gt = gt.cuda()\n",
    "                gt_mg = gt_mg.cuda()\n",
    "            \n",
    "            if i != 5: \n",
    "                loss = mse_losses[i](ft_test[i], gt)\n",
    "                test_losses_trainphase[i] += loss.data.cpu().numpy()[0]\n",
    "                test_cnts_trainphase[i] += 1\n",
    "            \n",
    "            if go_through_merge != False and i != 4:\n",
    "                if ((go_through_merge == '32M') or\n",
    "                    (go_through_merge == '16M' and i != 5) or  \n",
    "                    (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                    (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                    (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "                    if i==5: gt2=gt\n",
    "                    else: gt2=gt_mg\n",
    "#                     print(i)\n",
    "#                     print('merge size', merged_RGB[i].size())\n",
    "#                     print('gt2 size', gt2.size())\n",
    "                    loss = mse_merge_losses[i](merged_RGB[i], gt2)\n",
    "                    test_merge_losses_trainphase[i] += loss.data.cpu().numpy()[0]\n",
    "                    test_merge_cnts_trainphase[i] += 1\n",
    "            \n",
    "\n",
    "            \n",
    "            if ind == 0: \n",
    "                if i != 5:\n",
    "                    v = v[0].cpu().data.numpy()\n",
    "                    v = v.transpose(1,2,0)\n",
    "                    v = v[:,:,0:3]\n",
    "                    cv2.imwrite('snapshot{}/test-phase_{}-{}-{}.png'.format(args.gpu_num, phase, epoch, i), (v[:,:,::-1]+offset)*255)\n",
    "                if go_through_merge != False and i != 4:\n",
    "                    if ((go_through_merge == '32M') or\n",
    "                    (go_through_merge == '16M' and i != 5) or  \n",
    "                    (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                    (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                    (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "                        v = merged_RGB[i][0].cpu().data.numpy()\n",
    "                        v = v.transpose(1,2,0)\n",
    "                        v = v[:,:,0:3]\n",
    "                        cv2.imwrite('snapshot{}/test-mg-phase_{}-{}-{}.png'.format(args.gpu_num, phase, epoch, i), (v[:,:,::-1]+offset)*255)\n",
    "                    \n",
    "    run_losses = test_losses_trainphase\n",
    "    run_cnts = test_cnts_trainphase\n",
    "    writer.add_scalars('16M loss', {'test 16M phase {}'.format(phase): np.array([run_losses[0]/ run_cnts[0]])}, global_step=epoch)  \n",
    "    writer.add_scalars('8M loss', {'test 8M phase {}'.format(phase): np.array([run_losses[1]/ run_cnts[1]])}, global_step=epoch) \n",
    "    writer.add_scalars('4M loss', {'test 4M phase {}'.format(phase): np.array([run_losses[2]/ run_cnts[2]])}, global_step=epoch) \n",
    "    writer.add_scalars('2M loss', {'test 2M ': np.array([run_losses[3]/ run_cnts[3]])}, global_step=epoch) \n",
    "    writer.add_scalars('1M loss', {'test 1M phase {}'.format(phase): np.array([run_losses[4]/ run_cnts[4]])}, global_step=epoch) \n",
    "    writer.add_scalars('merged loss', {'test merged phase {}'.format(phase): np.array([run_losses[5]/ run_cnts[5]])}, global_step=epoch)\n",
    "    \n",
    "    run_losses = test_merge_losses_trainphase\n",
    "    run_cnts = test_merge_cnts_trainphase\n",
    "    writer.add_scalars('16M loss', {'mg test 16M phase {}'.format(phase): np.array([run_losses[0]/ run_cnts[0]])}, global_step=epoch)  \n",
    "    writer.add_scalars('8M loss', {'mg test 8M phase {}'.format(phase): np.array([run_losses[1]/ run_cnts[1]])}, global_step=epoch) \n",
    "    writer.add_scalars('4M loss', {'mg test 4M phase {}'.format(phase): np.array([run_losses[2]/ run_cnts[2]])}, global_step=epoch) \n",
    "    writer.add_scalars('2M loss', {'mg test 2M ': np.array([run_losses[3]/ run_cnts[3]])}, global_step=epoch) \n",
    "    writer.add_scalars('1M loss', {'mg test 1M phase {}'.format(phase): np.array([run_losses[4]/ run_cnts[4]])}, global_step=epoch) \n",
    "    writer.add_scalars('merged loss', {'mg test merged phase {}'.format(phase): np.array([run_losses[5]/ run_cnts[5]])}, global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [2017-12-20 13:10:34]\n",
      " 16M: 0.047860  8M: 0.046290  4M: 0.052096  2M: 0.049988  1M: 0.046738 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 1 [2017-12-20 13:11:53]\n",
      " 16M: 0.035208  8M: 0.036065  4M: 0.036911  2M: 0.038711  1M: 0.038810 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 2 [2017-12-20 13:13:11]\n",
      " 16M: 0.035811  8M: 0.026222  4M: 0.029935  2M: 0.026393  1M: 0.027452 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 3 [2017-12-20 13:14:29]\n",
      " 16M: 0.025005  8M: 0.020065  4M: 0.023321  2M: 0.020171  1M: 0.021057 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 4 [2017-12-20 13:15:46]\n",
      " 16M: 0.021601  8M: 0.017884  4M: 0.021716  2M: 0.015772  1M: 0.016284 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 5 [2017-12-20 13:17:10]\n",
      " 16M: 0.019251  8M: 0.016375  4M: 0.017452  2M: 0.013820  1M: 0.015199 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 6 [2017-12-20 13:18:27]\n",
      " 16M: 0.016384  8M: 0.014125  4M: 0.014643  2M: 0.011809  1M: 0.013371 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 7 [2017-12-20 13:19:45]\n",
      " 16M: 0.015600  8M: 0.013588  4M: 0.013949  2M: 0.010717  1M: 0.011343 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 8 [2017-12-20 13:21:01]\n",
      " 16M: 0.013685  8M: 0.012057  4M: 0.011915  2M: 0.008924  1M: 0.009680 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 9 [2017-12-20 13:22:18]\n",
      " 16M: 0.012987  8M: 0.011437  4M: 0.011459  2M: 0.009049  1M: 0.010360 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 10 [2017-12-20 13:23:40]\n",
      " 16M: 0.012435  8M: 0.010876  4M: 0.010469  2M: 0.007571  1M: 0.008971 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 11 [2017-12-20 13:24:58]\n",
      " 16M: 0.011239  8M: 0.010050  4M: 0.009616  2M: 0.007113  1M: 0.008291 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 12 [2017-12-20 13:26:16]\n",
      " 16M: 0.011184  8M: 0.009751  4M: 0.009284  2M: 0.006955  1M: 0.007611 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 13 [2017-12-20 13:27:34]\n",
      " 16M: 0.010720  8M: 0.009229  4M: 0.008399  2M: 0.006539  1M: 0.007030 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 14 [2017-12-20 13:28:51]\n",
      " 16M: 0.010422  8M: 0.008870  4M: 0.008436  2M: 0.006397  1M: 0.006863 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 15 [2017-12-20 13:30:13]\n",
      " 16M: 0.010055  8M: 0.008722  4M: 0.008432  2M: 0.006226  1M: 0.006834 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 16 [2017-12-20 13:31:31]\n",
      " 16M: 0.009695  8M: 0.008397  4M: 0.007693  2M: 0.005621  1M: 0.006021 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 17 [2017-12-20 13:32:49]\n",
      " 16M: 0.009387  8M: 0.007921  4M: 0.007206  2M: 0.005604  1M: 0.005780 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 18 [2017-12-20 13:34:05]\n",
      " 16M: 0.008983  8M: 0.007635  4M: 0.006948  2M: 0.005236  1M: 0.005673 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 19 [2017-12-20 13:35:23]\n",
      " 16M: 0.009222  8M: 0.007719  4M: 0.006976  2M: 0.005040  1M: 0.005309 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 20 [2017-12-20 13:36:48]\n",
      " 16M: 0.008551  8M: 0.007186  4M: 0.006521  2M: 0.004953  1M: 0.005237 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 21 [2017-12-20 13:38:07]\n",
      " 16M: 0.008386  8M: 0.007200  4M: 0.006191  2M: 0.004848  1M: 0.005070 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 22 [2017-12-20 13:39:24]\n",
      " 16M: 0.007808  8M: 0.006545  4M: 0.005760  2M: 0.004484  1M: 0.004598 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 23 [2017-12-20 13:40:41]\n",
      " 16M: 0.007730  8M: 0.006551  4M: 0.005735  2M: 0.004402  1M: 0.004621 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 24 [2017-12-20 13:41:58]\n",
      " 16M: 0.007661  8M: 0.006397  4M: 0.005744  2M: 0.004402  1M: 0.004599 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 25 [2017-12-20 13:43:19]\n",
      " 16M: 0.007701  8M: 0.006557  4M: 0.005830  2M: 0.004399  1M: 0.004410 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 26 [2017-12-20 13:44:37]\n",
      " 16M: 0.007338  8M: 0.006186  4M: 0.005416  2M: 0.004188  1M: 0.004168 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 27 [2017-12-20 13:45:55]\n",
      " 16M: 0.006915  8M: 0.005937  4M: 0.005000  2M: 0.003863  1M: 0.003947 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 28 [2017-12-20 13:47:12]\n",
      " 16M: 0.006684  8M: 0.005622  4M: 0.004786  2M: 0.003702  1M: 0.003776 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 29 [2017-12-20 13:48:30]\n",
      " 16M: 0.006767  8M: 0.005666  4M: 0.004856  2M: 0.003734  1M: 0.003890 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.000000 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 30 [2017-12-20 13:49:53]\n",
      " 16M: 0.010015  8M: 0.008090  4M: 0.007383  2M: 0.008085  1M: 0.005617 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.031783 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 31 [2017-12-20 13:51:27]\n",
      " 16M: 0.009091  8M: 0.007698  4M: 0.006872  2M: 0.006609  1M: 0.005611 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.015982 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 32 [2017-12-20 13:53:00]\n",
      " 16M: 0.007965  8M: 0.006619  4M: 0.005998  2M: 0.005347  1M: 0.005174 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.011583 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 33 [2017-12-20 13:54:32]\n",
      " 16M: 0.007684  8M: 0.006576  4M: 0.005638  2M: 0.004819  1M: 0.004904 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.009669 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 34 [2017-12-20 13:56:06]\n",
      " 16M: 0.007058  8M: 0.005930  4M: 0.005161  2M: 0.004236  1M: 0.004174 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.008156 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 35 [2017-12-20 13:57:43]\n",
      " 16M: 0.007097  8M: 0.005957  4M: 0.005132  2M: 0.004089  1M: 0.004188 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.007236 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 36 [2017-12-20 13:59:16]\n",
      " 16M: 0.009119  8M: 0.007434  4M: 0.006716  2M: 0.004997  1M: 0.005144 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.009712 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 37 [2017-12-20 14:00:48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.007830  8M: 0.007170  4M: 0.006077  2M: 0.005046  1M: 0.005122 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.009380 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 38 [2017-12-20 14:02:21]\n",
      " 16M: 0.007393  8M: 0.006496  4M: 0.005574  2M: 0.004648  1M: 0.004746 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.007945 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 39 [2017-12-20 14:03:53]\n",
      " 16M: 0.007124  8M: 0.005906  4M: 0.004961  2M: 0.003965  1M: 0.004195 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.006841 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 40 [2017-12-20 14:05:32]\n",
      " 16M: 0.006373  8M: 0.005445  4M: 0.004478  2M: 0.003647  1M: 0.003720 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.006194 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 41 [2017-12-20 14:07:05]\n",
      " 16M: 0.006545  8M: 0.005604  4M: 0.004558  2M: 0.003788  1M: 0.003596 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.006083 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 42 [2017-12-20 14:08:38]\n",
      " 16M: 0.007813  8M: 0.006394  4M: 0.005414  2M: 0.004335  1M: 0.004209 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.007542 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 43 [2017-12-20 14:10:10]\n",
      " 16M: 0.007627  8M: 0.006110  4M: 0.005142  2M: 0.004165  1M: 0.004185 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.007120 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 44 [2017-12-20 14:11:44]\n",
      " 16M: 0.006950  8M: 0.005881  4M: 0.005100  2M: 0.003868  1M: 0.004067 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.006500 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 45 [2017-12-20 14:13:24]\n",
      " 16M: 0.006604  8M: 0.005576  4M: 0.004666  2M: 0.003734  1M: 0.003812 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.006047 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 46 [2017-12-20 14:14:58]\n",
      " 16M: 0.006515  8M: 0.005419  4M: 0.004515  2M: 0.003562  1M: 0.003619 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.005741 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 47 [2017-12-20 14:16:33]\n",
      " 16M: 0.005998  8M: 0.005020  4M: 0.004196  2M: 0.003113  1M: 0.003253 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.000000 mg  2M: 0.005186 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 48 [2017-12-20 14:18:04]\n",
      " 16M: 0.007375  8M: 0.005991  4M: 0.006517  2M: 0.005868  1M: 0.007322 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.027718 mg  2M: 0.011751 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 49 [2017-12-20 14:19:59]\n",
      " 16M: 0.007062  8M: 0.005965  4M: 0.006725  2M: 0.004955  1M: 0.005281 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.013534 mg  2M: 0.008767 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 50 [2017-12-20 14:21:59]\n",
      " 16M: 0.006681  8M: 0.005569  4M: 0.005882  2M: 0.004530  1M: 0.004652 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.010118 mg  2M: 0.007427 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 51 [2017-12-20 14:23:54]\n",
      " 16M: 0.006366  8M: 0.005264  4M: 0.004986  2M: 0.003863  1M: 0.004080 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.008085 mg  2M: 0.006317 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 52 [2017-12-20 14:25:49]\n",
      " 16M: 0.005863  8M: 0.004897  4M: 0.004312  2M: 0.003479  1M: 0.003793 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.006930 mg  2M: 0.005763 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 53 [2017-12-20 14:27:44]\n",
      " 16M: 0.005904  8M: 0.004881  4M: 0.004353  2M: 0.003269  1M: 0.003707 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.006728 mg  2M: 0.005560 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 54 [2017-12-20 14:29:34]\n",
      " 16M: 0.006844  8M: 0.005569  4M: 0.005326  2M: 0.003723  1M: 0.004436 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.007911 mg  2M: 0.006521 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 55 [2017-12-20 14:31:30]\n",
      " 16M: 0.006675  8M: 0.005741  4M: 0.005628  2M: 0.004257  1M: 0.004290 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.008008 mg  2M: 0.006830 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 56 [2017-12-20 14:33:26]\n",
      " 16M: 0.006408  8M: 0.005324  4M: 0.004592  2M: 0.003591  1M: 0.003880 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.006414 mg  2M: 0.005712 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 57 [2017-12-20 14:35:22]\n",
      " 16M: 0.006049  8M: 0.005025  4M: 0.004311  2M: 0.003289  1M: 0.003665 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.005855 mg  2M: 0.005248 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 58 [2017-12-20 14:37:17]\n",
      " 16M: 0.005683  8M: 0.004651  4M: 0.003931  2M: 0.002978  1M: 0.003204 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.005356 mg  2M: 0.004835 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 59 [2017-12-20 14:39:11]\n",
      " 16M: 0.006006  8M: 0.004836  4M: 0.004305  2M: 0.003203  1M: 0.003463 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.005490 mg  2M: 0.005073 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 60 [2017-12-20 14:41:09]\n",
      " 16M: 0.006910  8M: 0.005548  4M: 0.004961  2M: 0.003623  1M: 0.003932 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.006471 mg  2M: 0.005747 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 61 [2017-12-20 14:43:01]\n",
      " 16M: 0.006583  8M: 0.005539  4M: 0.004774  2M: 0.003717  1M: 0.003800 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.006392 mg  2M: 0.005887 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 62 [2017-12-20 14:44:54]\n",
      " 16M: 0.005925  8M: 0.004957  4M: 0.004286  2M: 0.003309  1M: 0.003493 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.005522 mg  2M: 0.005252 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 63 [2017-12-20 14:46:49]\n",
      " 16M: 0.005792  8M: 0.004753  4M: 0.004070  2M: 0.003025  1M: 0.003230 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.005163 mg  2M: 0.004904 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 64 [2017-12-20 14:48:44]\n",
      " 16M: 0.005473  8M: 0.004480  4M: 0.003713  2M: 0.002824  1M: 0.003087 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.004622 mg  2M: 0.004508 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 65 [2017-12-20 14:50:42]\n",
      " 16M: 0.005220  8M: 0.004304  4M: 0.003601  2M: 0.002839  1M: 0.002846 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.000000 mg  4M: 0.004560 mg  2M: 0.004453 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 66 [2017-12-20 14:52:33]\n",
      " 16M: 0.007558  8M: 0.007026  4M: 0.005293  2M: 0.004009  1M: 0.003904 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.024896 mg  4M: 0.007852 mg  2M: 0.006430 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 67 [2017-12-20 14:54:59]\n",
      " 16M: 0.006249  8M: 0.005636  4M: 0.004703  2M: 0.003528  1M: 0.003756 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.010568 mg  4M: 0.005799 mg  2M: 0.005449 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 68 [2017-12-20 14:57:23]\n",
      " 16M: 0.005850  8M: 0.005129  4M: 0.004051  2M: 0.003304  1M: 0.003551 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.008452 mg  4M: 0.005442 mg  2M: 0.005246 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 69 [2017-12-20 14:59:51]\n",
      " 16M: 0.005518  8M: 0.004812  4M: 0.003796  2M: 0.003029  1M: 0.003252 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.006662 mg  4M: 0.004710 mg  2M: 0.004711 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 70 [2017-12-20 15:02:19]\n",
      " 16M: 0.005519  8M: 0.004662  4M: 0.003893  2M: 0.003101  1M: 0.003187 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.006073 mg  4M: 0.004699 mg  2M: 0.004695 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 71 [2017-12-20 15:04:45]\n",
      " 16M: 0.005226  8M: 0.004317  4M: 0.003456  2M: 0.002647  1M: 0.002973 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.005558 mg  4M: 0.004256 mg  2M: 0.004287 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 72 [2017-12-20 15:07:13]\n",
      " 16M: 0.006244  8M: 0.005709  4M: 0.004626  2M: 0.003625  1M: 0.003862 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.007702 mg  4M: 0.005620 mg  2M: 0.005441 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 73 [2017-12-20 15:09:41]\n",
      " 16M: 0.006097  8M: 0.005413  4M: 0.004500  2M: 0.003842  1M: 0.004130 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.007399 mg  4M: 0.005674 mg  2M: 0.005609 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 74 [2017-12-20 15:12:07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.005465  8M: 0.004871  4M: 0.003870  2M: 0.003400  1M: 0.003512 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.005961 mg  4M: 0.004905 mg  2M: 0.004989 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 75 [2017-12-20 15:14:46]\n",
      " 16M: 0.005440  8M: 0.004633  4M: 0.003695  2M: 0.002943  1M: 0.003319 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.005381 mg  4M: 0.004496 mg  2M: 0.004564 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 76 [2017-12-20 15:17:26]\n",
      " 16M: 0.005002  8M: 0.004212  4M: 0.003360  2M: 0.002723  1M: 0.002931 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.004794 mg  4M: 0.004110 mg  2M: 0.004210 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 77 [2017-12-20 15:19:58]\n",
      " 16M: 0.004874  8M: 0.004126  4M: 0.003507  2M: 0.002487  1M: 0.002709 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.004689 mg  4M: 0.004017 mg  2M: 0.004136 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 78 [2017-12-20 15:22:36]\n",
      " 16M: 0.005930  8M: 0.005122  4M: 0.004214  2M: 0.003249  1M: 0.003396 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.006179 mg  4M: 0.005146 mg  2M: 0.005092 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 79 [2017-12-20 15:25:03]\n",
      " 16M: 0.005671  8M: 0.004983  4M: 0.003985  2M: 0.003143  1M: 0.003463 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.005363 mg  4M: 0.004596 mg  2M: 0.004770 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 80 [2017-12-20 15:27:39]\n",
      " 16M: 0.005471  8M: 0.004610  4M: 0.003735  2M: 0.002906  1M: 0.003197 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.005020 mg  4M: 0.004255 mg  2M: 0.004372 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 81 [2017-12-20 15:30:06]\n",
      " 16M: 0.005236  8M: 0.004318  4M: 0.003413  2M: 0.002714  1M: 0.002899 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.004685 mg  4M: 0.004064 mg  2M: 0.004186 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 82 [2017-12-20 15:32:37]\n",
      " 16M: 0.004980  8M: 0.004155  4M: 0.003249  2M: 0.002528  1M: 0.002776 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.004323 mg  4M: 0.003848 mg  2M: 0.004014 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 83 [2017-12-20 15:35:13]\n",
      " 16M: 0.005036  8M: 0.004308  4M: 0.003171  2M: 0.002421  1M: 0.002794 merged: 0.000000\n",
      " mg 16M: 0.000000 mg  8M: 0.004321 mg  4M: 0.003747 mg  2M: 0.003893 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 84 [2017-12-20 15:37:51]\n",
      " 16M: 0.006639  8M: 0.005211  4M: 0.004070  2M: 0.003248  1M: 0.003234 merged: 0.000000\n",
      " mg 16M: 0.020174 mg  8M: 0.006446 mg  4M: 0.005221 mg  2M: 0.005122 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 85 [2017-12-20 15:41:56]\n",
      " 16M: 0.006474  8M: 0.005235  4M: 0.004107  2M: 0.003352  1M: 0.003225 merged: 0.000000\n",
      " mg 16M: 0.010593 mg  8M: 0.005960 mg  4M: 0.004971 mg  2M: 0.005045 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 86 [2017-12-20 15:45:47]\n",
      " 16M: 0.005670  8M: 0.004624  4M: 0.003667  2M: 0.003181  1M: 0.003396 merged: 0.000000\n",
      " mg 16M: 0.007401 mg  8M: 0.005187 mg  4M: 0.004537 mg  2M: 0.004793 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 87 [2017-12-20 15:49:32]\n",
      " 16M: 0.005310  8M: 0.004289  4M: 0.003461  2M: 0.002792  1M: 0.002961 merged: 0.000000\n",
      " mg 16M: 0.005989 mg  8M: 0.004508 mg  4M: 0.004052 mg  2M: 0.004281 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 88 [2017-12-20 15:53:31]\n",
      " 16M: 0.004985  8M: 0.004067  4M: 0.003170  2M: 0.002533  1M: 0.002825 merged: 0.000000\n",
      " mg 16M: 0.005202 mg  8M: 0.004218 mg  4M: 0.003809 mg  2M: 0.004038 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 89 [2017-12-20 15:57:23]\n",
      " 16M: 0.004877  8M: 0.004012  4M: 0.003090  2M: 0.002492  1M: 0.002742 merged: 0.000000\n",
      " mg 16M: 0.004968 mg  8M: 0.004121 mg  4M: 0.003720 mg  2M: 0.003967 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 90 [2017-12-20 16:01:38]\n",
      " 16M: 0.005865  8M: 0.005078  4M: 0.004023  2M: 0.003030  1M: 0.003108 merged: 0.000000\n",
      " mg 16M: 0.006947 mg  8M: 0.005222 mg  4M: 0.004439 mg  2M: 0.004409 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 91 [2017-12-20 16:05:40]\n",
      " 16M: 0.006096  8M: 0.004853  4M: 0.003776  2M: 0.002975  1M: 0.003490 merged: 0.000000\n",
      " mg 16M: 0.006024 mg  8M: 0.004907 mg  4M: 0.004285 mg  2M: 0.004491 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 92 [2017-12-20 16:09:34]\n",
      " 16M: 0.005444  8M: 0.004532  4M: 0.003626  2M: 0.002811  1M: 0.003017 merged: 0.000000\n",
      " mg 16M: 0.005473 mg  8M: 0.004588 mg  4M: 0.004109 mg  2M: 0.004304 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 93 [2017-12-20 16:13:27]\n",
      " 16M: 0.004972  8M: 0.004121  4M: 0.003252  2M: 0.002579  1M: 0.002828 merged: 0.000000\n",
      " mg 16M: 0.004592 mg  8M: 0.004111 mg  4M: 0.003716 mg  2M: 0.003997 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 94 [2017-12-20 16:17:19]\n",
      " 16M: 0.004674  8M: 0.003782  4M: 0.002906  2M: 0.002354  1M: 0.002526 merged: 0.000000\n",
      " mg 16M: 0.004191 mg  8M: 0.003852 mg  4M: 0.003485 mg  2M: 0.003706 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 95 [2017-12-20 16:21:26]\n",
      " 16M: 0.004686  8M: 0.003775  4M: 0.002920  2M: 0.002335  1M: 0.002539 merged: 0.000000\n",
      " mg 16M: 0.004114 mg  8M: 0.003849 mg  4M: 0.003508 mg  2M: 0.003755 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 96 [2017-12-20 16:25:25]\n",
      " 16M: 0.005551  8M: 0.004832  4M: 0.003666  2M: 0.002745  1M: 0.002980 merged: 0.000000\n",
      " mg 16M: 0.005299 mg  8M: 0.004636 mg  4M: 0.004065 mg  2M: 0.004225 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 97 [2017-12-20 16:29:19]\n",
      " 16M: 0.005365  8M: 0.004406  4M: 0.003603  2M: 0.002719  1M: 0.003034 merged: 0.000000\n",
      " mg 16M: 0.005087 mg  8M: 0.004423 mg  4M: 0.003916 mg  2M: 0.004077 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 98 [2017-12-20 16:33:17]\n",
      " 16M: 0.005311  8M: 0.004261  4M: 0.003477  2M: 0.002834  1M: 0.002926 merged: 0.000000\n",
      " mg 16M: 0.004913 mg  8M: 0.004394 mg  4M: 0.003959 mg  2M: 0.004169 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 99 [2017-12-20 16:37:07]\n",
      " 16M: 0.004810  8M: 0.003999  4M: 0.003084  2M: 0.002450  1M: 0.002664 merged: 0.000000\n",
      " mg 16M: 0.004122 mg  8M: 0.003861 mg  4M: 0.003546 mg  2M: 0.003832 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 100 [2017-12-20 16:40:56]\n",
      " 16M: 0.004486  8M: 0.003682  4M: 0.002856  2M: 0.002307  1M: 0.002536 merged: 0.000000\n",
      " mg 16M: 0.003863 mg  8M: 0.003630 mg  4M: 0.003336 mg  2M: 0.003614 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 101 [2017-12-20 16:44:43]\n",
      " 16M: 0.004506  8M: 0.003560  4M: 0.002807  2M: 0.002202  1M: 0.002615 merged: 0.000000\n",
      " mg 16M: 0.003710 mg  8M: 0.003550 mg  4M: 0.003286 mg  2M: 0.003664 mg  1M: 0.000000mg merged: 0.000000\n",
      "epoch: 102 [2017-12-20 16:48:39]\n",
      " 16M: 0.006195  8M: 0.004758  4M: 0.003730  2M: 0.003097  1M: 0.003401 merged: 0.000000\n",
      " mg 16M: 0.009497 mg  8M: 0.005315 mg  4M: 0.004587 mg  2M: 0.004659 mg  1M: 0.000000mg merged: 0.009497\n",
      "epoch: 103 [2017-12-20 16:53:44]\n",
      " 16M: 0.006976  8M: 0.005095  4M: 0.004098  2M: 0.003168  1M: 0.003514 merged: 0.000000\n",
      " mg 16M: 0.007492 mg  8M: 0.005393 mg  4M: 0.004671 mg  2M: 0.004805 mg  1M: 0.000000mg merged: 0.007492\n",
      "epoch: 104 [2017-12-20 16:58:51]\n",
      " 16M: 0.006799  8M: 0.005106  4M: 0.004123  2M: 0.003193  1M: 0.003375 merged: 0.000000\n",
      " mg 16M: 0.008164 mg  8M: 0.005356 mg  4M: 0.004683 mg  2M: 0.004741 mg  1M: 0.000000mg merged: 0.008164\n",
      "epoch: 105 [2017-12-20 17:04:00]\n",
      " 16M: 0.006627  8M: 0.004853  4M: 0.004208  2M: 0.003899  1M: 0.004103 merged: 0.000000\n",
      " mg 16M: 0.007816 mg  8M: 0.005559 mg  4M: 0.005046 mg  2M: 0.005718 mg  1M: 0.000000mg merged: 0.007816\n",
      "epoch: 106 [2017-12-20 17:08:59]\n",
      " 16M: 0.005867  8M: 0.004808  4M: 0.003859  2M: 0.003145  1M: 0.003734 merged: 0.000000\n",
      " mg 16M: 0.005427 mg  8M: 0.004602 mg  4M: 0.004271 mg  2M: 0.004602 mg  1M: 0.000000mg merged: 0.005427\n",
      "epoch: 107 [2017-12-20 17:13:57]\n",
      " 16M: 0.005765  8M: 0.004534  4M: 0.003586  2M: 0.002899  1M: 0.003328 merged: 0.000000\n",
      " mg 16M: 0.005386 mg  8M: 0.004351 mg  4M: 0.003929 mg  2M: 0.004298 mg  1M: 0.000000mg merged: 0.005386\n",
      "epoch: 108 [2017-12-20 17:18:58]\n",
      " 16M: 0.005882  8M: 0.004597  4M: 0.003854  2M: 0.003178  1M: 0.003272 merged: 0.000000\n",
      " mg 16M: 0.005566 mg  8M: 0.004562 mg  4M: 0.004159 mg  2M: 0.004518 mg  1M: 0.000000mg merged: 0.005566\n",
      "epoch: 109 [2017-12-20 17:23:59]\n",
      " 16M: 0.006051  8M: 0.004763  4M: 0.003829  2M: 0.003093  1M: 0.003106 merged: 0.000000\n",
      " mg 16M: 0.005153 mg  8M: 0.004417 mg  4M: 0.004069 mg  2M: 0.004513 mg  1M: 0.000000mg merged: 0.005153\n",
      "epoch: 110 [2017-12-20 17:29:08]\n",
      " 16M: 0.005646  8M: 0.004371  4M: 0.003540  2M: 0.002835  1M: 0.003118 merged: 0.000000\n",
      " mg 16M: 0.005344 mg  8M: 0.004323 mg  4M: 0.003975 mg  2M: 0.004274 mg  1M: 0.000000mg merged: 0.005344\n",
      "epoch: 111 [2017-12-20 17:34:05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.005360  8M: 0.004250  4M: 0.003569  2M: 0.002733  1M: 0.003095 merged: 0.000000\n",
      " mg 16M: 0.004472 mg  8M: 0.004006 mg  4M: 0.003722 mg  2M: 0.004068 mg  1M: 0.000000mg merged: 0.004472\n",
      "epoch: 112 [2017-12-20 17:39:03]\n",
      " 16M: 0.005133  8M: 0.004165  4M: 0.003475  2M: 0.002639  1M: 0.002986 merged: 0.000000\n",
      " mg 16M: 0.004278 mg  8M: 0.003895 mg  4M: 0.003582 mg  2M: 0.003889 mg  1M: 0.000000mg merged: 0.004278\n",
      "epoch: 113 [2017-12-20 17:44:07]\n",
      " 16M: 0.005456  8M: 0.004404  4M: 0.003596  2M: 0.003254  1M: 0.003119 merged: 0.000000\n",
      " mg 16M: 0.004489 mg  8M: 0.004052 mg  4M: 0.003829 mg  2M: 0.004360 mg  1M: 0.000000mg merged: 0.004489\n",
      "epoch: 114 [2017-12-20 17:49:06]\n",
      " 16M: 0.004939  8M: 0.003974  4M: 0.003112  2M: 0.002552  1M: 0.002898 merged: 0.000000\n",
      " mg 16M: 0.004069 mg  8M: 0.003703 mg  4M: 0.003446 mg  2M: 0.003902 mg  1M: 0.000000mg merged: 0.004069\n",
      "epoch: 115 [2017-12-20 17:54:12]\n",
      " 16M: 0.004965  8M: 0.003964  4M: 0.003150  2M: 0.002607  1M: 0.002916 merged: 0.000000\n",
      " mg 16M: 0.004063 mg  8M: 0.003760 mg  4M: 0.003497 mg  2M: 0.003950 mg  1M: 0.000000mg merged: 0.004063\n",
      "epoch: 116 [2017-12-20 17:59:16]\n",
      " 16M: 0.004871  8M: 0.003799  4M: 0.002989  2M: 0.002381  1M: 0.002795 merged: 0.000000\n",
      " mg 16M: 0.003816 mg  8M: 0.003576 mg  4M: 0.003320 mg  2M: 0.003691 mg  1M: 0.000000mg merged: 0.003816\n",
      "epoch: 117 [2017-12-20 18:04:15]\n",
      " 16M: 0.004929  8M: 0.003894  4M: 0.002974  2M: 0.002349  1M: 0.002676 merged: 0.000000\n",
      " mg 16M: 0.003747 mg  8M: 0.003494 mg  4M: 0.003240 mg  2M: 0.003644 mg  1M: 0.000000mg merged: 0.003747\n",
      "epoch: 118 [2017-12-20 18:09:18]\n",
      " 16M: 0.004757  8M: 0.003790  4M: 0.003045  2M: 0.002379  1M: 0.002641 merged: 0.000000\n",
      " mg 16M: 0.003628 mg  8M: 0.003469 mg  4M: 0.003210 mg  2M: 0.003587 mg  1M: 0.000000mg merged: 0.003628\n",
      "epoch: 119 [2017-12-20 18:14:17]\n",
      " 16M: 0.004984  8M: 0.003800  4M: 0.003011  2M: 0.002340  1M: 0.002518 merged: 0.000000\n",
      " mg 16M: 0.004045 mg  8M: 0.003544 mg  4M: 0.003288 mg  2M: 0.003606 mg  1M: 0.000000mg merged: 0.004045\n",
      "epoch: 120 [2017-12-20 18:19:24]\n",
      " 16M: 0.004726  8M: 0.003735  4M: 0.003028  2M: 0.002365  1M: 0.002592 merged: 0.000000\n",
      " mg 16M: 0.003684 mg  8M: 0.003475 mg  4M: 0.003227 mg  2M: 0.003612 mg  1M: 0.000000mg merged: 0.003684\n",
      "epoch: 121 [2017-12-20 18:24:27]\n",
      " 16M: 0.004812  8M: 0.003845  4M: 0.003070  2M: 0.002438  1M: 0.002758 merged: 0.000000\n",
      " mg 16M: 0.003634 mg  8M: 0.003476 mg  4M: 0.003248 mg  2M: 0.003611 mg  1M: 0.000000mg merged: 0.003634\n",
      "epoch: 122 [2017-12-20 18:29:25]\n",
      " 16M: 0.004891  8M: 0.003995  4M: 0.003020  2M: 0.002301  1M: 0.002533 merged: 0.000000\n",
      " mg 16M: 0.003584 mg  8M: 0.003414 mg  4M: 0.003180 mg  2M: 0.003525 mg  1M: 0.000000mg merged: 0.003584\n",
      "epoch: 123 [2017-12-20 18:34:22]\n",
      " 16M: 0.004645  8M: 0.003718  4M: 0.002855  2M: 0.002311  1M: 0.002547 merged: 0.000000\n",
      " mg 16M: 0.003503 mg  8M: 0.003372 mg  4M: 0.003138 mg  2M: 0.003556 mg  1M: 0.000000mg merged: 0.003503\n",
      "epoch: 124 [2017-12-20 18:39:20]\n",
      " 16M: 0.004513  8M: 0.003682  4M: 0.002891  2M: 0.002264  1M: 0.002421 merged: 0.000000\n",
      " mg 16M: 0.003437 mg  8M: 0.003289 mg  4M: 0.003050 mg  2M: 0.003419 mg  1M: 0.000000mg merged: 0.003437\n",
      "epoch: 125 [2017-12-20 18:44:23]\n",
      " 16M: 0.005038  8M: 0.004030  4M: 0.003223  2M: 0.002479  1M: 0.002740 merged: 0.000000\n",
      " mg 16M: 0.003867 mg  8M: 0.003589 mg  4M: 0.003353 mg  2M: 0.003732 mg  1M: 0.000000mg merged: 0.003867\n",
      "epoch: 126 [2017-12-20 18:49:20]\n",
      " 16M: 0.004727  8M: 0.003722  4M: 0.002971  2M: 0.002511  1M: 0.002556 merged: 0.000000\n",
      " mg 16M: 0.003415 mg  8M: 0.003271 mg  4M: 0.003103 mg  2M: 0.003584 mg  1M: 0.000000mg merged: 0.003415\n",
      "epoch: 127 [2017-12-20 18:54:18]\n",
      " 16M: 0.004650  8M: 0.003675  4M: 0.002800  2M: 0.002335  1M: 0.002422 merged: 0.000000\n",
      " mg 16M: 0.003388 mg  8M: 0.003289 mg  4M: 0.003070 mg  2M: 0.003465 mg  1M: 0.000000mg merged: 0.003388\n",
      "epoch: 128 [2017-12-20 18:59:16]\n",
      " 16M: 0.004533  8M: 0.003663  4M: 0.002839  2M: 0.002230  1M: 0.002365 merged: 0.000000\n",
      " mg 16M: 0.003319 mg  8M: 0.003269 mg  4M: 0.003047 mg  2M: 0.003398 mg  1M: 0.000000mg merged: 0.003319\n",
      "epoch: 129 [2017-12-20 19:04:17]\n",
      " 16M: 0.004436  8M: 0.003493  4M: 0.003043  2M: 0.002175  1M: 0.002375 merged: 0.000000\n",
      " mg 16M: 0.003254 mg  8M: 0.003147 mg  4M: 0.002963 mg  2M: 0.003283 mg  1M: 0.000000mg merged: 0.003254\n",
      "epoch: 130 [2017-12-20 19:09:30]\n",
      " 16M: 0.004496  8M: 0.003554  4M: 0.002777  2M: 0.002133  1M: 0.002328 merged: 0.000000\n",
      " mg 16M: 0.003170 mg  8M: 0.003111 mg  4M: 0.002896 mg  2M: 0.003269 mg  1M: 0.000000mg merged: 0.003170\n",
      "epoch: 131 [2017-12-20 19:14:25]\n",
      " 16M: 0.004386  8M: 0.003483  4M: 0.002766  2M: 0.002200  1M: 0.002333 merged: 0.000000\n",
      " mg 16M: 0.003181 mg  8M: 0.003127 mg  4M: 0.002937 mg  2M: 0.003335 mg  1M: 0.000000mg merged: 0.003181\n",
      "epoch: 132 [2017-12-20 19:19:33]\n",
      " 16M: 0.004544  8M: 0.003609  4M: 0.002873  2M: 0.002237  1M: 0.002423 merged: 0.000000\n",
      " mg 16M: 0.003281 mg  8M: 0.003203 mg  4M: 0.003016 mg  2M: 0.003388 mg  1M: 0.000000mg merged: 0.003281\n",
      "epoch: 133 [2017-12-20 19:24:36]\n",
      " 16M: 0.004234  8M: 0.003285  4M: 0.002736  2M: 0.002082  1M: 0.002238 merged: 0.000000\n",
      " mg 16M: 0.003022 mg  8M: 0.003015 mg  4M: 0.002831 mg  2M: 0.003204 mg  1M: 0.000000mg merged: 0.003022\n",
      "epoch: 134 [2017-12-20 19:29:38]\n",
      " 16M: 0.004251  8M: 0.003460  4M: 0.002661  2M: 0.002032  1M: 0.002190 merged: 0.000000\n",
      " mg 16M: 0.003015 mg  8M: 0.003000 mg  4M: 0.002807 mg  2M: 0.003161 mg  1M: 0.000000mg merged: 0.003015\n",
      "epoch: 135 [2017-12-20 19:34:39]\n",
      " 16M: 0.004537  8M: 0.003572  4M: 0.002725  2M: 0.002126  1M: 0.002339 merged: 0.000000\n",
      " mg 16M: 0.003203 mg  8M: 0.003091 mg  4M: 0.002929 mg  2M: 0.003274 mg  1M: 0.000000mg merged: 0.003203\n",
      "epoch: 136 [2017-12-20 19:39:29]\n",
      " 16M: 0.004328  8M: 0.003383  4M: 0.002571  2M: 0.002018  1M: 0.002215 merged: 0.000000\n",
      " mg 16M: 0.002956 mg  8M: 0.002947 mg  4M: 0.002761 mg  2M: 0.003111 mg  1M: 0.000000mg merged: 0.002956\n",
      "epoch: 137 [2017-12-20 19:44:35]\n",
      " 16M: 0.004399  8M: 0.003528  4M: 0.002643  2M: 0.002043  1M: 0.002256 merged: 0.000000\n",
      " mg 16M: 0.003065 mg  8M: 0.003020 mg  4M: 0.002818 mg  2M: 0.003197 mg  1M: 0.000000mg merged: 0.003065\n",
      "epoch: 138 [2017-12-20 19:49:44]\n",
      " 16M: 0.004414  8M: 0.003330  4M: 0.002557  2M: 0.001999  1M: 0.002155 merged: 0.000000\n",
      " mg 16M: 0.002877 mg  8M: 0.002893 mg  4M: 0.002727 mg  2M: 0.003129 mg  1M: 0.000000mg merged: 0.002877\n",
      "epoch: 139 [2017-12-20 19:54:49]\n",
      " 16M: 0.004079  8M: 0.003214  4M: 0.002475  2M: 0.001952  1M: 0.002108 merged: 0.000000\n",
      " mg 16M: 0.002783 mg  8M: 0.002846 mg  4M: 0.002680 mg  2M: 0.003079 mg  1M: 0.000000mg merged: 0.002783\n",
      "epoch: 140 [2017-12-20 19:59:57]\n",
      " 16M: 0.004163  8M: 0.003255  4M: 0.002600  2M: 0.001964  1M: 0.002141 merged: 0.000000\n",
      " mg 16M: 0.002878 mg  8M: 0.002908 mg  4M: 0.002710 mg  2M: 0.003059 mg  1M: 0.000000mg merged: 0.002878\n",
      "epoch: 141 [2017-12-20 20:05:00]\n",
      " 16M: 0.004068  8M: 0.003256  4M: 0.002586  2M: 0.001996  1M: 0.002864 merged: 0.000000\n",
      " mg 16M: 0.002940 mg  8M: 0.002915 mg  4M: 0.002765 mg  2M: 0.003210 mg  1M: 0.000000mg merged: 0.002940\n",
      "epoch: 142 [2017-12-20 20:09:59]\n",
      " 16M: 0.004119  8M: 0.003277  4M: 0.002579  2M: 0.001976  1M: 0.002664 merged: 0.000000\n",
      " mg 16M: 0.002818 mg  8M: 0.002833 mg  4M: 0.002694 mg  2M: 0.003125 mg  1M: 0.000000mg merged: 0.002818\n",
      "epoch: 143 [2017-12-20 20:14:57]\n",
      " 16M: 0.004067  8M: 0.003202  4M: 0.002584  2M: 0.002069  1M: 0.002626 merged: 0.000000\n",
      " mg 16M: 0.003048 mg  8M: 0.002966 mg  4M: 0.002783 mg  2M: 0.003202 mg  1M: 0.000000mg merged: 0.003048\n",
      "epoch: 144 [2017-12-20 20:20:00]\n",
      " 16M: 0.004363  8M: 0.003455  4M: 0.002699  2M: 0.002177  1M: 0.002589 merged: 0.000000\n",
      " mg 16M: 0.002938 mg  8M: 0.002952 mg  4M: 0.002790 mg  2M: 0.003195 mg  1M: 0.000000mg merged: 0.002938\n",
      "epoch: 145 [2017-12-20 20:25:07]\n",
      " 16M: 0.004140  8M: 0.003202  4M: 0.002600  2M: 0.002004  1M: 0.002336 merged: 0.000000\n",
      " mg 16M: 0.002744 mg  8M: 0.002831 mg  4M: 0.002691 mg  2M: 0.003089 mg  1M: 0.000000mg merged: 0.002744\n",
      "epoch: 146 [2017-12-20 20:30:05]\n",
      " 16M: 0.003918  8M: 0.003110  4M: 0.002449  2M: 0.001904  1M: 0.002286 merged: 0.000000\n",
      " mg 16M: 0.002694 mg  8M: 0.002754 mg  4M: 0.002600 mg  2M: 0.003028 mg  1M: 0.000000mg merged: 0.002694\n",
      "epoch: 147 [2017-12-20 20:35:03]\n",
      " 16M: 0.003977  8M: 0.003167  4M: 0.002421  2M: 0.001943  1M: 0.002264 merged: 0.000000\n",
      " mg 16M: 0.002670 mg  8M: 0.002745 mg  4M: 0.002594 mg  2M: 0.002993 mg  1M: 0.000000mg merged: 0.002670\n",
      "epoch: 148 [2017-12-20 20:40:03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.003920  8M: 0.003058  4M: 0.002403  2M: 0.001912  1M: 0.002189 merged: 0.000000\n",
      " mg 16M: 0.002706 mg  8M: 0.002750 mg  4M: 0.002579 mg  2M: 0.002970 mg  1M: 0.000000mg merged: 0.002706\n",
      "epoch: 149 [2017-12-20 20:45:00]\n",
      " 16M: 0.003859  8M: 0.003038  4M: 0.002392  2M: 0.001891  1M: 0.002190 merged: 0.000000\n",
      " mg 16M: 0.002623 mg  8M: 0.002682 mg  4M: 0.002537 mg  2M: 0.002959 mg  1M: 0.000000mg merged: 0.002623\n",
      "epoch: 150 [2017-12-20 20:50:07]\n",
      " 16M: 0.004167  8M: 0.003146  4M: 0.002490  2M: 0.001980  1M: 0.002263 merged: 0.000000\n",
      " mg 16M: 0.002661 mg  8M: 0.002759 mg  4M: 0.002626 mg  2M: 0.003024 mg  1M: 0.000000mg merged: 0.002661\n",
      "epoch: 151 [2017-12-20 20:55:09]\n",
      " 16M: 0.003930  8M: 0.003036  4M: 0.002354  2M: 0.001912  1M: 0.002135 merged: 0.000000\n",
      " mg 16M: 0.002612 mg  8M: 0.002641 mg  4M: 0.002499 mg  2M: 0.002892 mg  1M: 0.000000mg merged: 0.002612\n",
      "epoch: 152 [2017-12-20 21:00:07]\n",
      " 16M: 0.003882  8M: 0.003084  4M: 0.002420  2M: 0.001863  1M: 0.002112 merged: 0.000000\n",
      " mg 16M: 0.002589 mg  8M: 0.002656 mg  4M: 0.002534 mg  2M: 0.002880 mg  1M: 0.000000mg merged: 0.002589\n",
      "epoch: 153 [2017-12-20 21:05:03]\n",
      " 16M: 0.003945  8M: 0.003113  4M: 0.002422  2M: 0.001876  1M: 0.002148 merged: 0.000000\n",
      " mg 16M: 0.002651 mg  8M: 0.002712 mg  4M: 0.002577 mg  2M: 0.002995 mg  1M: 0.000000mg merged: 0.002651\n",
      "epoch: 154 [2017-12-20 21:10:00]\n",
      " 16M: 0.003781  8M: 0.003042  4M: 0.002285  2M: 0.001886  1M: 0.002124 merged: 0.000000\n",
      " mg 16M: 0.002565 mg  8M: 0.002624 mg  4M: 0.002496 mg  2M: 0.002899 mg  1M: 0.000000mg merged: 0.002565\n",
      "epoch: 155 [2017-12-20 21:15:09]\n",
      " 16M: 0.003956  8M: 0.003122  4M: 0.002338  2M: 0.001953  1M: 0.002177 merged: 0.000000\n",
      " mg 16M: 0.002664 mg  8M: 0.002698 mg  4M: 0.002549 mg  2M: 0.002954 mg  1M: 0.000000mg merged: 0.002664\n",
      "epoch: 156 [2017-12-20 21:20:10]\n",
      " 16M: 0.003776  8M: 0.003010  4M: 0.002339  2M: 0.001804  1M: 0.002054 merged: 0.000000\n",
      " mg 16M: 0.002560 mg  8M: 0.002655 mg  4M: 0.002521 mg  2M: 0.002881 mg  1M: 0.000000mg merged: 0.002560\n",
      "epoch: 157 [2017-12-20 21:24:55]\n",
      " 16M: 0.003964  8M: 0.003060  4M: 0.002375  2M: 0.001846  1M: 0.002082 merged: 0.000000\n",
      " mg 16M: 0.002563 mg  8M: 0.002645 mg  4M: 0.002521 mg  2M: 0.002906 mg  1M: 0.000000mg merged: 0.002563\n",
      "epoch: 158 [2017-12-20 21:30:00]\n",
      " 16M: 0.003867  8M: 0.002995  4M: 0.002310  2M: 0.001831  1M: 0.002112 merged: 0.000000\n",
      " mg 16M: 0.002470 mg  8M: 0.002577 mg  4M: 0.002456 mg  2M: 0.002868 mg  1M: 0.000000mg merged: 0.002470\n",
      "epoch: 159 [2017-12-20 21:35:07]\n",
      " 16M: 0.003778  8M: 0.002914  4M: 0.002290  2M: 0.001813  1M: 0.002071 merged: 0.000000\n",
      " mg 16M: 0.002403 mg  8M: 0.002511 mg  4M: 0.002387 mg  2M: 0.002821 mg  1M: 0.000000mg merged: 0.002403\n",
      "epoch: 160 [2017-12-20 21:40:13]\n",
      " 16M: 0.003785  8M: 0.002941  4M: 0.002298  2M: 0.001796  1M: 0.002030 merged: 0.000000\n",
      " mg 16M: 0.002452 mg  8M: 0.002562 mg  4M: 0.002419 mg  2M: 0.002830 mg  1M: 0.000000mg merged: 0.002452\n",
      "epoch: 161 [2017-12-20 21:45:19]\n",
      " 16M: 0.003884  8M: 0.003005  4M: 0.002337  2M: 0.001776  1M: 0.002013 merged: 0.000000\n",
      " mg 16M: 0.002557 mg  8M: 0.002580 mg  4M: 0.002437 mg  2M: 0.002792 mg  1M: 0.000000mg merged: 0.002557\n",
      "epoch: 162 [2017-12-20 21:50:15]\n",
      " 16M: 0.003658  8M: 0.002863  4M: 0.002221  2M: 0.001792  1M: 0.001959 merged: 0.000000\n",
      " mg 16M: 0.002447 mg  8M: 0.002546 mg  4M: 0.002429 mg  2M: 0.002829 mg  1M: 0.000000mg merged: 0.002447\n",
      "epoch: 163 [2017-12-20 21:55:23]\n",
      " 16M: 0.003613  8M: 0.002831  4M: 0.002191  2M: 0.001700  1M: 0.001926 merged: 0.000000\n",
      " mg 16M: 0.002377 mg  8M: 0.002512 mg  4M: 0.002382 mg  2M: 0.002768 mg  1M: 0.000000mg merged: 0.002377\n",
      "epoch: 164 [2017-12-20 22:00:26]\n",
      " 16M: 0.003610  8M: 0.002824  4M: 0.002158  2M: 0.001766  1M: 0.001949 merged: 0.000000\n",
      " mg 16M: 0.002373 mg  8M: 0.002490 mg  4M: 0.002373 mg  2M: 0.002758 mg  1M: 0.000000mg merged: 0.002373\n",
      "epoch: 165 [2017-12-20 22:05:22]\n",
      " 16M: 0.003749  8M: 0.002926  4M: 0.002205  2M: 0.001806  1M: 0.001947 merged: 0.000000\n",
      " mg 16M: 0.002381 mg  8M: 0.002516 mg  4M: 0.002390 mg  2M: 0.002819 mg  1M: 0.000000mg merged: 0.002381\n",
      "epoch: 166 [2017-12-20 22:10:31]\n",
      " 16M: 0.003731  8M: 0.002951  4M: 0.002182  2M: 0.001720  1M: 0.001897 merged: 0.000000\n",
      " mg 16M: 0.002382 mg  8M: 0.002503 mg  4M: 0.002369 mg  2M: 0.002745 mg  1M: 0.000000mg merged: 0.002382\n",
      "epoch: 167 [2017-12-20 22:15:33]\n",
      " 16M: 0.003612  8M: 0.002790  4M: 0.002149  2M: 0.001743  1M: 0.001894 merged: 0.000000\n",
      " mg 16M: 0.002352 mg  8M: 0.002467 mg  4M: 0.002336 mg  2M: 0.002728 mg  1M: 0.000000mg merged: 0.002352\n",
      "epoch: 168 [2017-12-20 22:20:36]\n",
      " 16M: 0.003527  8M: 0.002760  4M: 0.002130  2M: 0.001699  1M: 0.001949 merged: 0.000000\n",
      " mg 16M: 0.002355 mg  8M: 0.002457 mg  4M: 0.002313 mg  2M: 0.002712 mg  1M: 0.000000mg merged: 0.002355\n",
      "epoch: 169 [2017-12-20 22:25:40]\n",
      " 16M: 0.003629  8M: 0.002844  4M: 0.002186  2M: 0.001705  1M: 0.001961 merged: 0.000000\n",
      " mg 16M: 0.002352 mg  8M: 0.002444 mg  4M: 0.002324 mg  2M: 0.002724 mg  1M: 0.000000mg merged: 0.002352\n",
      "epoch: 170 [2017-12-20 22:30:46]\n",
      " 16M: 0.003595  8M: 0.002834  4M: 0.002179  2M: 0.001702  1M: 0.001896 merged: 0.000000\n",
      " mg 16M: 0.002312 mg  8M: 0.002444 mg  4M: 0.002330 mg  2M: 0.002706 mg  1M: 0.000000mg merged: 0.002312\n",
      "epoch: 171 [2017-12-20 22:35:54]\n",
      " 16M: 0.003609  8M: 0.002839  4M: 0.002192  2M: 0.001657  1M: 0.001886 merged: 0.000000\n",
      " mg 16M: 0.002312 mg  8M: 0.002456 mg  4M: 0.002334 mg  2M: 0.002722 mg  1M: 0.000000mg merged: 0.002312\n",
      "epoch: 172 [2017-12-20 22:40:54]\n",
      " 16M: 0.003578  8M: 0.002795  4M: 0.002130  2M: 0.001712  1M: 0.001923 merged: 0.000000\n",
      " mg 16M: 0.002352 mg  8M: 0.002478 mg  4M: 0.002364 mg  2M: 0.002763 mg  1M: 0.000000mg merged: 0.002352\n",
      "epoch: 173 [2017-12-20 22:45:41]\n",
      " 16M: 0.003561  8M: 0.002819  4M: 0.002181  2M: 0.001754  1M: 0.001927 merged: 0.000000\n",
      " mg 16M: 0.002345 mg  8M: 0.002483 mg  4M: 0.002375 mg  2M: 0.002780 mg  1M: 0.000000mg merged: 0.002345\n",
      "epoch: 174 [2017-12-20 22:50:46]\n",
      " 16M: 0.003547  8M: 0.002787  4M: 0.002101  2M: 0.001693  1M: 0.001867 merged: 0.000000\n",
      " mg 16M: 0.002290 mg  8M: 0.002410 mg  4M: 0.002286 mg  2M: 0.002677 mg  1M: 0.000000mg merged: 0.002290\n",
      "epoch: 175 [2017-12-20 22:56:00]\n",
      " 16M: 0.003530  8M: 0.002752  4M: 0.002066  2M: 0.001682  1M: 0.001870 merged: 0.000000\n",
      " mg 16M: 0.002277 mg  8M: 0.002398 mg  4M: 0.002267 mg  2M: 0.002664 mg  1M: 0.000000mg merged: 0.002277\n",
      "epoch: 176 [2017-12-20 23:01:04]\n",
      " 16M: 0.003466  8M: 0.002680  4M: 0.002047  2M: 0.001654  1M: 0.001825 merged: 0.000000\n",
      " mg 16M: 0.002209 mg  8M: 0.002338 mg  4M: 0.002209 mg  2M: 0.002607 mg  1M: 0.000000mg merged: 0.002209\n",
      "epoch: 177 [2017-12-20 23:06:12]\n",
      " 16M: 0.003574  8M: 0.002783  4M: 0.002110  2M: 0.001673  1M: 0.001870 merged: 0.000000\n",
      " mg 16M: 0.002268 mg  8M: 0.002388 mg  4M: 0.002276 mg  2M: 0.002664 mg  1M: 0.000000mg merged: 0.002268\n",
      "epoch: 178 [2017-12-20 23:11:07]\n",
      " 16M: 0.003470  8M: 0.002709  4M: 0.002123  2M: 0.001663  1M: 0.001797 merged: 0.000000\n",
      " mg 16M: 0.002224 mg  8M: 0.002370 mg  4M: 0.002262 mg  2M: 0.002634 mg  1M: 0.000000mg merged: 0.002224\n",
      "epoch: 179 [2017-12-20 23:16:12]\n",
      " 16M: 0.003506  8M: 0.002799  4M: 0.002079  2M: 0.001615  1M: 0.001757 merged: 0.000000\n",
      " mg 16M: 0.002225 mg  8M: 0.002360 mg  4M: 0.002237 mg  2M: 0.002605 mg  1M: 0.000000mg merged: 0.002225\n",
      "epoch: 180 [2017-12-20 23:21:21]\n",
      " 16M: 0.003453  8M: 0.002723  4M: 0.002040  2M: 0.001563  1M: 0.001746 merged: 0.000000\n",
      " mg 16M: 0.002144 mg  8M: 0.002309 mg  4M: 0.002186 mg  2M: 0.002557 mg  1M: 0.000000mg merged: 0.002144\n",
      "epoch: 181 [2017-12-20 23:26:32]\n",
      " 16M: 0.003469  8M: 0.002663  4M: 0.002024  2M: 0.001610  1M: 0.001717 merged: 0.000000\n",
      " mg 16M: 0.002178 mg  8M: 0.002316 mg  4M: 0.002195 mg  2M: 0.002564 mg  1M: 0.000000mg merged: 0.002178\n",
      "epoch: 182 [2017-12-20 23:31:26]\n",
      " 16M: 0.003504  8M: 0.002777  4M: 0.002067  2M: 0.001637  1M: 0.001819 merged: 0.000000\n",
      " mg 16M: 0.002205 mg  8M: 0.002329 mg  4M: 0.002227 mg  2M: 0.002594 mg  1M: 0.000000mg merged: 0.002205\n",
      "epoch: 183 [2017-12-20 23:36:29]\n",
      " 16M: 0.003454  8M: 0.002741  4M: 0.002081  2M: 0.001612  1M: 0.001753 merged: 0.000000\n",
      " mg 16M: 0.002203 mg  8M: 0.002346 mg  4M: 0.002224 mg  2M: 0.002591 mg  1M: 0.000000mg merged: 0.002203\n",
      "epoch: 184 [2017-12-20 23:41:30]\n",
      " 16M: 0.003309  8M: 0.002628  4M: 0.001979  2M: 0.001569  1M: 0.001693 merged: 0.000000\n",
      " mg 16M: 0.002119 mg  8M: 0.002283 mg  4M: 0.002167 mg  2M: 0.002516 mg  1M: 0.000000mg merged: 0.002119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 185 [2017-12-20 23:46:39]\n",
      " 16M: 0.003441  8M: 0.002699  4M: 0.002053  2M: 0.001601  1M: 0.001749 merged: 0.000000\n",
      " mg 16M: 0.002203 mg  8M: 0.002344 mg  4M: 0.002212 mg  2M: 0.002584 mg  1M: 0.000000mg merged: 0.002203\n",
      "epoch: 186 [2017-12-20 23:51:45]\n",
      " 16M: 0.003330  8M: 0.002607  4M: 0.001974  2M: 0.001616  1M: 0.001771 merged: 0.000000\n",
      " mg 16M: 0.002168 mg  8M: 0.002317 mg  4M: 0.002196 mg  2M: 0.002581 mg  1M: 0.000000mg merged: 0.002168\n",
      "epoch: 187 [2017-12-20 23:56:47]\n",
      " 16M: 0.003517  8M: 0.002793  4M: 0.002063  2M: 0.001614  1M: 0.001725 merged: 0.000000\n",
      " mg 16M: 0.002193 mg  8M: 0.002332 mg  4M: 0.002215 mg  2M: 0.002567 mg  1M: 0.000000mg merged: 0.002193\n",
      "epoch: 188 [2017-12-21 00:01:55]\n",
      " 16M: 0.003288  8M: 0.002583  4M: 0.001963  2M: 0.001538  1M: 0.001681 merged: 0.000000\n",
      " mg 16M: 0.002118 mg  8M: 0.002259 mg  4M: 0.002153 mg  2M: 0.002535 mg  1M: 0.000000mg merged: 0.002118\n",
      "epoch: 189 [2017-12-21 00:06:57]\n",
      " 16M: 0.003311  8M: 0.002619  4M: 0.001965  2M: 0.001576  1M: 0.001700 merged: 0.000000\n",
      " mg 16M: 0.002098 mg  8M: 0.002263 mg  4M: 0.002157 mg  2M: 0.002552 mg  1M: 0.000000mg merged: 0.002098\n",
      "epoch: 190 [2017-12-21 00:12:09]\n",
      " 16M: 0.003334  8M: 0.002614  4M: 0.001989  2M: 0.001590  1M: 0.001735 merged: 0.000000\n",
      " mg 16M: 0.002096 mg  8M: 0.002272 mg  4M: 0.002179 mg  2M: 0.002583 mg  1M: 0.000000mg merged: 0.002096\n",
      "epoch: 191 [2017-12-21 00:17:09]\n",
      " 16M: 0.003278  8M: 0.002616  4M: 0.001926  2M: 0.001545  1M: 0.001668 merged: 0.000000\n",
      " mg 16M: 0.002095 mg  8M: 0.002263 mg  4M: 0.002140 mg  2M: 0.002494 mg  1M: 0.000000mg merged: 0.002095\n",
      "epoch: 192 [2017-12-21 00:22:10]\n",
      " 16M: 0.003391  8M: 0.002637  4M: 0.001988  2M: 0.001595  1M: 0.001721 merged: 0.000000\n",
      " mg 16M: 0.002134 mg  8M: 0.002297 mg  4M: 0.002188 mg  2M: 0.002552 mg  1M: 0.000000mg merged: 0.002134\n",
      "epoch: 193 [2017-12-21 00:27:12]\n",
      " 16M: 0.003371  8M: 0.002625  4M: 0.001976  2M: 0.001571  1M: 0.001704 merged: 0.000000\n",
      " mg 16M: 0.002071 mg  8M: 0.002231 mg  4M: 0.002137 mg  2M: 0.002528 mg  1M: 0.000000mg merged: 0.002071\n",
      "epoch: 194 [2017-12-21 00:32:09]\n",
      " 16M: 0.003231  8M: 0.002533  4M: 0.001920  2M: 0.001503  1M: 0.001654 merged: 0.000000\n",
      " mg 16M: 0.002063 mg  8M: 0.002220 mg  4M: 0.002118 mg  2M: 0.002484 mg  1M: 0.000000mg merged: 0.002063\n",
      "epoch: 195 [2017-12-21 00:37:19]\n",
      " 16M: 0.003196  8M: 0.002518  4M: 0.001894  2M: 0.001488  1M: 0.001656 merged: 0.000000\n",
      " mg 16M: 0.002023 mg  8M: 0.002188 mg  4M: 0.002081 mg  2M: 0.002424 mg  1M: 0.000000mg merged: 0.002023\n",
      "epoch: 196 [2017-12-21 00:42:18]\n",
      " 16M: 0.003200  8M: 0.002541  4M: 0.001952  2M: 0.001545  1M: 0.001639 merged: 0.000000\n",
      " mg 16M: 0.002044 mg  8M: 0.002214 mg  4M: 0.002115 mg  2M: 0.002471 mg  1M: 0.000000mg merged: 0.002044\n",
      "epoch: 197 [2017-12-21 00:47:19]\n",
      " 16M: 0.003230  8M: 0.002484  4M: 0.001850  2M: 0.001469  1M: 0.001613 merged: 0.000000\n",
      " mg 16M: 0.002032 mg  8M: 0.002216 mg  4M: 0.002101 mg  2M: 0.002451 mg  1M: 0.000000mg merged: 0.002032\n",
      "epoch: 198 [2017-12-21 00:52:17]\n",
      " 16M: 0.003306  8M: 0.002607  4M: 0.001957  2M: 0.001583  1M: 0.001745 merged: 0.000000\n",
      " mg 16M: 0.002061 mg  8M: 0.002242 mg  4M: 0.002138 mg  2M: 0.002516 mg  1M: 0.000000mg merged: 0.002061\n",
      "epoch: 199 [2017-12-21 00:57:16]\n",
      " 16M: 0.003287  8M: 0.002552  4M: 0.001902  2M: 0.001517  1M: 0.001625 merged: 0.000000\n",
      " mg 16M: 0.002025 mg  8M: 0.002208 mg  4M: 0.002097 mg  2M: 0.002476 mg  1M: 0.000000mg merged: 0.002025\n",
      "epoch: 200 [2017-12-21 01:02:24]\n",
      " 16M: 0.003147  8M: 0.002465  4M: 0.001879  2M: 0.001543  1M: 0.001643 merged: 0.000000\n",
      " mg 16M: 0.002016 mg  8M: 0.002199 mg  4M: 0.002109 mg  2M: 0.002523 mg  1M: 0.000000mg merged: 0.002016\n",
      "epoch: 201 [2017-12-21 01:07:19]\n",
      " 16M: 0.003192  8M: 0.002516  4M: 0.001903  2M: 0.001550  1M: 0.001665 merged: 0.000000\n",
      " mg 16M: 0.002016 mg  8M: 0.002202 mg  4M: 0.002094 mg  2M: 0.002458 mg  1M: 0.000000mg merged: 0.002016\n",
      "epoch: 202 [2017-12-21 01:12:23]\n",
      " 16M: 0.003300  8M: 0.002535  4M: 0.001896  2M: 0.001527  1M: 0.001617 merged: 0.000000\n",
      " mg 16M: 0.002064 mg  8M: 0.002231 mg  4M: 0.002113 mg  2M: 0.002488 mg  1M: 0.000000mg merged: 0.002064\n",
      "epoch: 203 [2017-12-21 01:17:26]\n",
      " 16M: 0.003192  8M: 0.002487  4M: 0.001882  2M: 0.001475  1M: 0.001619 merged: 0.000000\n",
      " mg 16M: 0.002009 mg  8M: 0.002177 mg  4M: 0.002065 mg  2M: 0.002414 mg  1M: 0.000000mg merged: 0.002009\n",
      "epoch: 204 [2017-12-21 01:22:31]\n",
      " 16M: 0.003230  8M: 0.002491  4M: 0.001910  2M: 0.001529  1M: 0.001641 merged: 0.000000\n",
      " mg 16M: 0.002013 mg  8M: 0.002183 mg  4M: 0.002074 mg  2M: 0.002454 mg  1M: 0.000000mg merged: 0.002013\n",
      "epoch: 205 [2017-12-21 01:27:43]\n",
      " 16M: 0.003127  8M: 0.002414  4M: 0.001829  2M: 0.001472  1M: 0.001576 merged: 0.000000\n",
      " mg 16M: 0.001955 mg  8M: 0.002136 mg  4M: 0.002034 mg  2M: 0.002394 mg  1M: 0.000000mg merged: 0.001955\n",
      "epoch: 206 [2017-12-21 01:32:45]\n",
      " 16M: 0.003174  8M: 0.002460  4M: 0.001852  2M: 0.001467  1M: 0.001571 merged: 0.000000\n",
      " mg 16M: 0.001996 mg  8M: 0.002166 mg  4M: 0.002060 mg  2M: 0.002401 mg  1M: 0.000000mg merged: 0.001996\n",
      "epoch: 207 [2017-12-21 01:37:47]\n",
      " 16M: 0.003138  8M: 0.002479  4M: 0.001845  2M: 0.001485  1M: 0.001576 merged: 0.000000\n",
      " mg 16M: 0.001959 mg  8M: 0.002131 mg  4M: 0.002024 mg  2M: 0.002397 mg  1M: 0.000000mg merged: 0.001959\n",
      "epoch: 208 [2017-12-21 01:42:47]\n",
      " 16M: 0.003195  8M: 0.002499  4M: 0.001879  2M: 0.001480  1M: 0.001604 merged: 0.000000\n",
      " mg 16M: 0.001984 mg  8M: 0.002165 mg  4M: 0.002059 mg  2M: 0.002415 mg  1M: 0.000000mg merged: 0.001984\n",
      "epoch: 209 [2017-12-21 01:47:48]\n",
      " 16M: 0.003103  8M: 0.002420  4M: 0.001809  2M: 0.001454  1M: 0.001577 merged: 0.000000\n",
      " mg 16M: 0.001945 mg  8M: 0.002136 mg  4M: 0.002037 mg  2M: 0.002393 mg  1M: 0.000000mg merged: 0.001945\n",
      "epoch: 210 [2017-12-21 01:52:52]\n",
      " 16M: 0.003165  8M: 0.002526  4M: 0.001868  2M: 0.001469  1M: 0.001564 merged: 0.000000\n",
      " mg 16M: 0.001968 mg  8M: 0.002168 mg  4M: 0.002065 mg  2M: 0.002417 mg  1M: 0.000000mg merged: 0.001968\n",
      "epoch: 211 [2017-12-21 01:57:52]\n",
      " 16M: 0.003150  8M: 0.002487  4M: 0.001822  2M: 0.001475  1M: 0.001582 merged: 0.000000\n",
      " mg 16M: 0.001963 mg  8M: 0.002136 mg  4M: 0.002027 mg  2M: 0.002388 mg  1M: 0.000000mg merged: 0.001963\n",
      "epoch: 212 [2017-12-21 02:02:53]\n",
      " 16M: 0.003024  8M: 0.002353  4M: 0.001750  2M: 0.001451  1M: 0.001562 merged: 0.000000\n",
      " mg 16M: 0.001896 mg  8M: 0.002086 mg  4M: 0.001987 mg  2M: 0.002366 mg  1M: 0.000000mg merged: 0.001896\n",
      "epoch: 213 [2017-12-21 02:07:51]\n",
      " 16M: 0.003078  8M: 0.002393  4M: 0.001799  2M: 0.001437  1M: 0.001533 merged: 0.000000\n",
      " mg 16M: 0.001933 mg  8M: 0.002118 mg  4M: 0.002010 mg  2M: 0.002361 mg  1M: 0.000000mg merged: 0.001933\n",
      "epoch: 214 [2017-12-21 02:12:57]\n",
      " 16M: 0.003079  8M: 0.002417  4M: 0.001819  2M: 0.001480  1M: 0.001575 merged: 0.000000\n",
      " mg 16M: 0.001916 mg  8M: 0.002108 mg  4M: 0.002013 mg  2M: 0.002361 mg  1M: 0.000000mg merged: 0.001916\n",
      "epoch: 215 [2017-12-21 02:18:07]\n",
      " 16M: 0.003075  8M: 0.002387  4M: 0.001793  2M: 0.001472  1M: 0.001526 merged: 0.000000\n",
      " mg 16M: 0.001928 mg  8M: 0.002109 mg  4M: 0.002011 mg  2M: 0.002374 mg  1M: 0.000000mg merged: 0.001928\n",
      "epoch: 216 [2017-12-21 02:23:05]\n",
      " 16M: 0.003087  8M: 0.002406  4M: 0.001813  2M: 0.001477  1M: 0.001533 merged: 0.000000\n",
      " mg 16M: 0.001926 mg  8M: 0.002118 mg  4M: 0.002034 mg  2M: 0.002415 mg  1M: 0.000000mg merged: 0.001926\n",
      "epoch: 217 [2017-12-21 02:28:09]\n",
      " 16M: 0.003066  8M: 0.002391  4M: 0.001791  2M: 0.001420  1M: 0.001506 merged: 0.000000\n",
      " mg 16M: 0.001907 mg  8M: 0.002102 mg  4M: 0.001993 mg  2M: 0.002340 mg  1M: 0.000000mg merged: 0.001907\n",
      "epoch: 218 [2017-12-21 02:33:08]\n",
      " 16M: 0.003111  8M: 0.002406  4M: 0.001771  2M: 0.001456  1M: 0.001550 merged: 0.000000\n",
      " mg 16M: 0.001922 mg  8M: 0.002114 mg  4M: 0.002016 mg  2M: 0.002383 mg  1M: 0.000000mg merged: 0.001922\n",
      "epoch: 219 [2017-12-21 02:38:04]\n",
      " 16M: 0.002983  8M: 0.002341  4M: 0.001745  2M: 0.001425  1M: 0.001528 merged: 0.000000\n",
      " mg 16M: 0.001859 mg  8M: 0.002052 mg  4M: 0.001957 mg  2M: 0.002334 mg  1M: 0.000000mg merged: 0.001859\n",
      "epoch: 220 [2017-12-21 02:43:18]\n",
      " 16M: 0.003000  8M: 0.002336  4M: 0.001762  2M: 0.001399  1M: 0.001508 merged: 0.000000\n",
      " mg 16M: 0.001877 mg  8M: 0.002085 mg  4M: 0.001990 mg  2M: 0.002358 mg  1M: 0.000000mg merged: 0.001877\n",
      "epoch: 221 [2017-12-21 02:48:21]\n",
      " 16M: 0.003008  8M: 0.002320  4M: 0.001748  2M: 0.001405  1M: 0.001482 merged: 0.000000\n",
      " mg 16M: 0.001849 mg  8M: 0.002041 mg  4M: 0.001949 mg  2M: 0.002331 mg  1M: 0.000000mg merged: 0.001849\n",
      "epoch: 222 [2017-12-21 02:53:20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.003007  8M: 0.002342  4M: 0.001747  2M: 0.001390  1M: 0.001499 merged: 0.000000\n",
      " mg 16M: 0.001873 mg  8M: 0.002066 mg  4M: 0.001965 mg  2M: 0.002306 mg  1M: 0.000000mg merged: 0.001873\n",
      "epoch: 223 [2017-12-21 02:58:23]\n",
      " 16M: 0.002974  8M: 0.002336  4M: 0.001748  2M: 0.001414  1M: 0.001488 merged: 0.000000\n",
      " mg 16M: 0.001859 mg  8M: 0.002050 mg  4M: 0.001956 mg  2M: 0.002318 mg  1M: 0.000000mg merged: 0.001859\n",
      "epoch: 224 [2017-12-21 03:03:26]\n",
      " 16M: 0.002949  8M: 0.002326  4M: 0.001736  2M: 0.001380  1M: 0.001442 merged: 0.000000\n",
      " mg 16M: 0.001823 mg  8M: 0.002012 mg  4M: 0.001920 mg  2M: 0.002260 mg  1M: 0.000000mg merged: 0.001823\n",
      "epoch: 225 [2017-12-21 03:08:35]\n",
      " 16M: 0.002923  8M: 0.002311  4M: 0.001717  2M: 0.001389  1M: 0.001490 merged: 0.000000\n",
      " mg 16M: 0.001842 mg  8M: 0.002052 mg  4M: 0.001958 mg  2M: 0.002334 mg  1M: 0.000000mg merged: 0.001842\n",
      "epoch: 226 [2017-12-21 03:13:37]\n",
      " 16M: 0.002939  8M: 0.002280  4M: 0.001727  2M: 0.001377  1M: 0.001478 merged: 0.000000\n",
      " mg 16M: 0.001834 mg  8M: 0.002042 mg  4M: 0.001954 mg  2M: 0.002298 mg  1M: 0.000000mg merged: 0.001834\n",
      "epoch: 227 [2017-12-21 03:18:36]\n",
      " 16M: 0.002915  8M: 0.002272  4M: 0.001721  2M: 0.001366  1M: 0.001451 merged: 0.000000\n",
      " mg 16M: 0.001808 mg  8M: 0.002006 mg  4M: 0.001910 mg  2M: 0.002245 mg  1M: 0.000000mg merged: 0.001808\n",
      "epoch: 228 [2017-12-21 03:23:43]\n",
      " 16M: 0.002979  8M: 0.002296  4M: 0.001704  2M: 0.001359  1M: 0.001475 merged: 0.000000\n",
      " mg 16M: 0.001836 mg  8M: 0.002033 mg  4M: 0.001935 mg  2M: 0.002302 mg  1M: 0.000000mg merged: 0.001836\n",
      "epoch: 229 [2017-12-21 03:28:45]\n",
      " 16M: 0.002891  8M: 0.002294  4M: 0.001680  2M: 0.001395  1M: 0.001451 merged: 0.000000\n",
      " mg 16M: 0.001822 mg  8M: 0.002022 mg  4M: 0.001923 mg  2M: 0.002305 mg  1M: 0.000000mg merged: 0.001822\n",
      "epoch: 230 [2017-12-21 03:33:51]\n",
      " 16M: 0.002913  8M: 0.002259  4M: 0.001683  2M: 0.001358  1M: 0.001425 merged: 0.000000\n",
      " mg 16M: 0.001822 mg  8M: 0.002018 mg  4M: 0.001913 mg  2M: 0.002281 mg  1M: 0.000000mg merged: 0.001822\n",
      "epoch: 231 [2017-12-21 03:38:54]\n",
      " 16M: 0.002999  8M: 0.002347  4M: 0.001711  2M: 0.001408  1M: 0.001500 merged: 0.000000\n",
      " mg 16M: 0.001829 mg  8M: 0.002029 mg  4M: 0.001933 mg  2M: 0.002286 mg  1M: 0.000000mg merged: 0.001829\n",
      "epoch: 232 [2017-12-21 03:43:54]\n",
      " 16M: 0.002858  8M: 0.002241  4M: 0.001656  2M: 0.001330  1M: 0.001415 merged: 0.000000\n",
      " mg 16M: 0.001794 mg  8M: 0.001998 mg  4M: 0.001900 mg  2M: 0.002243 mg  1M: 0.000000mg merged: 0.001794\n",
      "epoch: 233 [2017-12-21 03:48:52]\n",
      " 16M: 0.002899  8M: 0.002277  4M: 0.001690  2M: 0.001385  1M: 0.001453 merged: 0.000000\n",
      " mg 16M: 0.001816 mg  8M: 0.002034 mg  4M: 0.001951 mg  2M: 0.002338 mg  1M: 0.000000mg merged: 0.001816\n",
      "epoch: 234 [2017-12-21 03:53:49]\n",
      " 16M: 0.002882  8M: 0.002244  4M: 0.001666  2M: 0.001387  1M: 0.001472 merged: 0.000000\n",
      " mg 16M: 0.001803 mg  8M: 0.002009 mg  4M: 0.001922 mg  2M: 0.002285 mg  1M: 0.000000mg merged: 0.001803\n",
      "epoch: 235 [2017-12-21 03:58:55]\n",
      " 16M: 0.002877  8M: 0.002231  4M: 0.001654  2M: 0.001371  1M: 0.001436 merged: 0.000000\n",
      " mg 16M: 0.001781 mg  8M: 0.001997 mg  4M: 0.001905 mg  2M: 0.002274 mg  1M: 0.000000mg merged: 0.001781\n",
      "epoch: 236 [2017-12-21 04:03:57]\n",
      " 16M: 0.002835  8M: 0.002250  4M: 0.001655  2M: 0.001340  1M: 0.001452 merged: 0.000000\n",
      " mg 16M: 0.001778 mg  8M: 0.001989 mg  4M: 0.001892 mg  2M: 0.002245 mg  1M: 0.000000mg merged: 0.001778\n",
      "epoch: 237 [2017-12-21 04:08:57]\n",
      " 16M: 0.002860  8M: 0.002257  4M: 0.001643  2M: 0.001353  1M: 0.001435 merged: 0.000000\n",
      " mg 16M: 0.001818 mg  8M: 0.002026 mg  4M: 0.001930 mg  2M: 0.002297 mg  1M: 0.000000mg merged: 0.001818\n",
      "epoch: 238 [2017-12-21 04:13:58]\n",
      " 16M: 0.002873  8M: 0.002251  4M: 0.001666  2M: 0.001333  1M: 0.001409 merged: 0.000000\n",
      " mg 16M: 0.001783 mg  8M: 0.001994 mg  4M: 0.001895 mg  2M: 0.002243 mg  1M: 0.000000mg merged: 0.001783\n",
      "epoch: 239 [2017-12-21 04:19:01]\n",
      " 16M: 0.002780  8M: 0.002186  4M: 0.001586  2M: 0.001295  1M: 0.001359 merged: 0.000000\n",
      " mg 16M: 0.001752 mg  8M: 0.001965 mg  4M: 0.001859 mg  2M: 0.002201 mg  1M: 0.000000mg merged: 0.001752\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "writer = SummaryWriter(comment='-{}'.format(writer_comment))\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "optimizer = optim.SGD(parameters, lr=args.base_lr, momentum=args.momentum)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, beg, end, reset_lr=None, base_lr=args.base_lr):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "#         print('para gp', param_group)\n",
    "        if reset_lr != None:\n",
    "            param_group['lr'] = reset_lr\n",
    "            continue\n",
    "        param_group['lr'] = base_lr * (float(end-epoch)/(end-beg)) ** (args.power)\n",
    "        if param_group['lr'] < 1.0e-8: param_group['lr'] = 1.0e-8\n",
    "        \n",
    "\n",
    "for epoch in range(args.epoches):\n",
    "#     epoch = 234\n",
    "    net.train()\n",
    "    print('epoch: {} [{}]'.format(epoch, datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "\n",
    "    if epoch < args.training_thresholds[-1]: \n",
    "        adjust_learning_rate(optimizer, epoch, beg=0, end=s0-1)\n",
    "    elif epoch < args.training_merge_thresholds[-1]:\n",
    "        adjust_learning_rate(optimizer, (epoch-s0)%(ss), beg=0, end=ss-1, base_lr=args.base_lr)\n",
    "    else:\n",
    "        adjust_learning_rate(optimizer, epoch, beg=args.training_merge_thresholds[-1], end=args.epoches-1, base_lr=args.base_lr)  \n",
    "        \n",
    "        \n",
    "    if epoch < args.training_thresholds[-1]: go_through_merge = False\n",
    "    elif epoch >= args.training_merge_thresholds[5]: go_through_merge = '32M'\n",
    "    elif epoch >= args.training_merge_thresholds[0]: go_through_merge = '16M'\n",
    "    elif epoch >= args.training_merge_thresholds[1]: go_through_merge = '08M'\n",
    "    elif epoch >= args.training_merge_thresholds[2]: go_through_merge = '04M'\n",
    "    elif epoch >= args.training_merge_thresholds[3]: go_through_merge = '02M'\n",
    "\n",
    "    run_losses = [0] * len(args.training_thresholds)\n",
    "    run_cnts   = [0.00001] * len(args.training_thresholds)\n",
    "    run_merge_losses = [0] * len(args.training_thresholds)\n",
    "    run_merge_cnts   = [0.00001] * len(args.training_thresholds)\n",
    "    if (epoch in args.training_thresholds) == True: \n",
    "        adjust_learning_rate(optimizer, epoch, reset_lr=args.base_lr, beg=-1, end=-1)\n",
    "    if (epoch in args.training_merge_thresholds) == True:\n",
    "        adjust_learning_rate(optimizer, epoch, reset_lr=args.base_lr, beg=-1, end=-1)\n",
    "        \n",
    "    writer.add_scalar('learning rate', optimizer.param_groups[0]['lr'], global_step=epoch)\n",
    "    for ind, data in enumerate(train_loader, 0):\n",
    "#         if  ind == 1 : break\n",
    "        \"\"\"prepare  training data\"\"\"\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        im = input_img[0,:,:,:].numpy(); im = im.transpose(1,2,0); im = im[:,:,::-1]*255\n",
    "        input_img, gt_albedo, gt_shading = Variable(input_img), Variable(gt_albedo), Variable(gt_shading)\n",
    "        if use_gpu: input_img, gt_albedo, gt_shading = input_img.cuda(), gt_albedo.cuda(), gt_shading.cuda()\n",
    "\n",
    "        if args.display_curindex % args.display_interval == 0: cv2.imwrite('snapshot{}/input.png'.format(args.gpu_num), im)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "            \n",
    "        ft_predict, merged_RGB = net(input_img, go_through_merge=go_through_merge)\n",
    "        for i, threshold in enumerate(args.training_thresholds):\n",
    "            if epoch >= threshold:\n",
    "#             if epoch >= 0:\n",
    "                \"\"\"prepare resized gt\"\"\"\n",
    "                if i == 5: s = 1\n",
    "                else: s = (2**(i+1))\n",
    "                gt0 = gt_albedo.cpu().data.numpy()\n",
    "                n,c,h,w = gt0.shape\n",
    "                gt, display = myutils.processGt(gt0, scale_factor=s, gd=gradient, return_image=True)\n",
    "                gt_mg, display_mg = myutils.processGt(gt0, scale_factor=s//2, gd=gradient, return_image=True)\n",
    "                if use_gpu: \n",
    "                    gt = gt.cuda()\n",
    "                    gt_mg = gt_mg.cuda()\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    display = display[:,:,0:3]\n",
    "                    cv2.imwrite('snapshot{}/gt-{}-{}.png'.format(args.gpu_num, epoch, i), display[:,:,::-1]*255)                \n",
    "                \n",
    "                \"\"\"compute loss\"\"\"\n",
    "                if i != 5: \n",
    "                    loss = mse_losses[i](ft_predict[i], gt)\n",
    "                    run_losses[i] += loss.data.cpu().numpy()[0]\n",
    "                    loss.backward(retain_graph=True)\n",
    "                    run_cnts[i] += 1\n",
    "                \n",
    "                if go_through_merge != False and i != 4:\n",
    "                    if ((go_through_merge == '32M') or\n",
    "                    (go_through_merge == '16M' and i != 5) or  \n",
    "                    (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                    (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                    (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "#                         print(epoch, go_through_merge, i)\n",
    "                        \n",
    "#                         print (merged_RGB[i].cpu().data.numpy().max(), merged_RGB[i].cpu().data.numpy().min())\n",
    "                        if i==5: gt2=gt\n",
    "                        else: gt2=gt_mg\n",
    "#                         print(i)\n",
    "#                         print('merge size', merged_RGB[i].size())\n",
    "#                         print('gt2 size', gt2.size())\n",
    "                        loss = mse_merge_losses[i](merged_RGB[i], gt2)\n",
    "                        run_merge_losses[i] += loss.data.cpu().numpy()[0]\n",
    "                        loss.backward(retain_graph=True)\n",
    "                        run_merge_cnts[i] += 1\n",
    "                \n",
    "                \"\"\"save training image\"\"\"\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    \n",
    "                    if i != 5:\n",
    "                        im = (ft_predict[i].cpu().data.numpy()[0].transpose((1,2,0))+offset) * 255\n",
    "                        im = im[:,:,0:3]\n",
    "                        \n",
    "                        cv2.imwrite('snapshot{}/train-{}-{}.png'.format(args.gpu_num, epoch, i), im[:,:,::-1])\n",
    "                    \n",
    "                    if go_through_merge != False and i != 4:\n",
    "                        if ((go_through_merge == '32M') or\n",
    "                        (go_through_merge == '16M' and i != 5) or  \n",
    "                        (go_through_merge == '08M' and i != 5 and i > 0) or\n",
    "                        (go_through_merge == '04M' and i != 5 and i > 1) or\n",
    "                        (go_through_merge == '02M' and i != 5 and i > 2)):\n",
    "                            im = (merged_RGB[i].cpu().data.numpy()[0].transpose((1,2,0))+offset) * 255\n",
    "                            im = im[:,:,0:3]\n",
    "                            cv2.imwrite('snapshot{}/train-mg-{}-{}.png'.format(args.gpu_num, epoch, i), im[:,:,::-1])\n",
    "        optimizer.step()\n",
    "        args.display_curindex += 1\n",
    "\n",
    "    \"\"\" every epoch \"\"\"\n",
    "#     loss_output = 'ind: ' + str(args.display_curindex)\n",
    "    loss_output = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i,v in enumerate(run_losses):\n",
    "        if i == len(run_losses)-1: \n",
    "            loss_output += ' merged: %6f' % (run_losses[i] / run_cnts[i])\n",
    "            continue\n",
    "        loss_output += ' %2dM: %6f' % ((2**(4-i)), (run_losses[i] / run_cnts[i]))\n",
    "    print(loss_output)\n",
    "    loss_output = ''\n",
    "    for i,v in enumerate(run_merge_losses):\n",
    "        if i == len(run_merge_losses)-1: \n",
    "            loss_output += 'mg merged: %6f' % (run_merge_losses[i] / run_merge_cnts[i])\n",
    "            continue\n",
    "        loss_output += ' mg %2dM: %6f' % ((2**(4-i)), (run_merge_losses[i] / run_merge_cnts[i]))\n",
    "    print(loss_output)\n",
    "    \n",
    "    \"\"\"save at every epoch\"\"\"\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'args' : args,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, 'snapshot{}/snapshot-{}.pth.tar'.format(args.gpu_num, epoch))\n",
    "    \n",
    "    # test \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        test_model(epoch, phase='train', go_through_merge=go_through_merge)\n",
    "        test_model(epoch, phase='test', go_through_merge=go_through_merge)\n",
    "\n",
    "        writer.add_scalars('16M loss', {'train 16M ': np.array([run_losses[0]/ run_cnts[0]])}, global_step=epoch)  \n",
    "        writer.add_scalars('8M loss', {'train 8M ': np.array([run_losses[1]/ run_cnts[1]])}, global_step=epoch) \n",
    "        writer.add_scalars('4M loss', {'train 4M ': np.array([run_losses[2]/ run_cnts[2]])}, global_step=epoch) \n",
    "        writer.add_scalars('2M loss', {'train 2M ': np.array([run_losses[3]/ run_cnts[3]])}, global_step=epoch) \n",
    "        writer.add_scalars('1M loss', {'train 1M ': np.array([run_losses[4]/ run_cnts[4]])}, global_step=epoch) \n",
    "        writer.add_scalars('merged loss', {'train merged ': np.array([run_losses[5]/ run_cnts[5]])}, global_step=epoch) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"10240,10240\"), format='svg')\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = Variable(torch.zeros(1,3,256,256))\n",
    "# y = net(x.cuda())\n",
    "# g = make_dot(y[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g.render('net-transition_scale_{}'.format(transition_scale)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
