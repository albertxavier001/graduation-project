{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, platform, datetime, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import functional as F\n",
    "# import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc\n",
    "\n",
    "from myimagefolder import MyImageFolder\n",
    "from mymodel import GradientNet\n",
    "from myargs import Args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('debian', 'jessie/sid', '')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = Args()\n",
    "args.test_scene = 'alley_1'\n",
    "args.arch = \"densenet121\"\n",
    "args.epoches = 500\n",
    "args.epoches_unary_threshold = 0\n",
    "args.image_h = 256\n",
    "args.image_w = 256\n",
    "args.img_extentions = [\"png\"]\n",
    "args.training_thresholds = [250,200,150,50,0,300]\n",
    "args.base_lr = 1\n",
    "args.lr = args.base_lr\n",
    "args.snapshot_interval = 5000\n",
    "args.debug = True\n",
    "args.gpu_num = 0\n",
    "# growth_rate = (4*(2**(args.gpu_num)))\n",
    "transition_scale=(2*(2**(args.gpu_num+1)))\n",
    "growth_rate = 32\n",
    "args.display_interval = 50\n",
    "args.display_curindex = 0\n",
    "\n",
    "system_ = platform.system()\n",
    "system_dist, system_version, _ = platform.dist()\n",
    "if system_ == \"Darwin\": \n",
    "    args.train_dir = '/Volumes/Transcend/dataset/sintel2'\n",
    "    args.pretrained = False\n",
    "elif platform.dist() ==  ('debian', 'jessie/sid', ''):\n",
    "    args.train_dir = '/home/lwp/workspace/sintel2'\n",
    "    args.pretrained = True\n",
    "elif platform.dist() == ('debian', 'stretch/sid', ''):\n",
    "    args.train_dir = '/home/cad/lwp/workspace/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "\n",
    "if platform.system() == 'Linux': use_gpu = True\n",
    "else: use_gpu = False\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.gpu_num)\n",
    "    \n",
    "\n",
    "print(platform.dist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = MyImageFolder(args.train_dir, 'train',\n",
    "                       transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ), random_crop=True, \n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "test_dataset = MyImageFolder(args.train_dir, 'test', \n",
    "                       transforms.Compose(\n",
    "        [transforms.CenterCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ), random_crop=False,\n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset,1,True,num_workers=1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "[Defination](https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py)\n",
    "* DenseNet-121: num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16)\n",
    "    * First Convolution: 32M -> 16M -> 8M\n",
    "    * every transition: 8M -> 4M -> 2M (downsample 1/2, except the last block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenet = models.__dict__[args.arch](pretrained=args.pretrained)\n",
    "\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if use_gpu: densenet.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 6\n",
    "\n",
    "args.display_curindex = 0\n",
    "args.base_lr = 0.05\n",
    "args.display_interval = 20\n",
    "args.momentum = 0.9\n",
    "args.epoches = 120\n",
    "args.training_thresholds = [ss*4,ss*3,ss*2,ss*1,ss*0,ss*5]\n",
    "args.power = 0.5\n",
    "\n",
    "\n",
    "\n",
    "# pretrained = PreTrainedModel(densenet)\n",
    "# if use_gpu: \n",
    "#     pretrained.cuda()\n",
    "\n",
    "\n",
    "net = GradientNet(densenet=densenet, growth_rate=growth_rate, transition_scale=transition_scale)\n",
    "if use_gpu:\n",
    "    net.cuda()\n",
    "\n",
    "if use_gpu: \n",
    "    mse_losses = [nn.MSELoss().cuda()] * 6\n",
    "    test_losses = [nn.MSELoss().cuda()] * 6\n",
    "else:\n",
    "    mse_losses = [nn.MSELoss()] * 6\n",
    "    test_losses = [nn.MSELoss()] * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [2017-11-23 15:43:27]\n",
      "lr 0.05\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.056346 merged: 0.000000\n",
      "epoch: 1 [2017-11-23 15:45:35]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.051293 merged: 0.000000\n",
      "epoch: 2 [2017-11-23 15:47:41]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.050426 merged: 0.000000\n",
      "epoch: 3 [2017-11-23 15:49:48]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.045310 merged: 0.000000\n",
      "epoch: 4 [2017-11-23 15:51:54]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.041864 merged: 0.000000\n",
      "epoch: 5 [2017-11-23 15:54:01]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.038081 merged: 0.000000\n",
      "epoch: 6 [2017-11-23 15:56:07]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.050632  1M: 0.044893 merged: 0.000000\n",
      "epoch: 7 [2017-11-23 15:58:36]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.041830  1M: 0.037297 merged: 0.000000\n",
      "epoch: 8 [2017-11-23 16:01:10]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.038328  1M: 0.036307 merged: 0.000000\n",
      "epoch: 9 [2017-11-23 16:03:48]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.030455  1M: 0.031241 merged: 0.000000\n",
      "epoch: 10 [2017-11-23 16:06:18]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.023524  1M: 0.028136 merged: 0.000000\n",
      "epoch: 11 [2017-11-23 16:08:50]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.020230  1M: 0.028566 merged: 0.000000\n",
      "epoch: 12 [2017-11-23 16:11:21]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.048583  2M: 0.027805  1M: 0.031723 merged: 0.000000\n",
      "epoch: 13 [2017-11-23 16:14:11]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.039270  2M: 0.023627  1M: 0.029941 merged: 0.000000\n",
      "epoch: 14 [2017-11-23 16:16:55]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.028857  2M: 0.020459  1M: 0.027377 merged: 0.000000\n",
      "epoch: 15 [2017-11-23 16:19:40]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.023017  2M: 0.018355  1M: 0.025514 merged: 0.000000\n",
      "epoch: 16 [2017-11-23 16:22:27]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.019011  2M: 0.016497  1M: 0.023245 merged: 0.000000\n",
      "epoch: 17 [2017-11-23 16:25:16]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.018064  2M: 0.016422  1M: 0.022323 merged: 0.000000\n",
      "epoch: 18 [2017-11-23 16:28:10]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.047219  4M: 0.025861  2M: 0.018504  1M: 0.026694 merged: 0.000000\n",
      "epoch: 19 [2017-11-23 16:31:10]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.000000  8M: 0.037033  4M: 0.021127  2M: 0.017448  1M: 0.024489 merged: 0.000000\n",
      "epoch: 20 [2017-11-23 16:34:14]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.000000  8M: 0.026921  4M: 0.017209  2M: 0.016117  1M: 0.024114 merged: 0.000000\n",
      "epoch: 21 [2017-11-23 16:37:11]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.000000  8M: 0.022049  4M: 0.015750  2M: 0.014885  1M: 0.022948 merged: 0.000000\n",
      "epoch: 22 [2017-11-23 16:40:12]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.000000  8M: 0.018257  4M: 0.014509  2M: 0.014577  1M: 0.022100 merged: 0.000000\n",
      "epoch: 23 [2017-11-23 16:43:15]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.018828  4M: 0.014502  2M: 0.014097  1M: 0.023216 merged: 0.000000\n",
      "epoch: 24 [2017-11-23 16:46:13]\n",
      "lr 1e-08\n",
      " 16M: 0.043308  8M: 0.021372  4M: 0.016752  2M: 0.015713  1M: 0.024243 merged: 0.000000\n",
      "epoch: 25 [2017-11-23 16:49:25]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.032101  8M: 0.018288  4M: 0.016559  2M: 0.014735  1M: 0.023415 merged: 0.000000\n",
      "epoch: 26 [2017-11-23 16:52:37]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.023015  8M: 0.015692  4M: 0.014008  2M: 0.014034  1M: 0.022839 merged: 0.000000\n",
      "epoch: 27 [2017-11-23 16:55:50]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.020160  8M: 0.014811  4M: 0.012931  2M: 0.013113  1M: 0.021341 merged: 0.000000\n",
      "epoch: 28 [2017-11-23 16:58:59]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.017321  8M: 0.012983  4M: 0.012009  2M: 0.012536  1M: 0.021214 merged: 0.000000\n",
      "epoch: 29 [2017-11-23 17:02:10]\n",
      "lr 1e-08\n",
      " 16M: 0.016378  8M: 0.012169  4M: 0.011484  2M: 0.011850  1M: 0.019770 merged: 0.000000\n",
      "epoch: 30 [2017-11-23 17:05:22]\n",
      "lr 0.05\n",
      " 16M: 0.020712  8M: 0.017511  4M: 0.014794  2M: 0.014449  1M: 0.022852 merged: 0.034070\n",
      "epoch: 31 [2017-11-23 17:10:11]\n",
      "lr 0.04971830761761256\n",
      " 16M: 0.018833  8M: 0.021438  4M: 0.014525  2M: 0.014964  1M: 0.022585 merged: 0.023343\n",
      "epoch: 32 [2017-11-23 17:14:56]\n",
      "lr 0.04943501011144937\n",
      " 16M: 0.018299  8M: 0.019179  4M: 0.014672  2M: 0.015636  1M: 0.022657 merged: 0.019402\n",
      "epoch: 33 [2017-11-23 17:19:44]\n",
      "lr 0.04915007972606608\n",
      " 16M: 0.018964  8M: 0.018934  4M: 0.014052  2M: 0.014680  1M: 0.022131 merged: 0.018770\n",
      "epoch: 34 [2017-11-23 17:24:30]\n",
      "lr 0.04886348789677424\n",
      " 16M: 0.015564  8M: 0.015990  4M: 0.012950  2M: 0.015276  1M: 0.021739 merged: 0.015841\n",
      "epoch: 35 [2017-11-23 17:29:18]\n",
      "lr 0.04857520521621862\n",
      " 16M: 0.014355  8M: 0.014931  4M: 0.012063  2M: 0.013249  1M: 0.021396 merged: 0.014666\n",
      "epoch: 36 [2017-11-23 17:34:02]\n",
      "lr 0.04828520139915856\n",
      " 16M: 0.013881  8M: 0.014458  4M: 0.012122  2M: 0.013282  1M: 0.021773 merged: 0.013567\n",
      "epoch: 37 [2017-11-23 17:38:49]\n",
      "lr 0.047993445245333805\n",
      " 16M: 0.013910  8M: 0.013776  4M: 0.011785  2M: 0.012927  1M: 0.021087 merged: 0.013424\n",
      "epoch: 38 [2017-11-23 17:43:35]\n",
      "lr 0.0476999046002862\n",
      " 16M: 0.012601  8M: 0.012800  4M: 0.011083  2M: 0.012741  1M: 0.020237 merged: 0.012008\n",
      "epoch: 39 [2017-11-23 17:48:22]\n",
      "lr 0.04740454631399772\n",
      " 16M: 0.012403  8M: 0.012313  4M: 0.010798  2M: 0.012458  1M: 0.020177 merged: 0.011509\n",
      "epoch: 40 [2017-11-23 17:53:06]\n",
      "lr 0.04710733619719444\n",
      " 16M: 0.012579  8M: 0.012985  4M: 0.011277  2M: 0.012844  1M: 0.020181 merged: 0.011930\n",
      "epoch: 41 [2017-11-23 17:57:54]\n",
      "lr 0.04680823897515326\n",
      " 16M: 0.012168  8M: 0.012263  4M: 0.010703  2M: 0.012642  1M: 0.019654 merged: 0.011600\n",
      "epoch: 42 [2017-11-23 18:02:40]\n",
      "lr 0.04650721823883479\n",
      " 16M: 0.011331  8M: 0.011296  4M: 0.010785  2M: 0.012355  1M: 0.019567 merged: 0.010806\n",
      "epoch: 43 [2017-11-23 18:07:28]\n",
      "lr 0.046204236393150765\n",
      " 16M: 0.011144  8M: 0.011178  4M: 0.010477  2M: 0.011938  1M: 0.019129 merged: 0.010475\n",
      "epoch: 44 [2017-11-23 18:12:14]\n",
      "lr 0.045899254602157845\n",
      " 16M: 0.010733  8M: 0.011444  4M: 0.010141  2M: 0.011775  1M: 0.018698 merged: 0.010337\n",
      "epoch: 45 [2017-11-23 18:17:00]\n",
      "lr 0.04559223273095164\n",
      " 16M: 0.010339  8M: 0.010823  4M: 0.010085  2M: 0.011720  1M: 0.019023 merged: 0.009960\n",
      "epoch: 46 [2017-11-23 18:21:47]\n",
      "lr 0.045283129284014914\n",
      " 16M: 0.010032  8M: 0.010160  4M: 0.009612  2M: 0.011109  1M: 0.017546 merged: 0.009373\n",
      "epoch: 47 [2017-11-23 18:26:32]\n",
      "lr 0.04497190133975169\n",
      " 16M: 0.009949  8M: 0.010506  4M: 0.009255  2M: 0.011230  1M: 0.017993 merged: 0.009497\n",
      "epoch: 48 [2017-11-23 18:31:18]\n",
      "lr 0.04465850448091506\n",
      " 16M: 0.009700  8M: 0.009943  4M: 0.009163  2M: 0.011064  1M: 0.018080 merged: 0.008995\n",
      "epoch: 49 [2017-11-23 18:36:05]\n",
      "lr 0.044342892720609255\n",
      " 16M: 0.009673  8M: 0.009777  4M: 0.009617  2M: 0.011063  1M: 0.017719 merged: 0.009065\n",
      "epoch: 50 [2017-11-23 18:40:52]\n",
      "lr 0.044025018423517\n",
      " 16M: 0.009225  8M: 0.009487  4M: 0.009153  2M: 0.010903  1M: 0.017787 merged: 0.008607\n",
      "epoch: 51 [2017-11-23 18:45:39]\n",
      "lr 0.04370483222197017\n",
      " 16M: 0.009039  8M: 0.009426  4M: 0.009004  2M: 0.010862  1M: 0.017729 merged: 0.008547\n",
      "epoch: 52 [2017-11-23 18:50:26]\n",
      "lr 0.043382282926444894\n",
      " 16M: 0.009082  8M: 0.009899  4M: 0.009054  2M: 0.010722  1M: 0.017208 merged: 0.008906\n",
      "epoch: 53 [2017-11-23 18:55:15]\n",
      "lr 0.04305731743002185\n",
      " 16M: 0.009030  8M: 0.009506  4M: 0.008725  2M: 0.010574  1M: 0.017572 merged: 0.008462\n",
      "epoch: 54 [2017-11-23 19:00:02]\n",
      "lr 0.04272988060630656\n",
      " 16M: 0.008931  8M: 0.009345  4M: 0.008965  2M: 0.010361  1M: 0.016909 merged: 0.008256\n",
      "epoch: 55 [2017-11-23 19:04:46]\n",
      "lr 0.04239991520025441\n",
      " 16M: 0.008547  8M: 0.008831  4M: 0.008768  2M: 0.010429  1M: 0.016975 merged: 0.008028\n",
      "epoch: 56 [2017-11-23 19:09:33]\n",
      "lr 0.0420673617112877\n",
      " 16M: 0.008343  8M: 0.008646  4M: 0.008209  2M: 0.010143  1M: 0.016541 merged: 0.007812\n",
      "epoch: 57 [2017-11-23 19:14:41]\n",
      "lr 0.041732158268029534\n",
      " 16M: 0.008478  8M: 0.008490  4M: 0.008173  2M: 0.010049  1M: 0.016816 merged: 0.007553\n",
      "epoch: 58 [2017-11-23 19:19:49]\n",
      "lr 0.041394240493907074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.008058  8M: 0.008470  4M: 0.008058  2M: 0.009947  1M: 0.016273 merged: 0.007711\n",
      "epoch: 59 [2017-11-23 19:24:54]\n",
      "lr 0.041053541362798006\n",
      " 16M: 0.008373  8M: 0.008548  4M: 0.008487  2M: 0.009992  1M: 0.016794 merged: 0.007629\n",
      "epoch: 60 [2017-11-23 19:30:03]\n",
      "lr 0.04070999104380296\n",
      " 16M: 0.008072  8M: 0.008511  4M: 0.007858  2M: 0.009792  1M: 0.016283 merged: 0.007470\n",
      "epoch: 61 [2017-11-23 19:35:09]\n",
      "lr 0.04036351673412598\n",
      " 16M: 0.007866  8M: 0.008163  4M: 0.007915  2M: 0.009663  1M: 0.015977 merged: 0.007333\n",
      "epoch: 62 [2017-11-23 19:40:16]\n",
      "lr 0.04001404247893005\n",
      " 16M: 0.007819  8M: 0.008225  4M: 0.007804  2M: 0.009861  1M: 0.016271 merged: 0.007266\n",
      "epoch: 63 [2017-11-23 19:45:22]\n",
      "lr 0.03966148897690515\n",
      " 16M: 0.007896  8M: 0.008366  4M: 0.007824  2M: 0.009503  1M: 0.015478 merged: 0.007410\n",
      "epoch: 64 [2017-11-23 19:50:27]\n",
      "lr 0.03930577337013889\n",
      " 16M: 0.007712  8M: 0.008371  4M: 0.007770  2M: 0.009594  1M: 0.015745 merged: 0.007434\n",
      "epoch: 65 [2017-11-23 19:55:34]\n",
      "lr 0.038946809016712394\n",
      " 16M: 0.007428  8M: 0.008067  4M: 0.007659  2M: 0.009492  1M: 0.015648 merged: 0.007070\n",
      "epoch: 66 [2017-11-23 20:00:40]\n",
      "lr 0.03858450524425343\n",
      " 16M: 0.007367  8M: 0.008032  4M: 0.007657  2M: 0.009327  1M: 0.015771 merged: 0.006872\n",
      "epoch: 67 [2017-11-23 20:05:46]\n",
      "lr 0.03821876708246056\n",
      " 16M: 0.007583  8M: 0.007865  4M: 0.007479  2M: 0.009455  1M: 0.015713 merged: 0.006866\n",
      "epoch: 68 [2017-11-23 20:10:52]\n",
      "lr 0.03784949497236286\n",
      " 16M: 0.007466  8M: 0.007822  4M: 0.007341  2M: 0.009389  1M: 0.015337 merged: 0.006894\n",
      "epoch: 69 [2017-11-23 20:15:58]\n",
      "lr 0.03747658444979307\n",
      " 16M: 0.007214  8M: 0.007623  4M: 0.007273  2M: 0.009217  1M: 0.015262 merged: 0.006580\n",
      "epoch: 70 [2017-11-23 20:21:05]\n",
      "lr 0.0370999258002226\n",
      " 16M: 0.007037  8M: 0.007456  4M: 0.007144  2M: 0.009135  1M: 0.015221 merged: 0.006504\n",
      "epoch: 71 [2017-11-23 20:26:12]\n",
      "lr 0.03671940368172628\n",
      " 16M: 0.006854  8M: 0.007292  4M: 0.007170  2M: 0.009012  1M: 0.015303 merged: 0.006437\n",
      "epoch: 72 [2017-11-23 20:31:18]\n",
      "lr 0.03633489671240478\n",
      " 16M: 0.007258  8M: 0.007527  4M: 0.007229  2M: 0.009095  1M: 0.015068 merged: 0.006618\n",
      "epoch: 73 [2017-11-23 20:36:24]\n",
      "lr 0.03594627701808178\n",
      " 16M: 0.008107  8M: 0.008554  4M: 0.007305  2M: 0.009270  1M: 0.015527 merged: 0.007379\n",
      "epoch: 74 [2017-11-23 20:41:30]\n",
      "lr 0.035553409735498295\n",
      " 16M: 0.007033  8M: 0.007549  4M: 0.007137  2M: 0.008912  1M: 0.015021 merged: 0.006474\n",
      "epoch: 75 [2017-11-23 20:46:37]\n",
      "lr 0.03515615246553262\n",
      " 16M: 0.006999  8M: 0.007591  4M: 0.007315  2M: 0.009197  1M: 0.015321 merged: 0.006532\n",
      "epoch: 76 [2017-11-23 20:51:43]\n",
      "lr 0.03475435467016077\n",
      " 16M: 0.006839  8M: 0.007251  4M: 0.007050  2M: 0.008883  1M: 0.014751 merged: 0.006258\n",
      "epoch: 77 [2017-11-23 20:56:48]\n",
      "lr 0.034347857005916346\n",
      " 16M: 0.006744  8M: 0.007096  4M: 0.006830  2M: 0.008780  1M: 0.014740 merged: 0.006218\n",
      "epoch: 78 [2017-11-23 21:01:55]\n",
      "lr 0.0339364905854808\n",
      " 16M: 0.006885  8M: 0.007222  4M: 0.007020  2M: 0.009008  1M: 0.014697 merged: 0.006322\n",
      "epoch: 79 [2017-11-23 21:07:01]\n",
      "lr 0.03352007615769955\n",
      " 16M: 0.006489  8M: 0.007115  4M: 0.006807  2M: 0.008750  1M: 0.014395 merged: 0.006058\n",
      "epoch: 80 [2017-11-23 21:12:09]\n",
      "lr 0.03309842319473132\n",
      " 16M: 0.006518  8M: 0.006836  4M: 0.006683  2M: 0.008762  1M: 0.014484 merged: 0.005994\n",
      "epoch: 81 [2017-11-23 21:17:16]\n",
      "lr 0.03267132887314317\n",
      " 16M: 0.006507  8M: 0.006882  4M: 0.006600  2M: 0.008623  1M: 0.014283 merged: 0.006047\n",
      "epoch: 82 [2017-11-23 21:22:22]\n",
      "lr 0.03223857693349118\n",
      " 16M: 0.006306  8M: 0.006723  4M: 0.006653  2M: 0.008636  1M: 0.014633 merged: 0.005859\n",
      "epoch: 83 [2017-11-23 21:27:30]\n",
      "lr 0.0317999364001908\n",
      " 16M: 0.006392  8M: 0.006860  4M: 0.006721  2M: 0.008683  1M: 0.014600 merged: 0.005998\n",
      "epoch: 84 [2017-11-23 21:32:36]\n",
      "lr 0.031355160140170396\n",
      " 16M: 0.006405  8M: 0.006696  4M: 0.006655  2M: 0.008488  1M: 0.014195 merged: 0.005918\n",
      "epoch: 85 [2017-11-23 21:37:43]\n",
      "lr 0.03090398323477543\n",
      " 16M: 0.006368  8M: 0.006697  4M: 0.006681  2M: 0.008445  1M: 0.013947 merged: 0.005796\n",
      "epoch: 86 [2017-11-23 21:42:49]\n",
      "lr 0.030446121134470178\n",
      " 16M: 0.006295  8M: 0.006605  4M: 0.006404  2M: 0.008354  1M: 0.014162 merged: 0.005783\n",
      "epoch: 87 [2017-11-23 21:47:53]\n",
      "lr 0.02998126755983446\n",
      " 16M: 0.006207  8M: 0.006506  4M: 0.006345  2M: 0.008221  1M: 0.013727 merged: 0.005626\n",
      "epoch: 88 [2017-11-23 21:52:58]\n",
      "lr 0.029509092104873926\n",
      " 16M: 0.006099  8M: 0.006441  4M: 0.006334  2M: 0.008339  1M: 0.014071 merged: 0.005646\n",
      "epoch: 89 [2017-11-23 21:58:04]\n",
      "lr 0.029029237489356888\n",
      " 16M: 0.005960  8M: 0.006362  4M: 0.006332  2M: 0.008183  1M: 0.014013 merged: 0.005490\n",
      "epoch: 90 [2017-11-23 22:03:10]\n",
      "lr 0.028541316395237167\n",
      " 16M: 0.005999  8M: 0.006451  4M: 0.006389  2M: 0.008351  1M: 0.014029 merged: 0.005612\n",
      "epoch: 91 [2017-11-23 22:08:19]\n",
      "lr 0.028044907807525134\n",
      " 16M: 0.005936  8M: 0.006438  4M: 0.006431  2M: 0.008344  1M: 0.014033 merged: 0.005556\n",
      "epoch: 92 [2017-11-23 22:13:28]\n",
      "lr 0.027539552761294706\n",
      " 16M: 0.005903  8M: 0.006445  4M: 0.006401  2M: 0.008335  1M: 0.014263 merged: 0.005548\n",
      "epoch: 93 [2017-11-23 22:18:40]\n",
      "lr 0.027024749372597065\n",
      " 16M: 0.005874  8M: 0.006271  4M: 0.006121  2M: 0.007937  1M: 0.013390 merged: 0.005401\n",
      "epoch: 94 [2017-11-23 22:23:48]\n",
      "lr 0.026499947000159004\n",
      " 16M: 0.005765  8M: 0.006220  4M: 0.006133  2M: 0.008010  1M: 0.013389 merged: 0.005352\n",
      "epoch: 95 [2017-11-23 22:28:56]\n",
      "lr 0.02596453934447493\n",
      " 16M: 0.006001  8M: 0.006404  4M: 0.006227  2M: 0.008148  1M: 0.013933 merged: 0.005541\n",
      "epoch: 96 [2017-11-23 22:34:02]\n",
      "lr 0.025417856237895775\n",
      " 16M: 0.005724  8M: 0.006247  4M: 0.006229  2M: 0.008153  1M: 0.013784 merged: 0.005386\n",
      "epoch: 97 [2017-11-23 22:39:10]\n",
      "lr 0.02485915380880628\n",
      " 16M: 0.005780  8M: 0.006110  4M: 0.006004  2M: 0.007789  1M: 0.013503 merged: 0.005329\n",
      "epoch: 98 [2017-11-23 22:44:16]\n",
      "lr 0.02428760260810931\n",
      " 16M: 0.005802  8M: 0.006179  4M: 0.006196  2M: 0.008103  1M: 0.014025 merged: 0.005329\n",
      "epoch: 99 [2017-11-23 22:49:23]\n",
      "lr 0.02370227315699886\n",
      " 16M: 0.005709  8M: 0.006183  4M: 0.006323  2M: 0.008038  1M: 0.013852 merged: 0.005339\n",
      "epoch: 100 [2017-11-23 22:54:31]\n",
      "lr 0.023102118196575382\n",
      " 16M: 0.005715  8M: 0.006163  4M: 0.006140  2M: 0.007930  1M: 0.013620 merged: 0.005362\n",
      "epoch: 101 [2017-11-23 22:59:37]\n",
      "lr 0.022485950669875843\n",
      " 16M: 0.005607  8M: 0.006093  4M: 0.006034  2M: 0.007832  1M: 0.013403 merged: 0.005258\n",
      "epoch: 102 [2017-11-23 23:04:45]\n",
      "lr 0.021852416110985085\n",
      " 16M: 0.005567  8M: 0.006053  4M: 0.005931  2M: 0.007823  1M: 0.013184 merged: 0.005200\n",
      "epoch: 103 [2017-11-23 23:09:51]\n",
      "lr 0.021199957600127203\n",
      " 16M: 0.005631  8M: 0.006185  4M: 0.006130  2M: 0.007918  1M: 0.013372 merged: 0.005345\n",
      "epoch: 104 [2017-11-23 23:14:56]\n",
      "lr 0.020526770681399003\n",
      " 16M: 0.005535  8M: 0.006017  4M: 0.005927  2M: 0.007670  1M: 0.013209 merged: 0.005089\n",
      "epoch: 105 [2017-11-23 23:20:02]\n",
      "lr 0.019830744488452574\n",
      " 16M: 0.005500  8M: 0.005961  4M: 0.006035  2M: 0.007870  1M: 0.013455 merged: 0.005092\n",
      "epoch: 106 [2017-11-23 23:25:09]\n",
      "lr 0.01910938354123028\n",
      " 16M: 0.005426  8M: 0.005825  4M: 0.005942  2M: 0.007640  1M: 0.012962 merged: 0.004988\n",
      "epoch: 107 [2017-11-23 23:30:16]\n",
      "lr 0.01835970184086314\n",
      " 16M: 0.005393  8M: 0.005897  4M: 0.005958  2M: 0.007774  1M: 0.013309 merged: 0.005016\n",
      "epoch: 108 [2017-11-23 23:35:22]\n",
      "lr 0.01757807623276631\n",
      " 16M: 0.005299  8M: 0.005843  4M: 0.005938  2M: 0.007797  1M: 0.013363 merged: 0.004982\n",
      "epoch: 109 [2017-11-23 23:40:29]\n",
      "lr 0.016760038078849775\n",
      " 16M: 0.005373  8M: 0.005822  4M: 0.005889  2M: 0.007723  1M: 0.013032 merged: 0.004993\n",
      "epoch: 110 [2017-11-23 23:45:36]\n",
      "lr 0.0158999682000954\n",
      " 16M: 0.005318  8M: 0.005841  4M: 0.005854  2M: 0.007715  1M: 0.013302 merged: 0.005018\n",
      "epoch: 111 [2017-11-23 23:50:43]\n",
      "lr 0.01499063377991723\n",
      " 16M: 0.005307  8M: 0.005818  4M: 0.005876  2M: 0.007740  1M: 0.013145 merged: 0.004936\n",
      "epoch: 112 [2017-11-23 23:55:52]\n",
      "lr 0.014022453903762567\n",
      " 16M: 0.005386  8M: 0.005804  4M: 0.005816  2M: 0.007696  1M: 0.013155 merged: 0.004952\n",
      "epoch: 113 [2017-11-24 00:00:59]\n",
      "lr 0.012982269672237465\n",
      " 16M: 0.005233  8M: 0.005731  4M: 0.005816  2M: 0.007640  1M: 0.013208 merged: 0.004849\n",
      "epoch: 114 [2017-11-24 00:06:06]\n",
      "lr 0.01185113657849943\n",
      " 16M: 0.005159  8M: 0.005689  4M: 0.005753  2M: 0.007622  1M: 0.013367 merged: 0.004836\n",
      "epoch: 115 [2017-11-24 00:11:14]\n",
      "lr 0.010599978800063602\n",
      " 16M: 0.005193  8M: 0.005688  4M: 0.005773  2M: 0.007629  1M: 0.013239 merged: 0.004779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 116 [2017-11-24 00:16:21]\n",
      "lr 0.00917985092043157\n",
      " 16M: 0.005108  8M: 0.005619  4M: 0.005707  2M: 0.007514  1M: 0.012882 merged: 0.004766\n",
      "epoch: 117 [2017-11-24 00:21:18]\n",
      "lr 0.007495316889958615\n",
      " 16M: 0.005047  8M: 0.005515  4M: 0.005605  2M: 0.007311  1M: 0.012730 merged: 0.004687\n",
      "epoch: 118 [2017-11-24 00:26:12]\n",
      "lr 0.005299989400031801\n",
      " 16M: 0.005102  8M: 0.005702  4M: 0.005807  2M: 0.007743  1M: 0.013352 merged: 0.004809\n",
      "epoch: 119 [2017-11-24 00:31:07]\n",
      "lr 1e-08\n",
      " 16M: 0.005044  8M: 0.005587  4M: 0.005622  2M: 0.007457  1M: 0.012889 merged: 0.004721\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "writer = SummaryWriter(comment='-transition_scale_{}'.format(transition_scale))\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "optimizer = optim.SGD(parameters, lr=args.base_lr, momentum=args.momentum)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, beg, end, reset_lr=None):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if reset_lr != None:\n",
    "            param_group['lr'] = reset_lr\n",
    "            continue\n",
    "        if epoch != 0: \n",
    "            # linear\n",
    "#             param_group['lr'] *= (end-epoch) / (end-beg)\n",
    "#             poly base_lr (1 - iter/max_iter) ^ (power)\n",
    "            param_group['lr'] = args.base_lr * (float(end-epoch)/(end-beg)) ** (args.power)\n",
    "            if param_group['lr'] < 1.0e-8: param_group['lr'] = 1.0e-8\n",
    "        print('lr', param_group['lr'])\n",
    "        \n",
    "# def findLargerInd(target, arr):\n",
    "#     res = list(filter(lambda x: x>target, arr))\n",
    "#     print('res',res)\n",
    "#     if len(res) == 0: return -1\n",
    "#     return res[0]\n",
    "\n",
    "for epoch in range(args.epoches):\n",
    "    net.train()\n",
    "    print('epoch: {} [{}]'.format(epoch, datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "    \n",
    "    if epoch < args.training_thresholds[-1]: adjust_learning_rate(optimizer, epoch%ss, beg=0, end=ss-1)\n",
    "    else: adjust_learning_rate(optimizer, epoch, beg=args.training_thresholds[-1], end=args.epoches-1)\n",
    "    \n",
    "    run_losses = [0] * len(args.training_thresholds)\n",
    "    run_cnts   = [0.00001] * len(args.training_thresholds)\n",
    "    if (epoch in args.training_thresholds) == True: \n",
    "        adjust_learning_rate(optimizer, epoch, reset_lr=args.base_lr, beg=-1, end=-1)\n",
    "    writer.add_scalar('learning rate', optimizer.param_groups[0]['lr'], global_step=epoch)\n",
    "    for ind, data in enumerate(train_loader, 0):\n",
    "#         if  ind == 1 : break\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        im = input_img[0,:,:,:].numpy(); im = im.transpose(1,2,0); im = im[:,:,::-1]*255\n",
    "        \n",
    "        if test_scene[0] == 'alley_1':\n",
    "            print('alley_1 yes')\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda()\n",
    "            gt_albedo = gt_albedo.cuda()\n",
    "            gt_shading = gt_shading.cuda()\n",
    "#         run_losses = [0] * len(mse_losses)\n",
    "#         run_cnts = [0.00001] * len(mse_losses)\n",
    "        if args.display_curindex % args.display_interval == 0:\n",
    "            cv2.imwrite('snapshot{}/input.png'.format(args.gpu_num), im)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "#         pretrained.train(); ft_pretreained = pretrained(input_img)\n",
    "        ft_predict = net(input_img)\n",
    "        for i, threshold in enumerate(args.training_thresholds):\n",
    "#             threshold = args.training_thresholds[i]\n",
    "            if epoch >= threshold:\n",
    "#             if epoch >= 0:\n",
    "                if i == 5: s = 1\n",
    "                else: s = (2**(i+1))\n",
    "                gt = gt_albedo.cpu().data.numpy()\n",
    "                n,c,h,w = gt.shape\n",
    "                gt = gt[0,:,:,:]\n",
    "                gt = gt.transpose((1,2,0))\n",
    "                gt = cv2.resize(gt, (h//s, w//s))\n",
    "#                 gt = cv2.resize(gt, (h,w))\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    cv2.imwrite('snapshot{}/gt-{}-{}.png'.format(args.gpu_num, epoch, i), gt[:,:,::-1]*255)\n",
    "                gt = gt.transpose((2,0,1))\n",
    "                gt = gt[np.newaxis, :]\n",
    "                gt = Variable(torch.from_numpy(gt))\n",
    "                if use_gpu: gt = gt.cuda()\n",
    "                loss = mse_losses[i](ft_predict[i], gt)\n",
    "                loss_data = loss.data.cpu().numpy()\n",
    "                writer.add_scalar('{}th train iters loss'.format(i), loss_data, global_step=args.display_curindex)\n",
    "                ma_ = ft_predict[i].max().cpu().data.numpy()\n",
    "                mi_ = ft_predict[i].min().cpu().data.numpy()\n",
    "                #print('mi', mi_, 'ma', ma_)\n",
    "#                 writer.add_scalars('{}th train predict'.format(i), {'max': ma_, 'min': mi_}, global_step=args.display_curindex)\n",
    "#                 run_cnts[i] += 1\n",
    "                run_losses[i] += loss.data.cpu().numpy()[0]\n",
    "                loss.backward(retain_graph=True)\n",
    "                run_cnts[i] += 1\n",
    "#                 print('i = ', i, '; weig\\n', net.upsample01.weight[0,0,0:4,0:4].data.cpu().numpy())\n",
    "#                 print('i = ', i, '; grad\\n', net.upsample01.weight.grad[0,0,0:4,0:4].data.cpu().numpy())\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    im = ft_predict[i].cpu().data.numpy()[0].transpose((1,2,0)) * 255\n",
    "                    cv2.imwrite('snapshot{}/train-{}-{}.png'.format(args.gpu_num, epoch, i), im[:,:,::-1])\n",
    "        optimizer.step()\n",
    "        args.display_curindex += 1\n",
    "\n",
    "    \"\"\" every epoch \"\"\"\n",
    "#     loss_output = 'ind: ' + str(args.display_curindex)\n",
    "    loss_output = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i,v in enumerate(run_losses):\n",
    "        if i == len(run_losses)-1: \n",
    "            loss_output += ' merged: %6f' % (run_losses[i] / run_cnts[i])\n",
    "            continue\n",
    "        loss_output += ' %2dM: %6f' % ((2**(4-i)), (run_losses[i] / run_cnts[i]))\n",
    "    print(loss_output)\n",
    "    # save at every epoch\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'args' : args,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, 'snapshot{}/snapshot-{}.pth.tar'.format(args.gpu_num, epoch))\n",
    "    \n",
    "    # test \n",
    "    test_losses_trainphase = [0] * len(args.training_thresholds)\n",
    "    test_cnts_trainphase   = [0.00001] * len(args.training_thresholds)   \n",
    "    for ind, data in enumerate(test_loader, 0):\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "        \n",
    "#         pretrained.train(); ft_pretreained = pretrained(input_img)\n",
    "        ft_test = net(input_img)\n",
    "            \n",
    "        for i,v in enumerate(ft_test):\n",
    "            if epoch < args.training_thresholds[i]: continue\n",
    "            if i == 5: s = 1\n",
    "            else: s = (2**(i+1))\n",
    "            gt = gt_albedo.data.numpy()\n",
    "            n,c,h,w = gt.shape\n",
    "            gt = gt[0,:,:,:]\n",
    "            gt = gt.transpose((1,2,0))\n",
    "            gt = cv2.resize(gt, (h//s, w//s))\n",
    "#             gt = cv2.resize(gt, (h,w))\n",
    "            \n",
    "            gt = gt.transpose((2,0,1))\n",
    "            gt = gt[np.newaxis, :]\n",
    "            gt = Variable(torch.from_numpy(gt))\n",
    "            if use_gpu: gt = gt.cuda()\n",
    "\n",
    "            loss = mse_losses[i](ft_test[i], gt)\n",
    "            \n",
    "            test_losses_trainphase[i] += loss.data.cpu().numpy()[0]\n",
    "            test_cnts_trainphase[i] += 1\n",
    "            v = v[0].cpu().data.numpy()\n",
    "            v = v.transpose(1,2,0)\n",
    "            if ind == 0: cv2.imwrite('snapshot{}/test-phase_train-{}-{}.png'.format(args.gpu_num, epoch, i), v[:,:,::-1]*255)\n",
    "\n",
    "    \n",
    "    net.eval()\n",
    "    test_losses = [0] * len(args.training_thresholds)\n",
    "    test_cnts   = [0.00001] * len(args.training_thresholds)   \n",
    "    for ind, data in enumerate(test_loader, 0):\n",
    "#         if ind == 1: break\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "            \n",
    "#         pretrained.eval(); ft_pretreained = pretrained(input_img)\n",
    "        ft_test = net(input_img)\n",
    "            \n",
    "        for i,v in enumerate(ft_test):\n",
    "            if epoch < args.training_thresholds[i]: continue\n",
    "            if i == 5: s = 1\n",
    "            else: s = (2**(i+1))\n",
    "            gt = gt_albedo.data.numpy()\n",
    "            n,c,h,w = gt.shape\n",
    "            gt = gt[0,:,:,:]\n",
    "            gt = gt.transpose((1,2,0))\n",
    "            gt = cv2.resize(gt, (h//s, w//s))\n",
    "#             gt = cv2.resize(gt, (h,w))\n",
    "            \n",
    "            gt = gt.transpose((2,0,1))\n",
    "            gt = gt[np.newaxis, :]\n",
    "            gt = Variable(torch.from_numpy(gt))\n",
    "            if use_gpu: gt = gt.cuda()\n",
    "\n",
    "            loss = mse_losses[i](ft_test[i], gt)\n",
    "            \n",
    "            test_losses[i] += loss.data.cpu().numpy()[0]\n",
    "            test_cnts[i] += 1\n",
    "            v = v[0].cpu().data.numpy()\n",
    "            v = v.transpose(1,2,0)\n",
    "            if ind == 0: cv2.imwrite('snapshot{}/test-phase_test-{}-{}.png'.format(args.gpu_num, epoch, i), v[:,:,::-1]*255)\n",
    "    \n",
    "    writer.add_scalars('16M loss', {\n",
    "        'train 16M ': np.array([run_losses[0]/ run_cnts[0]]),\n",
    "        'test_trainphase 16M ': np.array([test_losses_trainphase[0]/ test_cnts_trainphase[0]]),\n",
    "        'test 16M ': np.array([test_losses[0]/ test_cnts[0]])\n",
    "    }, global_step=epoch)  \n",
    "    writer.add_scalars('8M loss', {\n",
    "        'train 8M ': np.array([run_losses[1]/ run_cnts[1]]),\n",
    "        'test_trainphase 8M ': np.array([test_losses_trainphase[1]/ test_cnts_trainphase[1]]),\n",
    "        'test 8M ': np.array([test_losses[1]/ test_cnts[1]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('4M loss', {\n",
    "        'train 4M ': np.array([run_losses[2]/ run_cnts[2]]),\n",
    "        'test_trainphase 4M ': np.array([test_losses_trainphase[2]/ test_cnts_trainphase[2]]),\n",
    "        'test 4M ': np.array([test_losses[2]/ test_cnts[2]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('2M loss', {\n",
    "        'train 2M ': np.array([run_losses[3]/ run_cnts[3]]),\n",
    "        'test_trainphase 2M ': np.array([test_losses_trainphase[3]/ test_cnts_trainphase[3]]),\n",
    "        'test 2M ': np.array([test_losses[3]/ test_cnts[3]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('1M loss', {\n",
    "        'train 1M ': np.array([run_losses[4]/ run_cnts[4]]),\n",
    "        'test_trainphase 1M ': np.array([test_losses_trainphase[4]/ test_cnts_trainphase[4]]),\n",
    "        'test 1M ': np.array([test_losses[4]/ test_cnts[4]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('merged loss', {\n",
    "        'train merged ': np.array([run_losses[5]/ run_cnts[5]]),\n",
    "        'test_trainphase merged ': np.array([test_losses_trainphase[5]/ test_cnts_trainphase[5]]),\n",
    "        'test merged ': np.array([test_losses[5]/ test_cnts[5]])\n",
    "    }, global_step=epoch) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"10240,10240\"), format='svg')\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.zeros(1,3,256,256))\n",
    "y = net(x.cuda())\n",
    "g = make_dot(y[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tsvg', '-O', 'net-transition_scale_4'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(engine, format, filepath, quiet)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTARTUPINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \"\"\"\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1343\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot': 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-81727d6bc75d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'net-transition_scale_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, filename, directory, view, cleanup)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mrendered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(engine, format, filepath, quiet)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tsvg', '-O', 'net-transition_scale_4'], make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "g.render('net-transition_scale_{}'.format(transition_scale)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
