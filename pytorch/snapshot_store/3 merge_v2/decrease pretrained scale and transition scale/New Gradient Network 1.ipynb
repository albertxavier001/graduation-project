{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, platform, datetime, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import functional as F\n",
    "# import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc\n",
    "\n",
    "from myimagefolder import MyImageFolder\n",
    "from mymodel import GradientNet\n",
    "from myargs import Args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('debian', 'jessie/sid', '')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "args = Args()\n",
    "args.test_scene = 'alley_1'\n",
    "args.arch = \"densenet121\"\n",
    "args.epoches = 500\n",
    "args.epoches_unary_threshold = 0\n",
    "args.image_h = 256\n",
    "args.image_w = 256\n",
    "args.img_extentions = [\"png\"]\n",
    "args.training_thresholds = [250,200,150,50,0,300]\n",
    "args.base_lr = 1\n",
    "args.lr = args.base_lr\n",
    "args.snapshot_interval = 5000\n",
    "args.debug = True\n",
    "args.gpu_num = 1\n",
    "# growth_rate = (4*(2**(args.gpu_num)))\n",
    "transition_scale=(2*(2**(args.gpu_num+1)))\n",
    "growth_rate = 32\n",
    "args.display_interval = 50\n",
    "args.display_curindex = 0\n",
    "\n",
    "system_ = platform.system()\n",
    "system_dist, system_version, _ = platform.dist()\n",
    "if system_ == \"Darwin\": \n",
    "    args.train_dir = '/Volumes/Transcend/dataset/sintel2'\n",
    "    args.pretrained = False\n",
    "elif platform.dist() ==  ('debian', 'jessie/sid', ''):\n",
    "    args.train_dir = '/home/lwp/workspace/sintel2'\n",
    "    args.pretrained = True\n",
    "elif platform.dist() == ('debian', 'stretch/sid', ''):\n",
    "    args.train_dir = '/home/cad/lwp/workspace/dataset/sintel2'\n",
    "    args.pretrained = True\n",
    "\n",
    "if platform.system() == 'Linux': use_gpu = True\n",
    "else: use_gpu = False\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.gpu_num)\n",
    "    \n",
    "\n",
    "print(platform.dist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# My DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = MyImageFolder(args.train_dir, 'train',\n",
    "                       transforms.Compose(\n",
    "        [transforms.ToTensor()]\n",
    "    ), random_crop=True, \n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "test_dataset = MyImageFolder(args.train_dir, 'test', \n",
    "                       transforms.Compose(\n",
    "        [transforms.CenterCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ), random_crop=False,\n",
    "    img_extentions=args.img_extentions, test_scene=args.test_scene, image_h=args.image_h, image_w=args.image_w)\n",
    "\n",
    "train_loader = data_utils.DataLoader(train_dataset,1,True,num_workers=1)\n",
    "test_loader = data_utils.DataLoader(test_dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Load Pretrained Model\n",
    "\n",
    "[Defination](https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py)\n",
    "* DenseNet-121: num_init_features=64, growth_rate=32, block_config=(6, 12, 24, 16)\n",
    "    * First Convolution: 32M -> 16M -> 8M\n",
    "    * every transition: 8M -> 4M -> 2M (downsample 1/2, except the last block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "densenet = models.__dict__[args.arch](pretrained=args.pretrained)\n",
    "\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "if use_gpu: densenet.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 6\n",
    "\n",
    "args.display_curindex = 0\n",
    "args.base_lr = 0.05\n",
    "args.display_interval = 20\n",
    "args.momentum = 0.9\n",
    "args.epoches = 120\n",
    "args.training_thresholds = [ss*4,ss*3,ss*2,ss*1,ss*0,ss*5]\n",
    "args.power = 0.5\n",
    "\n",
    "\n",
    "\n",
    "# pretrained = PreTrainedModel(densenet)\n",
    "# if use_gpu: \n",
    "#     pretrained.cuda()\n",
    "\n",
    "\n",
    "net = GradientNet(densenet=densenet, growth_rate=growth_rate, transition_scale=transition_scale)\n",
    "if use_gpu:\n",
    "    net.cuda()\n",
    "\n",
    "if use_gpu: \n",
    "    mse_losses = [nn.MSELoss().cuda()] * 6\n",
    "    test_losses = [nn.MSELoss().cuda()] * 6\n",
    "else:\n",
    "    mse_losses = [nn.MSELoss()] * 6\n",
    "    test_losses = [nn.MSELoss()] * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 [2017-11-23 15:43:45]\n",
      "lr 0.05\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.056058 merged: 0.000000\n",
      "epoch: 1 [2017-11-23 15:45:47]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.051880 merged: 0.000000\n",
      "epoch: 2 [2017-11-23 15:47:50]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.046272 merged: 0.000000\n",
      "epoch: 3 [2017-11-23 15:49:52]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.046587 merged: 0.000000\n",
      "epoch: 4 [2017-11-23 15:51:54]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.042295 merged: 0.000000\n",
      "epoch: 5 [2017-11-23 15:53:56]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.000000  1M: 0.042449 merged: 0.000000\n",
      "epoch: 6 [2017-11-23 15:55:58]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.053034  1M: 0.045342 merged: 0.000000\n",
      "epoch: 7 [2017-11-23 15:58:20]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.044935  1M: 0.040145 merged: 0.000000\n",
      "epoch: 8 [2017-11-23 16:00:48]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.040160  1M: 0.035718 merged: 0.000000\n",
      "epoch: 9 [2017-11-23 16:03:19]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.032963  1M: 0.032910 merged: 0.000000\n",
      "epoch: 10 [2017-11-23 16:05:46]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.024377  1M: 0.027546 merged: 0.000000\n",
      "epoch: 11 [2017-11-23 16:08:14]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.000000  2M: 0.022725  1M: 0.026383 merged: 0.000000\n",
      "epoch: 12 [2017-11-23 16:10:39]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.048872  2M: 0.030331  1M: 0.033938 merged: 0.000000\n",
      "epoch: 13 [2017-11-23 16:13:23]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.038449  2M: 0.025062  1M: 0.031121 merged: 0.000000\n",
      "epoch: 14 [2017-11-23 16:16:04]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.032484  2M: 0.022485  1M: 0.028771 merged: 0.000000\n",
      "epoch: 15 [2017-11-23 16:18:43]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.024987  2M: 0.019907  1M: 0.026140 merged: 0.000000\n",
      "epoch: 16 [2017-11-23 16:21:25]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.019580  2M: 0.018084  1M: 0.024596 merged: 0.000000\n",
      "epoch: 17 [2017-11-23 16:24:08]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.000000  4M: 0.017865  2M: 0.017634  1M: 0.024014 merged: 0.000000\n",
      "epoch: 18 [2017-11-23 16:26:53]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.046292  4M: 0.021528  2M: 0.019886  1M: 0.027491 merged: 0.000000\n",
      "epoch: 19 [2017-11-23 16:29:53]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.000000  8M: 0.034180  4M: 0.019712  2M: 0.018680  1M: 0.025950 merged: 0.000000\n",
      "epoch: 20 [2017-11-23 16:32:47]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.000000  8M: 0.027425  4M: 0.017702  2M: 0.017545  1M: 0.024946 merged: 0.000000\n",
      "epoch: 21 [2017-11-23 16:35:40]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.000000  8M: 0.021148  4M: 0.014970  2M: 0.016295  1M: 0.023539 merged: 0.000000\n",
      "epoch: 22 [2017-11-23 16:38:34]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.000000  8M: 0.017393  4M: 0.013624  2M: 0.015425  1M: 0.021782 merged: 0.000000\n",
      "epoch: 23 [2017-11-23 16:41:30]\n",
      "lr 1e-08\n",
      " 16M: 0.000000  8M: 0.016563  4M: 0.013344  2M: 0.015648  1M: 0.022171 merged: 0.000000\n",
      "epoch: 24 [2017-11-23 16:44:22]\n",
      "lr 1e-08\n",
      " 16M: 0.045881  8M: 0.021760  4M: 0.015769  2M: 0.017259  1M: 0.024196 merged: 0.000000\n",
      "epoch: 25 [2017-11-23 16:47:27]\n",
      "lr 0.044721359549995794\n",
      " 16M: 0.034483  8M: 0.018814  4M: 0.015001  2M: 0.018045  1M: 0.023449 merged: 0.000000\n",
      "epoch: 26 [2017-11-23 16:50:31]\n",
      "lr 0.038729833462074176\n",
      " 16M: 0.026231  8M: 0.015341  4M: 0.013157  2M: 0.015237  1M: 0.022502 merged: 0.000000\n",
      "epoch: 27 [2017-11-23 16:53:34]\n",
      "lr 0.0316227766016838\n",
      " 16M: 0.021491  8M: 0.014331  4M: 0.012021  2M: 0.014612  1M: 0.021633 merged: 0.000000\n",
      "epoch: 28 [2017-11-23 16:56:37]\n",
      "lr 0.022360679774997897\n",
      " 16M: 0.018616  8M: 0.012797  4M: 0.011214  2M: 0.014085  1M: 0.020879 merged: 0.000000\n",
      "epoch: 29 [2017-11-23 16:59:42]\n",
      "lr 1e-08\n",
      " 16M: 0.017217  8M: 0.012291  4M: 0.011436  2M: 0.013808  1M: 0.021218 merged: 0.000000\n",
      "epoch: 30 [2017-11-23 17:02:48]\n",
      "lr 0.05\n",
      " 16M: 0.022097  8M: 0.018941  4M: 0.014382  2M: 0.015738  1M: 0.023189 merged: 0.032934\n",
      "epoch: 31 [2017-11-23 17:07:23]\n",
      "lr 0.04971830761761256\n",
      " 16M: 0.022289  8M: 0.020632  4M: 0.018121  2M: 0.016201  1M: 0.022858 merged: 0.024452\n",
      "epoch: 32 [2017-11-23 17:11:59]\n",
      "lr 0.04943501011144937\n",
      " 16M: 0.019645  8M: 0.017884  4M: 0.014344  2M: 0.015799  1M: 0.022267 merged: 0.019653\n",
      "epoch: 33 [2017-11-23 17:16:33]\n",
      "lr 0.04915007972606608\n",
      " 16M: 0.018215  8M: 0.017073  4M: 0.013958  2M: 0.015396  1M: 0.021301 merged: 0.018116\n",
      "epoch: 34 [2017-11-23 17:21:05]\n",
      "lr 0.04886348789677424\n",
      " 16M: 0.017232  8M: 0.015670  4M: 0.013122  2M: 0.014528  1M: 0.020686 merged: 0.016650\n",
      "epoch: 35 [2017-11-23 17:25:40]\n",
      "lr 0.04857520521621862\n",
      " 16M: 0.015870  8M: 0.014668  4M: 0.012268  2M: 0.014308  1M: 0.020752 merged: 0.014634\n",
      "epoch: 36 [2017-11-23 17:30:13]\n",
      "lr 0.04828520139915856\n",
      " 16M: 0.015364  8M: 0.013588  4M: 0.011864  2M: 0.013911  1M: 0.020976 merged: 0.014143\n",
      "epoch: 37 [2017-11-23 17:34:47]\n",
      "lr 0.047993445245333805\n",
      " 16M: 0.014991  8M: 0.013339  4M: 0.011456  2M: 0.013406  1M: 0.020021 merged: 0.013529\n",
      "epoch: 38 [2017-11-23 17:39:22]\n",
      "lr 0.0476999046002862\n",
      " 16M: 0.013803  8M: 0.012546  4M: 0.010923  2M: 0.013094  1M: 0.020204 merged: 0.012384\n",
      "epoch: 39 [2017-11-23 17:43:55]\n",
      "lr 0.04740454631399772\n",
      " 16M: 0.013543  8M: 0.012350  4M: 0.010598  2M: 0.012525  1M: 0.019222 merged: 0.012050\n",
      "epoch: 40 [2017-11-23 17:48:30]\n",
      "lr 0.04710733619719444\n",
      " 16M: 0.012430  8M: 0.011563  4M: 0.010619  2M: 0.012437  1M: 0.019094 merged: 0.011689\n",
      "epoch: 41 [2017-11-23 17:53:03]\n",
      "lr 0.04680823897515326\n",
      " 16M: 0.012874  8M: 0.011752  4M: 0.010253  2M: 0.012691  1M: 0.019309 merged: 0.011487\n",
      "epoch: 42 [2017-11-23 17:57:38]\n",
      "lr 0.04650721823883479\n",
      " 16M: 0.012451  8M: 0.011617  4M: 0.010098  2M: 0.012232  1M: 0.018393 merged: 0.011269\n",
      "epoch: 43 [2017-11-23 18:02:13]\n",
      "lr 0.046204236393150765\n",
      " 16M: 0.011622  8M: 0.010918  4M: 0.009663  2M: 0.011823  1M: 0.018678 merged: 0.010595\n",
      "epoch: 44 [2017-11-23 18:06:47]\n",
      "lr 0.045899254602157845\n",
      " 16M: 0.010951  8M: 0.010943  4M: 0.009333  2M: 0.011714  1M: 0.018126 merged: 0.010387\n",
      "epoch: 45 [2017-11-23 18:11:20]\n",
      "lr 0.04559223273095164\n",
      " 16M: 0.010823  8M: 0.010502  4M: 0.009166  2M: 0.011789  1M: 0.018141 merged: 0.009930\n",
      "epoch: 46 [2017-11-23 18:15:54]\n",
      "lr 0.045283129284014914\n",
      " 16M: 0.011014  8M: 0.010371  4M: 0.009545  2M: 0.011898  1M: 0.018270 merged: 0.009982\n",
      "epoch: 47 [2017-11-23 18:20:27]\n",
      "lr 0.04497190133975169\n",
      " 16M: 0.010043  8M: 0.009864  4M: 0.008781  2M: 0.011564  1M: 0.017495 merged: 0.009286\n",
      "epoch: 48 [2017-11-23 18:25:02]\n",
      "lr 0.04465850448091506\n",
      " 16M: 0.010538  8M: 0.009809  4M: 0.008735  2M: 0.011423  1M: 0.017854 merged: 0.009408\n",
      "epoch: 49 [2017-11-23 18:29:36]\n",
      "lr 0.044342892720609255\n",
      " 16M: 0.010068  8M: 0.009730  4M: 0.008560  2M: 0.011121  1M: 0.017976 merged: 0.009110\n",
      "epoch: 50 [2017-11-23 18:34:11]\n",
      "lr 0.044025018423517\n",
      " 16M: 0.010119  8M: 0.009812  4M: 0.008488  2M: 0.010892  1M: 0.016973 merged: 0.009070\n",
      "epoch: 51 [2017-11-23 18:38:47]\n",
      "lr 0.04370483222197017\n",
      " 16M: 0.009827  8M: 0.009495  4M: 0.008716  2M: 0.010951  1M: 0.017957 merged: 0.009002\n",
      "epoch: 52 [2017-11-23 18:43:21]\n",
      "lr 0.043382282926444894\n",
      " 16M: 0.009668  8M: 0.009283  4M: 0.008417  2M: 0.011161  1M: 0.017944 merged: 0.008610\n",
      "epoch: 53 [2017-11-23 18:47:56]\n",
      "lr 0.04305731743002185\n",
      " 16M: 0.009544  8M: 0.009255  4M: 0.008324  2M: 0.010754  1M: 0.017366 merged: 0.008403\n",
      "epoch: 54 [2017-11-23 18:52:32]\n",
      "lr 0.04272988060630656\n",
      " 16M: 0.009358  8M: 0.009132  4M: 0.008380  2M: 0.010600  1M: 0.016970 merged: 0.008224\n",
      "epoch: 55 [2017-11-23 18:57:08]\n",
      "lr 0.04239991520025441\n",
      " 16M: 0.009780  8M: 0.011067  4M: 0.008294  2M: 0.010311  1M: 0.016412 merged: 0.008909\n",
      "epoch: 56 [2017-11-23 19:01:44]\n",
      "lr 0.0420673617112877\n",
      " 16M: 0.008849  8M: 0.009170  4M: 0.008148  2M: 0.010545  1M: 0.016315 merged: 0.008069\n",
      "epoch: 57 [2017-11-23 19:06:19]\n",
      "lr 0.041732158268029534\n",
      " 16M: 0.008856  8M: 0.009199  4M: 0.007760  2M: 0.009906  1M: 0.016076 merged: 0.008094\n",
      "epoch: 58 [2017-11-23 19:11:00]\n",
      "lr 0.041394240493907074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16M: 0.008529  8M: 0.008850  4M: 0.007889  2M: 0.010139  1M: 0.016184 merged: 0.007746\n",
      "epoch: 59 [2017-11-23 19:15:57]\n",
      "lr 0.041053541362798006\n",
      " 16M: 0.008719  8M: 0.008468  4M: 0.007833  2M: 0.010246  1M: 0.016454 merged: 0.007697\n",
      "epoch: 60 [2017-11-23 19:20:53]\n",
      "lr 0.04070999104380296\n",
      " 16M: 0.008880  8M: 0.008808  4M: 0.007895  2M: 0.010165  1M: 0.016242 merged: 0.007795\n",
      "epoch: 61 [2017-11-23 19:25:48]\n",
      "lr 0.04036351673412598\n",
      " 16M: 0.008262  8M: 0.008258  4M: 0.007371  2M: 0.009833  1M: 0.016173 merged: 0.007369\n",
      "epoch: 62 [2017-11-23 19:30:43]\n",
      "lr 0.04001404247893005\n",
      " 16M: 0.008681  8M: 0.008419  4M: 0.007615  2M: 0.010120  1M: 0.016428 merged: 0.007602\n",
      "epoch: 63 [2017-11-23 19:35:39]\n",
      "lr 0.03966148897690515\n",
      " 16M: 0.008221  8M: 0.008158  4M: 0.007489  2M: 0.009934  1M: 0.015799 merged: 0.007220\n",
      "epoch: 64 [2017-11-23 19:40:35]\n",
      "lr 0.03930577337013889\n",
      " 16M: 0.008182  8M: 0.008792  4M: 0.007424  2M: 0.009824  1M: 0.015303 merged: 0.007441\n",
      "epoch: 65 [2017-11-23 19:45:32]\n",
      "lr 0.038946809016712394\n",
      " 16M: 0.008063  8M: 0.008258  4M: 0.007287  2M: 0.009602  1M: 0.015479 merged: 0.007170\n",
      "epoch: 66 [2017-11-23 19:50:28]\n",
      "lr 0.03858450524425343\n",
      " 16M: 0.008022  8M: 0.007912  4M: 0.007119  2M: 0.009510  1M: 0.015310 merged: 0.006878\n",
      "epoch: 67 [2017-11-23 19:55:24]\n",
      "lr 0.03821876708246056\n",
      " 16M: 0.007770  8M: 0.007996  4M: 0.007095  2M: 0.009557  1M: 0.015357 merged: 0.007024\n",
      "epoch: 68 [2017-11-23 20:00:19]\n",
      "lr 0.03784949497236286\n",
      " 16M: 0.007826  8M: 0.007876  4M: 0.007076  2M: 0.009326  1M: 0.014975 merged: 0.006975\n",
      "epoch: 69 [2017-11-23 20:05:16]\n",
      "lr 0.03747658444979307\n",
      " 16M: 0.007566  8M: 0.007526  4M: 0.007020  2M: 0.009401  1M: 0.015297 merged: 0.006595\n",
      "epoch: 70 [2017-11-23 20:10:12]\n",
      "lr 0.0370999258002226\n",
      " 16M: 0.007621  8M: 0.007536  4M: 0.007027  2M: 0.009430  1M: 0.015218 merged: 0.006706\n",
      "epoch: 71 [2017-11-23 20:15:08]\n",
      "lr 0.03671940368172628\n",
      " 16M: 0.007776  8M: 0.007595  4M: 0.006903  2M: 0.009268  1M: 0.015030 merged: 0.006729\n",
      "epoch: 72 [2017-11-23 20:20:03]\n",
      "lr 0.03633489671240478\n",
      " 16M: 0.007749  8M: 0.007426  4M: 0.006859  2M: 0.009370  1M: 0.015102 merged: 0.006604\n",
      "epoch: 73 [2017-11-23 20:24:59]\n",
      "lr 0.03594627701808178\n",
      " 16M: 0.007699  8M: 0.007535  4M: 0.006974  2M: 0.009440  1M: 0.015315 merged: 0.006599\n",
      "epoch: 74 [2017-11-23 20:29:54]\n",
      "lr 0.035553409735498295\n",
      " 16M: 0.007477  8M: 0.007529  4M: 0.006864  2M: 0.009251  1M: 0.014894 merged: 0.006628\n",
      "epoch: 75 [2017-11-23 20:34:48]\n",
      "lr 0.03515615246553262\n",
      " 16M: 0.007347  8M: 0.007411  4M: 0.006834  2M: 0.009583  1M: 0.015112 merged: 0.006569\n",
      "epoch: 76 [2017-11-23 20:39:44]\n",
      "lr 0.03475435467016077\n",
      " 16M: 0.007415  8M: 0.007307  4M: 0.006775  2M: 0.009308  1M: 0.015063 merged: 0.006323\n",
      "epoch: 77 [2017-11-23 20:44:38]\n",
      "lr 0.034347857005916346\n",
      " 16M: 0.007269  8M: 0.007333  4M: 0.006848  2M: 0.009251  1M: 0.015026 merged: 0.006603\n",
      "epoch: 78 [2017-11-23 20:49:34]\n",
      "lr 0.0339364905854808\n",
      " 16M: 0.007258  8M: 0.007220  4M: 0.006666  2M: 0.008956  1M: 0.014404 merged: 0.006366\n",
      "epoch: 79 [2017-11-23 20:54:30]\n",
      "lr 0.03352007615769955\n",
      " 16M: 0.007157  8M: 0.007034  4M: 0.006645  2M: 0.009114  1M: 0.015016 merged: 0.006249\n",
      "epoch: 80 [2017-11-23 20:59:25]\n",
      "lr 0.03309842319473132\n",
      " 16M: 0.006996  8M: 0.006987  4M: 0.006657  2M: 0.008944  1M: 0.014693 merged: 0.006211\n",
      "epoch: 81 [2017-11-23 21:04:21]\n",
      "lr 0.03267132887314317\n",
      " 16M: 0.006944  8M: 0.006910  4M: 0.006512  2M: 0.009066  1M: 0.014588 merged: 0.006041\n",
      "epoch: 82 [2017-11-23 21:09:17]\n",
      "lr 0.03223857693349118\n",
      " 16M: 0.007132  8M: 0.007678  4M: 0.006554  2M: 0.008824  1M: 0.014452 merged: 0.006443\n",
      "epoch: 83 [2017-11-23 21:14:12]\n",
      "lr 0.0317999364001908\n",
      " 16M: 0.007021  8M: 0.006917  4M: 0.006357  2M: 0.008724  1M: 0.014207 merged: 0.006078\n",
      "epoch: 84 [2017-11-23 21:19:08]\n",
      "lr 0.031355160140170396\n",
      " 16M: 0.007615  8M: 0.009117  4M: 0.006732  2M: 0.008819  1M: 0.014348 merged: 0.007271\n",
      "epoch: 85 [2017-11-23 21:24:06]\n",
      "lr 0.03090398323477543\n",
      " 16M: 0.006850  8M: 0.008041  4M: 0.006478  2M: 0.008665  1M: 0.014156 merged: 0.006324\n",
      "epoch: 86 [2017-11-23 21:29:02]\n",
      "lr 0.030446121134470178\n",
      " 16M: 0.006553  8M: 0.007107  4M: 0.006280  2M: 0.008504  1M: 0.013893 merged: 0.005896\n",
      "epoch: 87 [2017-11-23 21:33:58]\n",
      "lr 0.02998126755983446\n",
      " 16M: 0.006618  8M: 0.007023  4M: 0.006275  2M: 0.008690  1M: 0.014162 merged: 0.005854\n",
      "epoch: 88 [2017-11-23 21:38:54]\n",
      "lr 0.029509092104873926\n",
      " 16M: 0.006465  8M: 0.006821  4M: 0.006190  2M: 0.008495  1M: 0.013992 merged: 0.005843\n",
      "epoch: 89 [2017-11-23 21:43:50]\n",
      "lr 0.029029237489356888\n",
      " 16M: 0.006480  8M: 0.006698  4M: 0.006218  2M: 0.008656  1M: 0.014200 merged: 0.005727\n",
      "epoch: 90 [2017-11-23 21:48:46]\n",
      "lr 0.028541316395237167\n",
      " 16M: 0.006511  8M: 0.006705  4M: 0.006334  2M: 0.008621  1M: 0.013974 merged: 0.005821\n",
      "epoch: 91 [2017-11-23 21:53:42]\n",
      "lr 0.028044907807525134\n",
      " 16M: 0.006338  8M: 0.006506  4M: 0.006075  2M: 0.008419  1M: 0.014020 merged: 0.005649\n",
      "epoch: 92 [2017-11-23 21:58:38]\n",
      "lr 0.027539552761294706\n",
      " 16M: 0.006290  8M: 0.006515  4M: 0.006009  2M: 0.008214  1M: 0.013530 merged: 0.005602\n",
      "epoch: 93 [2017-11-23 22:03:34]\n",
      "lr 0.027024749372597065\n",
      " 16M: 0.006430  8M: 0.006689  4M: 0.006257  2M: 0.008718  1M: 0.014264 merged: 0.005734\n",
      "epoch: 94 [2017-11-23 22:08:32]\n",
      "lr 0.026499947000159004\n",
      " 16M: 0.007290  8M: 0.006412  4M: 0.006084  2M: 0.008425  1M: 0.013873 merged: 0.005649\n",
      "epoch: 95 [2017-11-23 22:13:28]\n",
      "lr 0.02596453934447493\n",
      " 16M: 0.006615  8M: 0.006373  4M: 0.005954  2M: 0.008327  1M: 0.013809 merged: 0.005577\n",
      "epoch: 96 [2017-11-23 22:18:29]\n",
      "lr 0.025417856237895775\n",
      " 16M: 0.006593  8M: 0.006396  4M: 0.006064  2M: 0.008390  1M: 0.013943 merged: 0.005517\n",
      "epoch: 97 [2017-11-23 22:23:28]\n",
      "lr 0.02485915380880628\n",
      " 16M: 0.006191  8M: 0.006201  4M: 0.005834  2M: 0.008179  1M: 0.013636 merged: 0.005394\n",
      "epoch: 98 [2017-11-23 22:28:23]\n",
      "lr 0.02428760260810931\n",
      " 16M: 0.006156  8M: 0.006197  4M: 0.005894  2M: 0.008188  1M: 0.013539 merged: 0.005435\n",
      "epoch: 99 [2017-11-23 22:33:18]\n",
      "lr 0.02370227315699886\n",
      " 16M: 0.006187  8M: 0.006256  4M: 0.005862  2M: 0.008141  1M: 0.013511 merged: 0.005425\n",
      "epoch: 100 [2017-11-23 22:38:16]\n",
      "lr 0.023102118196575382\n",
      " 16M: 0.006319  8M: 0.006354  4M: 0.005982  2M: 0.008369  1M: 0.013979 merged: 0.005475\n",
      "epoch: 101 [2017-11-23 22:43:12]\n",
      "lr 0.022485950669875843\n",
      " 16M: 0.006019  8M: 0.006228  4M: 0.006043  2M: 0.008405  1M: 0.013908 merged: 0.005424\n",
      "epoch: 102 [2017-11-23 22:48:09]\n",
      "lr 0.021852416110985085\n",
      " 16M: 0.006035  8M: 0.006153  4M: 0.005832  2M: 0.008057  1M: 0.013431 merged: 0.005345\n",
      "epoch: 103 [2017-11-23 22:53:05]\n",
      "lr 0.021199957600127203\n",
      " 16M: 0.005944  8M: 0.006157  4M: 0.005877  2M: 0.008068  1M: 0.013269 merged: 0.005300\n",
      "epoch: 104 [2017-11-23 22:58:02]\n",
      "lr 0.020526770681399003\n",
      " 16M: 0.005930  8M: 0.006145  4M: 0.005850  2M: 0.008271  1M: 0.013689 merged: 0.005274\n",
      "epoch: 105 [2017-11-23 23:02:59]\n",
      "lr 0.019830744488452574\n",
      " 16M: 0.005954  8M: 0.006074  4M: 0.005836  2M: 0.008162  1M: 0.013469 merged: 0.005273\n",
      "epoch: 106 [2017-11-23 23:07:56]\n",
      "lr 0.01910938354123028\n",
      " 16M: 0.005944  8M: 0.006123  4M: 0.005794  2M: 0.007980  1M: 0.013311 merged: 0.005316\n",
      "epoch: 107 [2017-11-23 23:12:53]\n",
      "lr 0.01835970184086314\n",
      " 16M: 0.005751  8M: 0.005941  4M: 0.005659  2M: 0.007866  1M: 0.013044 merged: 0.005059\n",
      "epoch: 108 [2017-11-23 23:17:48]\n",
      "lr 0.01757807623276631\n",
      " 16M: 0.005843  8M: 0.006016  4M: 0.005743  2M: 0.007966  1M: 0.012806 merged: 0.005192\n",
      "epoch: 109 [2017-11-23 23:22:44]\n",
      "lr 0.016760038078849775\n",
      " 16M: 0.005730  8M: 0.005968  4M: 0.005735  2M: 0.007918  1M: 0.013251 merged: 0.005191\n",
      "epoch: 110 [2017-11-23 23:27:40]\n",
      "lr 0.0158999682000954\n",
      " 16M: 0.005729  8M: 0.005969  4M: 0.005744  2M: 0.008161  1M: 0.013464 merged: 0.005133\n",
      "epoch: 111 [2017-11-23 23:32:37]\n",
      "lr 0.01499063377991723\n",
      " 16M: 0.005682  8M: 0.005859  4M: 0.005627  2M: 0.007856  1M: 0.013040 merged: 0.005063\n",
      "epoch: 112 [2017-11-23 23:37:31]\n",
      "lr 0.014022453903762567\n",
      " 16M: 0.005602  8M: 0.005801  4M: 0.005664  2M: 0.007948  1M: 0.013200 merged: 0.004981\n",
      "epoch: 113 [2017-11-23 23:42:27]\n",
      "lr 0.012982269672237465\n",
      " 16M: 0.005556  8M: 0.005808  4M: 0.005578  2M: 0.007843  1M: 0.012976 merged: 0.004978\n",
      "epoch: 114 [2017-11-23 23:47:24]\n",
      "lr 0.01185113657849943\n",
      " 16M: 0.005578  8M: 0.005833  4M: 0.005669  2M: 0.008013  1M: 0.013291 merged: 0.004990\n",
      "epoch: 115 [2017-11-23 23:52:21]\n",
      "lr 0.010599978800063602\n",
      " 16M: 0.005560  8M: 0.005740  4M: 0.005586  2M: 0.007908  1M: 0.013183 merged: 0.004920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 116 [2017-11-23 23:57:20]\n",
      "lr 0.00917985092043157\n",
      " 16M: 0.005369  8M: 0.005619  4M: 0.005451  2M: 0.007679  1M: 0.012650 merged: 0.004842\n",
      "epoch: 117 [2017-11-24 00:02:18]\n",
      "lr 0.007495316889958615\n",
      " 16M: 0.005507  8M: 0.005826  4M: 0.005677  2M: 0.007835  1M: 0.013130 merged: 0.004962\n",
      "epoch: 118 [2017-11-24 00:07:15]\n",
      "lr 0.005299989400031801\n",
      " 16M: 0.005497  8M: 0.005714  4M: 0.005579  2M: 0.007766  1M: 0.012775 merged: 0.004856\n",
      "epoch: 119 [2017-11-24 00:12:13]\n",
      "lr 1e-08\n",
      " 16M: 0.005383  8M: 0.005634  4M: 0.005551  2M: 0.007808  1M: 0.012815 merged: 0.004814\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "writer = SummaryWriter(comment='-transition_scale_{}'.format(transition_scale))\n",
    "\n",
    "parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "optimizer = optim.SGD(parameters, lr=args.base_lr, momentum=args.momentum)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, beg, end, reset_lr=None):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if reset_lr != None:\n",
    "            param_group['lr'] = reset_lr\n",
    "            continue\n",
    "        if epoch != 0: \n",
    "            # linear\n",
    "#             param_group['lr'] *= (end-epoch) / (end-beg)\n",
    "#             poly base_lr (1 - iter/max_iter) ^ (power)\n",
    "            param_group['lr'] = args.base_lr * (float(end-epoch)/(end-beg)) ** (args.power)\n",
    "            if param_group['lr'] < 1.0e-8: param_group['lr'] = 1.0e-8\n",
    "        print('lr', param_group['lr'])\n",
    "        \n",
    "# def findLargerInd(target, arr):\n",
    "#     res = list(filter(lambda x: x>target, arr))\n",
    "#     print('res',res)\n",
    "#     if len(res) == 0: return -1\n",
    "#     return res[0]\n",
    "\n",
    "for epoch in range(args.epoches):\n",
    "    net.train()\n",
    "    print('epoch: {} [{}]'.format(epoch, datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "    \n",
    "    if epoch < args.training_thresholds[-1]: adjust_learning_rate(optimizer, epoch%ss, beg=0, end=ss-1)\n",
    "    else: adjust_learning_rate(optimizer, epoch, beg=args.training_thresholds[-1], end=args.epoches-1)\n",
    "    \n",
    "    run_losses = [0] * len(args.training_thresholds)\n",
    "    run_cnts   = [0.00001] * len(args.training_thresholds)\n",
    "    if (epoch in args.training_thresholds) == True: \n",
    "        adjust_learning_rate(optimizer, epoch, reset_lr=args.base_lr, beg=-1, end=-1)\n",
    "    writer.add_scalar('learning rate', optimizer.param_groups[0]['lr'], global_step=epoch)\n",
    "    for ind, data in enumerate(train_loader, 0):\n",
    "#         if  ind == 1 : break\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        im = input_img[0,:,:,:].numpy(); im = im.transpose(1,2,0); im = im[:,:,::-1]*255\n",
    "        \n",
    "        if test_scene[0] == 'alley_1':\n",
    "            print('alley_1 yes')\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda()\n",
    "            gt_albedo = gt_albedo.cuda()\n",
    "            gt_shading = gt_shading.cuda()\n",
    "#         run_losses = [0] * len(mse_losses)\n",
    "#         run_cnts = [0.00001] * len(mse_losses)\n",
    "        if args.display_curindex % args.display_interval == 0:\n",
    "            cv2.imwrite('snapshot{}/input.png'.format(args.gpu_num), im)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "#         pretrained.train(); ft_pretreained = pretrained(input_img)\n",
    "        ft_predict = net(input_img)\n",
    "        for i, threshold in enumerate(args.training_thresholds):\n",
    "#             threshold = args.training_thresholds[i]\n",
    "            if epoch >= threshold:\n",
    "#             if epoch >= 0:\n",
    "                if i == 5: s = 1\n",
    "                else: s = (2**(i+1))\n",
    "                gt = gt_albedo.cpu().data.numpy()\n",
    "                n,c,h,w = gt.shape\n",
    "                gt = gt[0,:,:,:]\n",
    "                gt = gt.transpose((1,2,0))\n",
    "                gt = cv2.resize(gt, (h//s, w//s))\n",
    "#                 gt = cv2.resize(gt, (h,w))\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    cv2.imwrite('snapshot{}/gt-{}-{}.png'.format(args.gpu_num, epoch, i), gt[:,:,::-1]*255)\n",
    "                gt = gt.transpose((2,0,1))\n",
    "                gt = gt[np.newaxis, :]\n",
    "                gt = Variable(torch.from_numpy(gt))\n",
    "                if use_gpu: gt = gt.cuda()\n",
    "                loss = mse_losses[i](ft_predict[i], gt)\n",
    "                loss_data = loss.data.cpu().numpy()\n",
    "                writer.add_scalar('{}th train iters loss'.format(i), loss_data, global_step=args.display_curindex)\n",
    "                ma_ = ft_predict[i].max().cpu().data.numpy()\n",
    "                mi_ = ft_predict[i].min().cpu().data.numpy()\n",
    "                #print('mi', mi_, 'ma', ma_)\n",
    "#                 writer.add_scalars('{}th train predict'.format(i), {'max': ma_, 'min': mi_}, global_step=args.display_curindex)\n",
    "#                 run_cnts[i] += 1\n",
    "                run_losses[i] += loss.data.cpu().numpy()[0]\n",
    "                loss.backward(retain_graph=True)\n",
    "                run_cnts[i] += 1\n",
    "#                 print('i = ', i, '; weig\\n', net.upsample01.weight[0,0,0:4,0:4].data.cpu().numpy())\n",
    "#                 print('i = ', i, '; grad\\n', net.upsample01.weight.grad[0,0,0:4,0:4].data.cpu().numpy())\n",
    "                if args.display_curindex % args.display_interval == 0:\n",
    "                    im = ft_predict[i].cpu().data.numpy()[0].transpose((1,2,0)) * 255\n",
    "                    cv2.imwrite('snapshot{}/train-{}-{}.png'.format(args.gpu_num, epoch, i), im[:,:,::-1])\n",
    "        optimizer.step()\n",
    "        args.display_curindex += 1\n",
    "\n",
    "    \"\"\" every epoch \"\"\"\n",
    "#     loss_output = 'ind: ' + str(args.display_curindex)\n",
    "    loss_output = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i,v in enumerate(run_losses):\n",
    "        if i == len(run_losses)-1: \n",
    "            loss_output += ' merged: %6f' % (run_losses[i] / run_cnts[i])\n",
    "            continue\n",
    "        loss_output += ' %2dM: %6f' % ((2**(4-i)), (run_losses[i] / run_cnts[i]))\n",
    "    print(loss_output)\n",
    "    # save at every epoch\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'args' : args,\n",
    "            'state_dict': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, 'snapshot{}/snapshot-{}.pth.tar'.format(args.gpu_num, epoch))\n",
    "    \n",
    "    # test \n",
    "    test_losses_trainphase = [0] * len(args.training_thresholds)\n",
    "    test_cnts_trainphase   = [0.00001] * len(args.training_thresholds)   \n",
    "    for ind, data in enumerate(test_loader, 0):\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "        \n",
    "#         pretrained.train(); ft_pretreained = pretrained(input_img)\n",
    "        ft_test = net(input_img)\n",
    "            \n",
    "        for i,v in enumerate(ft_test):\n",
    "            if epoch < args.training_thresholds[i]: continue\n",
    "            if i == 5: s = 1\n",
    "            else: s = (2**(i+1))\n",
    "            gt = gt_albedo.data.numpy()\n",
    "            n,c,h,w = gt.shape\n",
    "            gt = gt[0,:,:,:]\n",
    "            gt = gt.transpose((1,2,0))\n",
    "            gt = cv2.resize(gt, (h//s, w//s))\n",
    "#             gt = cv2.resize(gt, (h,w))\n",
    "            \n",
    "            gt = gt.transpose((2,0,1))\n",
    "            gt = gt[np.newaxis, :]\n",
    "            gt = Variable(torch.from_numpy(gt))\n",
    "            if use_gpu: gt = gt.cuda()\n",
    "\n",
    "            loss = mse_losses[i](ft_test[i], gt)\n",
    "            \n",
    "            test_losses_trainphase[i] += loss.data.cpu().numpy()[0]\n",
    "            test_cnts_trainphase[i] += 1\n",
    "            v = v[0].cpu().data.numpy()\n",
    "            v = v.transpose(1,2,0)\n",
    "            if ind == 0: cv2.imwrite('snapshot{}/test-phase_train-{}-{}.png'.format(args.gpu_num, epoch, i), v[:,:,::-1]*255)\n",
    "\n",
    "    \n",
    "    net.eval()\n",
    "    test_losses = [0] * len(args.training_thresholds)\n",
    "    test_cnts   = [0.00001] * len(args.training_thresholds)   \n",
    "    for ind, data in enumerate(test_loader, 0):\n",
    "#         if ind == 1: break\n",
    "        input_img, gt_albedo, gt_shading, test_scene, img_path = data\n",
    "        input_img = Variable(input_img)\n",
    "        gt_albedo = Variable(gt_albedo)\n",
    "        gt_shading = Variable(gt_shading)\n",
    "        if use_gpu:\n",
    "            input_img = input_img.cuda(args.gpu_num)\n",
    "            \n",
    "#         pretrained.eval(); ft_pretreained = pretrained(input_img)\n",
    "        ft_test = net(input_img)\n",
    "            \n",
    "        for i,v in enumerate(ft_test):\n",
    "            if epoch < args.training_thresholds[i]: continue\n",
    "            if i == 5: s = 1\n",
    "            else: s = (2**(i+1))\n",
    "            gt = gt_albedo.data.numpy()\n",
    "            n,c,h,w = gt.shape\n",
    "            gt = gt[0,:,:,:]\n",
    "            gt = gt.transpose((1,2,0))\n",
    "            gt = cv2.resize(gt, (h//s, w//s))\n",
    "#             gt = cv2.resize(gt, (h,w))\n",
    "            \n",
    "            gt = gt.transpose((2,0,1))\n",
    "            gt = gt[np.newaxis, :]\n",
    "            gt = Variable(torch.from_numpy(gt))\n",
    "            if use_gpu: gt = gt.cuda()\n",
    "\n",
    "            loss = mse_losses[i](ft_test[i], gt)\n",
    "            \n",
    "            test_losses[i] += loss.data.cpu().numpy()[0]\n",
    "            test_cnts[i] += 1\n",
    "            v = v[0].cpu().data.numpy()\n",
    "            v = v.transpose(1,2,0)\n",
    "            if ind == 0: cv2.imwrite('snapshot{}/test-phase_test-{}-{}.png'.format(args.gpu_num, epoch, i), v[:,:,::-1]*255)\n",
    "    \n",
    "    writer.add_scalars('16M loss', {\n",
    "        'train 16M ': np.array([run_losses[0]/ run_cnts[0]]),\n",
    "        'test_trainphase 16M ': np.array([test_losses_trainphase[0]/ test_cnts_trainphase[0]]),\n",
    "        'test 16M ': np.array([test_losses[0]/ test_cnts[0]])\n",
    "    }, global_step=epoch)  \n",
    "    writer.add_scalars('8M loss', {\n",
    "        'train 8M ': np.array([run_losses[1]/ run_cnts[1]]),\n",
    "        'test_trainphase 8M ': np.array([test_losses_trainphase[1]/ test_cnts_trainphase[1]]),\n",
    "        'test 8M ': np.array([test_losses[1]/ test_cnts[1]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('4M loss', {\n",
    "        'train 4M ': np.array([run_losses[2]/ run_cnts[2]]),\n",
    "        'test_trainphase 4M ': np.array([test_losses_trainphase[2]/ test_cnts_trainphase[2]]),\n",
    "        'test 4M ': np.array([test_losses[2]/ test_cnts[2]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('2M loss', {\n",
    "        'train 2M ': np.array([run_losses[3]/ run_cnts[3]]),\n",
    "        'test_trainphase 2M ': np.array([test_losses_trainphase[3]/ test_cnts_trainphase[3]]),\n",
    "        'test 2M ': np.array([test_losses[3]/ test_cnts[3]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('1M loss', {\n",
    "        'train 1M ': np.array([run_losses[4]/ run_cnts[4]]),\n",
    "        'test_trainphase 1M ': np.array([test_losses_trainphase[4]/ test_cnts_trainphase[4]]),\n",
    "        'test 1M ': np.array([test_losses[4]/ test_cnts[4]])\n",
    "    }, global_step=epoch) \n",
    "    writer.add_scalars('merged loss', {\n",
    "        'train merged ': np.array([run_losses[5]/ run_cnts[5]]),\n",
    "        'test_trainphase merged ': np.array([test_losses_trainphase[5]/ test_cnts_trainphase[5]]),\n",
    "        'test merged ': np.array([test_losses[5]/ test_cnts[5]])\n",
    "    }, global_step=epoch) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Visualize Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params=None):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    if params is not None:\n",
    "        assert isinstance(params.values()[0], Variable)\n",
    "        param_map = {id(v): k for k, v in params.items()}\n",
    "\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"10240,10240\"), format='svg')\n",
    "    seen = set()\n",
    "\n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d' % v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                name = param_map[id(u)] if params is not None else ''\n",
    "                node_name = '%s\\n %s' % (name, size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.zeros(1,3,256,256))\n",
    "y = net(x.cuda())\n",
    "g = make_dot(y[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tsvg', '-O', 'net-transition_scale_8'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(engine, format, filepath, quiet)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartupinfo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTARTUPINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \"\"\"\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1343\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot': 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-81727d6bc75d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'net-transition_scale_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransition_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, filename, directory, view, cleanup)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mrendered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(engine, format, filepath, quiet)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tsvg', '-O', 'net-transition_scale_8'], make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "g.render('net-transition_scale_{}'.format(transition_scale)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
