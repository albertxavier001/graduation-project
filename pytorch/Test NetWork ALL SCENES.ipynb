{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, platform, datetime, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import functional as F\n",
    "# import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc\n",
    "\n",
    "from myimagefoldereccv import MyImageFolder\n",
    "from mymodel import GradientNet\n",
    "from myargs import Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadimg(path):\n",
    "    im = Image.open(path).convert('RGB')\n",
    "    print(im.size)\n",
    "    im = transforms.ToTensor()(im)\n",
    "    x = torch.zeros(1,3,416,1024)\n",
    "    x[0,:,:,:] = im[:,0:416,0:1024]\n",
    "    #x = torch.zeros(1,3,32,32)\n",
    "    #x[0,:,:,:] = im[:,0:32,0:32]\n",
    "    x = Variable(x, volatile=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_csv(path, para):\n",
    "    text = ''\n",
    "    n,c,h,w = para.size()\n",
    "    text += ','.join([str(n), str(c), str(h), str(w)]) + ','\n",
    "    for nn in range(n):\n",
    "        for cc in range(c):\n",
    "            for hh in range(h):\n",
    "                for ww in range(w):\n",
    "                    text += str(para[nn,cc,hh,ww].data.cpu().numpy()) + ','\n",
    "    with open(path, 'w') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpu_num = 0\n",
    "gradient = False\n",
    "type2 = 'rgb' if gradient == False else 'gd'\n",
    "image_slpit = True\n",
    "\n",
    "# parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "# optimizer = optim.SGD(parameters, lr=args.base_lr, momentum=args.momentum)\n",
    "\n",
    "res_root = './results/images/'\n",
    "scenes = glob.glob('/home/albertxavier/dataset/sintel2/clean/*')\n",
    "cnt_albedo = 0\n",
    "cnt_shading = 0\n",
    "for scene in scenes:\n",
    "    scene = scene.split('/')[-1]\n",
    "    res_dir = os.path.join(res_root, 'image_split', scene)\n",
    "    if not os.path.exists(res_dir):\n",
    "        os.makedirs(res_dir)\n",
    "    for type_ in ['albedo', 'shading']:\n",
    "        \n",
    "#         if scene!='image_split': continue\n",
    "        \n",
    "        #root = '/media/lwp/xavier/graduation_results/showcase_model/image_split/{}/{}/'.format(type_, type2)\n",
    "#         root = '/media/lwp/xavier/graduation_results/showcase_model/{}/{}/{}/'.format(scene, type_, type2)\n",
    "        root = '/media/albertxavier/data/eccv/graduation-project/pytorch/snapshot0/'\n",
    "        print (root+'snapshot-238.pth.tar')\n",
    "        if not os.path.exists(root+'snapshot-238.pth.tar'): continue\n",
    "        snapshot = torch.load(root+'snapshot-238.pth.tar')\n",
    "        state_dict = snapshot['state_dict']\n",
    "        args = snapshot['args']\n",
    "        densenet = models.__dict__[args.arch](pretrained=True).cuda(gpu_num)\n",
    "        \n",
    "#         net.load_state_dict(state_dict)\n",
    "#         net.train()\n",
    "        net = None\n",
    "        num = 40 if scene=='market_6' else 50\n",
    "        for ind in range(1, 11):\n",
    "            if net is not None: del net\n",
    "#             torch.cuda.empty_cache()\n",
    "            net = GradientNet(densenet=densenet, growth_rate=32, \n",
    "                          transition_scale=2, pretrained_scale=4,\n",
    "                    debug=False).cuda(gpu_num)\n",
    "            \n",
    "            net.load_state_dict(state_dict)\n",
    "            net.train()\n",
    "            frame = 'frame_%04d.png'%(ind)\n",
    "            print('/home/albertxavier/dataset/sintel2/clean/{}/{}'.format(scene, frame))\n",
    "            im = loadimg('/home/albertxavier/dataset/sintel2/clean/{}/{}'.format(scene, frame)).cuda(gpu_num)\n",
    "            print(im.size())\n",
    "            merged = net(im.cuda(gpu_num))\n",
    "            alpha = merged[0,9:10,:,:]\n",
    "            beta = merged[0,10:13,:,:]\n",
    "            alpha = alpha.cpu().data.numpy()\n",
    "            beta = beta.cpu().data.numpy()\n",
    "            alpha = alpha.transpose((1,2,0))\n",
    "            beta = beta.transpose((1,2,0))\n",
    "            print('alpha', alpha.min(), alpha.max())\n",
    "            print('beta', beta.min(), beta.max())\n",
    "            #print(merged)\n",
    "            ######\n",
    "            #break\n",
    "            ######\n",
    "            # merged = mergeRGB\n",
    "            merged = merged[0]\n",
    "            # merged = merged[0:3,:,:]\n",
    "            merged = merged.cpu().data.numpy()\n",
    "            print (merged.shape)\n",
    "            merged = merged.transpose(1,2,0)\n",
    "            print (merged.shape)\n",
    "            B = merged[:,:,0:3]\n",
    "            dx = merged[:,:,3:6]\n",
    "            dy = merged[:,:,6:9]\n",
    "            res_frame = 'albedo_%04d.png'%(ind) if type_ == 'albedo' else 'shading_%04d.png'%(ind)\n",
    "            res_dx_frame = 'albedo_dx_%04d.png'%(ind) if type_ == 'albedo' else 'shading_%04d.png'%(ind)\n",
    "            res_dy_frame = 'albedo_dy_%04d.png'%(ind) if type_ == 'albedo' else 'shading_%04d.png'%(ind)\n",
    "            res_alpha = 'alpha_%04d.mat'%(ind)\n",
    "            res_beta =  'beta_%04d.mat'%(ind)\n",
    "            print('res path', os.path.join(res_dir,res_frame))\n",
    "            cv2.imwrite(os.path.join(res_dir,res_frame), B[:,:,::-1]*255)   \n",
    "            cv2.imwrite(os.path.join(res_dir,res_dx_frame), (dx[:,:,::-1]+0.5)*255)   \n",
    "            cv2.imwrite(os.path.join(res_dir,res_dy_frame), (dy[:,:,::-1]+0.5)*255)   \n",
    "            # save_csv(os.path.join(res_dir,res_alpha), alpha)\n",
    "            # save_csv(os.path.join(res_dir,res_beta), beta)\n",
    "            sio.savemat(os.path.join(res_dir,res_alpha), {'alpha': alpha})\n",
    "            sio.savemat(os.path.join(res_dir,res_beta), {'beta': beta})\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if gradient == False:\n",
    "#     merged = mergeRGB[5]\n",
    "#     merged = merged[0]\n",
    "#     merged = merged.cpu().data.numpy()\n",
    "#     print (merged.shape)\n",
    "#     merged = merged.transpose(1,2,0)\n",
    "#     print (merged.shape)\n",
    "#     dx = merged[:,:,0:3]\n",
    "#     cv2.imwrite('out_merge.png', dx[:,:,::-1]*255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if gradient == True:\n",
    "#     merged = mergeRGB[5]\n",
    "#     merged = merged[0]\n",
    "#     merged = merged.cpu().data.numpy()\n",
    "#     print (merged.shape)\n",
    "#     merged = merged.transpose(1,2,0)\n",
    "#     print (merged.shape)\n",
    "#     dy = merged[:,:,0:3]+0.5\n",
    "#     dx = merged[:,:,3:6]+0.5\n",
    "#     cv2.imwrite('out_merge_dx.png', dx[:,:,::-1]*255)\n",
    "#     cv2.imwrite('out_merge_dy.png', dy[:,:,::-1]*255)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
