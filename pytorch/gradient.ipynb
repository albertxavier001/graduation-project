{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.10+ac9245a\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as opti\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    pass\n",
    "args = Args()\n",
    "args.epoches = 20\n",
    "args.epoches_unary_threshold = 0\n",
    "args.base_lr = 1e-5\n",
    "args.train_dir = '/home/albertxavier/dataset/sintel/images/'\n",
    "args.arch = \"resnet18\"\n",
    "args.img_extentions = [\"png\",'jpg']\n",
    "args.image_w = 256\n",
    "args.image_h = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "def make_dataset(dir):\n",
    "    images_paths = glob.glob(os.path.join(dir, 'clean', '*', '*.png'))\n",
    "    albedo_paths = images_paths[:]\n",
    "    shading_paths = images_paths[:]\n",
    "    pathes = []\n",
    "    for img_path in images_paths:\n",
    "        sp = img_path.split('/'); sp[-3] = 'albedo'; sp = ['/'] + sp; albedo_path = os.path.join(*sp)\n",
    "        sp = img_path.split('/'); sp[-3] = 'albedo'; sp = ['/'] + sp; shading_path = os.path.join(*sp)\n",
    "        pathes.append((img_path, albedo_path, shading_path))\n",
    "    return pathes\n",
    "\n",
    "class MyImageFolder(data_utils.Dataset):\n",
    "    def __init__(self, root, transform=None, target_transform=None,\n",
    "                loader=default_loader):\n",
    "        imgs = make_dataset(root)\n",
    "        if len(imgs) == 0:\n",
    "            raise(RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n",
    "                               \"Supported image extensions are: \" + \",\".join(args.img_extentions)))\n",
    "\n",
    "        self.root = root\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img_path, albedo_path, shading_path = self.imgs[index]\n",
    "        \n",
    "        img = self.loader(img_path)\n",
    "        albedo = self.loader(albedo_path)\n",
    "        shading = self.loader(shading_path)\n",
    "        \n",
    "        if self.transform is not None: img = self.transform(img)\n",
    "        if self.transform is not None: albedo = self.transform(albedo)\n",
    "        if self.transform is not None: shading = self.transform(shading)\n",
    "\n",
    "        return img, albedo, shading\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "dataset= MyImageFolder(args.train_dir, \n",
    "                       transforms.Compose(\n",
    "        [transforms.RandomCrop((args.image_h, args.image_w)),\n",
    "         transforms.ToTensor()]\n",
    "    ))\n",
    "\n",
    "train_loader =data_utils.DataLoader(dataset,1,True,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CommonModel(nn.Module):\n",
    "    def __init__(self, original_model, arch):\n",
    "        super(CommonModel, self).__init__()\n",
    "        if arch.startswith('resnet') :\n",
    "            self.unary_2M = nn.Sequential(*list(original_model.children())[0:7])\n",
    "            self.unary_1M = nn.Sequential(*list(original_model.children())[7:8])\n",
    "    def forward(self, x):\n",
    "        _2M = self.unary_2M(x) \n",
    "        _1M = self.unary_1M(_2M)\n",
    "        return _2M, _1M\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
