{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, platform, datetime, random\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import functional as F\n",
    "# import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import inv as denseinv\n",
    "from scipy import sparse\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.sparse.linalg import inv as spinv\n",
    "import scipy.misc\n",
    "\n",
    "# from myimagefolder import MyImageFolder\n",
    "from mymodel import GradientNet\n",
    "from myargs import Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadimg(path):\n",
    "    im = Image.open(path).convert('RGB')\n",
    "    w0,h0 = im.size\n",
    "    w1,h1 = w0//32*32,h0//32*32\n",
    "    print(im.size)\n",
    "    print(w1,h1)\n",
    "    im = transforms.ToTensor()(im)\n",
    "    x = torch.zeros(1,3,h1,w1)\n",
    "    x[0,:,:,:] = im[:,0:h1,0:w1]\n",
    "    x = Variable(x, volatile=True)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type_ = 'albedo'\n",
    "gpu_num = 1\n",
    "gradient = False\n",
    "type2 = 'rgb' if gradient == False else 'gd'\n",
    "image_slpit = True\n",
    "input_img_paths = glob.glob('/media/lwp/xavier/tmp/test_image/*.jpg')\n",
    "# root = '/media/lwp/xavier/graduation_results/showcase_model/image_split/{}/rgb/'.format(type_)\n",
    "root = '/media/albertxavier/data/eccv/graduation-project/pytorch/snapshot0/'\n",
    "snapshot = torch.load(root+'snapshot-418.pth.tar')\n",
    "state_dict = snapshot['state_dict']\n",
    "args = snapshot['args']\n",
    "densenet = models.__dict__[args.arch](pretrained=True).cuda(gpu_num)\n",
    "        \n",
    "net = GradientNet(densenet=densenet, growth_rate=32, \n",
    "              transition_scale=2, pretrained_scale=4,\n",
    "             gradient=gradient).cuda(gpu_num)\n",
    "net.load_state_dict(state_dict)\n",
    "net.train()\n",
    "for input_img_path in input_img_paths:\n",
    "    print(input_img_path)\n",
    "    sp = input_img_path.split('.')\n",
    "    output_img_path = os.path.join(sp[0]+type_+'.'+sp[1])\n",
    "    im = loadimg(input_img_path).cuda(gpu_num)\n",
    "    res = net(im.cuda(gpu_num), go_through_merge=True)\n",
    "    merged = res[:,0:3,:,:]\n",
    "    merged = merged[0]\n",
    "    merged = merged.cpu().data.numpy()\n",
    "    merged = merged.transpose(1,2,0)\n",
    "    alpha = res[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if gradient == False:\n",
    "#     merged = mergeRGB[5]\n",
    "#     merged = merged[0]\n",
    "#     merged = merged.cpu().data.numpy()\n",
    "#     print (merged.shape)\n",
    "#     merged = merged.transpose(1,2,0)\n",
    "#     print (merged.shape)\n",
    "#     dx = merged[:,:,0:3]\n",
    "#     cv2.imwrite('out_merge.png', dx[:,:,::-1]*255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if gradient == True:\n",
    "#     merged = mergeRGB[5]\n",
    "#     merged = merged[0]\n",
    "#     merged = merged.cpu().data.numpy()\n",
    "#     print (merged.shape)\n",
    "#     merged = merged.transpose(1,2,0)\n",
    "#     print (merged.shape)\n",
    "#     dy = merged[:,:,0:3]+0.5\n",
    "#     dx = merged[:,:,3:6]+0.5\n",
    "#     cv2.imwrite('out_merge_dx.png', dx[:,:,::-1]*255)\n",
    "#     cv2.imwrite('out_merge_dy.png', dy[:,:,::-1]*255)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
